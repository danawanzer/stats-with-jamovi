% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Statistics with jamovi},
  pdfauthor={Dana Wanzer},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\usepackage[normalem]{ulem}
% Avoid problems with \sout in headers with hyperref
\pdfstringdefDisableCommands{\renewcommand{\sout}{}}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}

\newenvironment{danger}
    {
    \hline\\
    }
    { 
    \\\\\hline
    }
    
\newenvironment{warning}
    {
    \hline\\
    }
    { 
    \\\\\hline
    }
    
\newenvironment{info}
    {
    \hline\\
    }
    { 
    \\\\\hline
    }
    
\newenvironment{try}
    {
    \hline\\
    }
    { 
    \\\\\hline
    }
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Statistics with jamovi}
\author{Dana Wanzer}
\date{Last Update: 2022-01-19}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{welcome}{%
\chapter*{Welcome}\label{welcome}}
\addcontentsline{toc}{chapter}{Welcome}

\includegraphics{images/Cover.jpg}

This is the website for PSYC 290 and PSYC 790 at the University of Wisconsin-Stout, taught by Dr.~Dana Wanzer. These resources are aimed at teaching you how to use jamovi and null hypothesis significance testing (NHST) to answer research questions.

This website is \textbf{free to use} and is licensed under a Creative Commons BY-SA (CC BY-SA) license version 4.0. This means you are free to \textbf{share} (i.e., copy and redistribute the material in any medium or format) and \textbf{adapt} (i.e., remix, transform, and build upon the material for any purpose, even commercially), provided that you \textbf{attribute} these resources by citing me, indicating if changes were made and you \textbf{share alike} (i.e., if you adapt, you must distribute your contributes under the same license as the original).

Many of the data examples come from ``\href{http://www.learnstatswithjamovi.com}{Learning statistics with jamovi: A tutorial for psychology students and other beginners}'' by Danielle J. Navarro and David R. Foxcroft, version 0.70.

\textbf{Dedication:} This book is dedicated to my graduate statistics professor Dr.~Dale Berger, who gave us a similar set of resources when he taught statistics at Claremont Graduate University. I still have my binder of handouts, homework assignments, and notes and they have been instrumental in my career. Thank you for showing me the joy of statistics.

\begin{figure}
\centering
\includegraphics{images/Dale.jpg}
\caption{Image of Dale Berger and Dana Wanzer at her master's graduation ceremony}
\end{figure}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

This chapter will introduce you to the course, the instructor (Dr.~Dana Wanzer), and the textbook.

\hypertarget{getting-help-in-this-class}{%
\section{Getting help in this class}\label{getting-help-in-this-class}}

Come to student hours regularly! The GA and myself are \emph{always} available to help you. We will be scheduling regularly recurring student hours each week so you can come ask questions, get help on your homework, or just have a space to come together to work on your assignments in a dedicated online space.

If you have more personal questions, you can message me on Teams or email me at wanzerd@uwstout.edu.

\hypertarget{dana-your-instructor}{%
\section{Dana, your instructor}\label{dana-your-instructor}}

My name is Dana Wanzer (pronounced DAY-nuh JUAN-zur) and I started teaching at UW-Stout in Fall 2019. I teach statistics (BS and MS programs) and evaluation (MS program) in the psychology department. I \emph{love} statistics! It is one way we can answer our research questions and test our hypotheses.

\includegraphics{images/01-intro/cyanide-happiness_statistics.png}

However, I know not everyone likes statistics. Some of you may not care much about it, and some of you may be apprehensive or anxious about taking this course. Please know that \textbf{I am here for you and I want to make this class an enjoyable learning experience}. If there is anything I can do to help make this class more enjoyable and to help you learn, please reach out to me.

\hypertarget{navigating-this-websitebook}{%
\section{Navigating this website/book}\label{navigating-this-websitebook}}

This book was developed in R/Rstudio using \href{https://bookdown.org/yihui/bookdown}{bookdown} and is hosted on a platform called GitHub. You can see the code for this book \href{https://github.com/danawanzer/stats-with-jamovi}{here}.

There are some icons at the top of this book that you may find useful:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The first button of the toolbar toggles the visibility of the sidebar, which contains the table of contents. You can also hit the \texttt{S} key on your keyboard to toggle the sidebar.
\item
  The second button of the toolbar is the search button, which you can use to search the entire book. You can also hit the \texttt{F} (Find) key on your keyboard.
\item
  The third button is for font/theme settings, which you can use to change font size (smaller or bigger), font family (serif or sans serif), and theme (white, sepia, or night).
\item
  The fourth button provides information on the keyboard shortcuts.
\item
  On the right of the toolbar are icons to share on various social media platforms.
\end{enumerate}

Answers to questions are found in the Answers appendix.

\hypertarget{errors-mistakes-and-suggestions}{%
\subsection{Errors, mistakes, and suggestions}\label{errors-mistakes-and-suggestions}}

I am human, therefore I err. If you find an error in the textbook or something you think might be a mistake, please let me know ASAP so I can update this for everyone else. Let me know which section you find the error or mistake in and what the error or mistake is. For example, if there was an error here you could say, ``There was an error in 1.2 that the first sentence should really be `To err is human (Alexander Pope, 1711).'\,''

In addition, if you have ideas to help make this textbook even better, please let me know. I would love to make this a useful resource to you both during our course and in your future research. Help me in making that a reality!

\hypertarget{statistics-foundations}{%
\chapter{Statistics foundations}\label{statistics-foundations}}

You have learned about both quantitative and qualitative methods. We will be focusing primarily on quantitative methods in this class and in this textbook. By quantitative methods, I mean methods that predominantly collect data that deals with numbers. We can then analyze that data using statistical procedures, which we will shorthand to ``statistics.'' Understanding what we mean by statistics is the purpose of this chapter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=QirHpjLkHmc"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{descriptive-vs-inferential-statistics}{%
\section{Descriptive vs inferential statistics}\label{descriptive-vs-inferential-statistics}}

There are basically two different types of statistics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Descriptive statistics} are used to summarize, organize, and overall \emph{describe} our sample data. Typically, we do so using measures of central tendency (e.g., mean, median, mode), measures of dispersion (e.g., range, standard deviation, variance), and shape (e.g., skew, kurtosis). We may also visualize the data using tables or graphs.
\item
  \textbf{Inferential statistics} are what we use when we collect data about a sample and see how well that sample \emph{infers} things about the population from which the sample comes from. Typically, we do so with statistical tests like the t-test, ANOVA, correlation, chi-square, regression, and more.
\end{enumerate}

We can visualize the relationship between the population, sample, descriptive statistics, and inferential statistics (see figure below). We are typically interested in a \textbf{population} of interest but may not be able to collect data from the entire population because of budget, time, access, or other constraints. We therefore \textbf{sample} from the population; ideally, we do so randomly, but there are other types of sampling methods available. We then use \textbf{descriptive statistics} to describe our sample data and \textbf{inferential statistics} to make generalizations about the population from which they were selected.

\includegraphics{images/02-stats-foundations/descriptive-vs-inferential.png}

\hypertarget{an-example}{%
\subsection{An example}\label{an-example}}

This has been pretty abstract so far. Let's go through a fairly simple research study to walk through all of this.

Imagine we're conducting an experimental study examining whether watching Schitt's Creek--a very good show--versus watching video lessons on studying techniques--useful, but boring--improved test performance in UW-Stout students.

Our population of interest is therefore all UW-Stout students, roughly 9,500 students total. We cannot include them all in our study; it wouldn't be feasible for us to collect all that data and probably not possible to get the university to get on board with the study of the entire student body. Therefore, we smartly decide to only collect data from a sample of the student body.

Who might our sample be? Ideally, we'd gather a random sample of the 9,500 students. However, to do that we'd likely need to still get university approval and get a list of a portion of student emails for recruitment purposes (oversampling because our response rate is unlikely to be 100\%). I just want to do this study to show what descriptive and inferential statistics are, so I just use students in my two sections of introduction to psychology classes (around 80 students total) as my population. This is definitely not a random sample, but a fine study for our illustrative purposes.

We conduct our study--let's assume we're fabulous researchers and it worked out perfectly. We randomly assign half our students to watch Schitt's Creek as part of their studying, and the other half watch video lessons on studying techniques. They have an exam a week later and we measure their accuracy on that exam. We then want to know: which group performed better on the exam?

First, let's describe the sample. We would likely visualize our results, perhaps as a histogram of all test scores, maybe separated by which group they were in. This would help us look at whether our data is normally distributed (more on this in a subsequent chapter on assumption checking). We would get the descriptive statistics: probably the mean, maybe the median if our data is skewed, the standard deviation and variance, and the range. If we wrote up our results and didn't share a visualization, this information would give a good sense of our data to our readers.

But what we really want to know is: which group performed better on the test? For that, we need our mean, standard deviations, and sample sizes for both groups. We then plug the numbers into the equation for this particular inferential statistic (in this case, an independent t-test, but we'll learn about that later) or--even better--we perform the statistic in our statistical software (jamovi). It spits out our statistical value and our p-value and we can then infer what the results mean for our population and answers our research question.\footnote{You might be wondering: well, what were the results? Which group performed better? As much as I love Schitt's Creek, most students don't know how to study well, and so the students who watched the video lessons on studying techniques far outperformed the students who watched Schitt's Creek.

  Interested in better techniques for studying? Check out \href{https://www.learningscientists.org/blog/category/For+Students}{The Learning Scientists}. This \href{https://www.learningscientists.org/blog/2020/1/9-1}{article}does a good job of summarizing the research on effective study practices.}

\hypertarget{measures-of-central-tendency-and-dispersion}{%
\section{Measures of central tendency and dispersion}\label{measures-of-central-tendency-and-dispersion}}

There are multiple \textbf{measures of central tendency} (these are \emph{all} averages so you must be careful when you say that word to explain which type you mean!):

\begin{itemize}
\item
  \textbf{Mean}: the sum of all points divided by the total number of points; susceptible to outliers
\item
  \textbf{Median}: the middlemost value; less susceptible to outliers and best used when the data is skewed
\item
  \textbf{Mode}: most frequent score

  \begin{itemize}
  \tightlist
  \item
    \textbf{Multimodal} or \textbf{bimodal}: when two or more values are the most frequent score
  \end{itemize}
\end{itemize}

There are also multiple \textbf{measures of dispersion} that describe the spread of our data:

\begin{itemize}
\item
  \textbf{Range}: the difference between the maximum and minimum value (e.g., if the minimum score is 17 and the maximum is 49, then the range is 32)
\item
  \textbf{Quartile}: when a dataset is divided into four equal parts, the first quartile (Q1) is at the 25th percentile, the second quartile (Q2) is at the 50th percentile, and the third quartile (Q3) is at the 75th percentile.

  \begin{itemize}
  \tightlist
  \item
    \textbf{Interquartile range}: the middle 50\% (Q1 to Q3)
  \end{itemize}
\item
  \textbf{Variance}: the sum of the squared deviations from the mean. This means first (a) calculating the mean, (b) subtracting each score from the mean (aka deviations from the mean), (c) squaring each of those deviations values, and (d) summing all those squared deviations. This is represented by the equation \(\frac{\sum (X-\mu)^2}{N}\)
\item
  \textbf{Standard deviation}: is the square of the variance. This is represented by the equation \(\sqrt{\frac{\sum (X-\mu)^2}{N}}\) however that equation is only used if we are examining the whole population. If we only have a sample, we replace the denominator \texttt{N} with \texttt{N-1}.
\end{itemize}

We also have two main \textbf{measures of shape} that describe the shape of the distribution of our data:

\begin{itemize}
\item
  \textbf{Skew}: in a non-normal distribution, it is when one tail of the distribution is longer than another. Present in asymmetric distributions

  \begin{itemize}
  \item
    \textbf{Negative skew}: when the tail points to the negative end of the spectrum; in other words, most of the values are on the right side of the distribution
  \item
    \textbf{Positive skew}: when the tail points to the positive end of the spectrum; in other words, most of the values are on the left side of the distribution
  \end{itemize}
\item
  \textbf{Kurtosis}: the weight of the tails relative to a normal distribution. There are some fancy terms related to kurtosis that you may hear about, but honestly I don't hear them used very frequently by researchers.

  \begin{itemize}
  \tightlist
  \item
    \textbf{Leptokurtic}: light tails; values are more concentrated around the mean
  \item
    \textbf{Platykurtic}: heavy tails; values are less concentrated around the mean
  \end{itemize}
\end{itemize}

There are other terms we use to describe data:

\begin{itemize}
\item
  \textbf{Frequency distribution}: overview of the times each value occurs in a dataset; often portrayed visually like with a histogram
\item
  \textbf{Histogram}: a visual depiction of the frequency distribution using bars to depict a range of the distribution
\item
  \textbf{Normal distribution}: a special distribution in which the data are symmetrical on both sides of the mean; under a normal distribution, the mean is also equal to the median
\end{itemize}

\hypertarget{levels-of-measurement}{%
\section{Levels of measurement}\label{levels-of-measurement}}

This should be refresher material for you, but it is extremely important you are familiar with the four levels of measurement.

\includegraphics{images/01-intro/Levels of measurement.png}

\textbf{Categorical}: variables that have \emph{categories} to the levels, but cannot be analyzed with a mean because the levels are not proportionate. There are two types of categorical variables:

\begin{itemize}
\item
  \textbf{Nominal}: a categorical variable in which each level of the variable is named but there is no order to them (e.g., breeds of dogs)

  \begin{itemize}
  \tightlist
  \item
    \textbf{Binary}, \textbf{dummy-coded}, or \textbf{dichotomous}: a nominal variable with only two levels (general 0 or 1). This is a special type of nominal variable.
  \end{itemize}
\item
  \textbf{Ordinal}: a categorical variable in which each level of the variable is named and there is an order to them (e.g., ranks)
\end{itemize}

\textbf{Continuous}: variables with proportionate intervals between the levels meaning they can be analyzed with a mean, SD, variance. There are two types of continuous variables (although for the purpose of this course we will simply call them continuous variables):

\begin{itemize}
\item
  \textbf{Interval}: a continuous variable that has intervals that are directly proportionate (e.g., the distance between 2-3 is the same as the distance between 5-6)
\item
  \textbf{Ratio}: a continuous variable like an internal variable but can accommodate an absolute zero, meaning a zero is actually possible (e.g., weight, temperature in Kelvin, reaction time)
\end{itemize}

\hypertarget{examples-of-levels-of-measurement}{%
\subsection{Examples of levels of measurement}\label{examples-of-levels-of-measurement}}

Confused still on the levels of measurement? Maybe this will help! Notice that studying can be measured at different levels. Depending on the nature of the question and response options, it might be nominal, ordinal, or continuous! Here's an example of data at the continuous, ordinal, and nominal level.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.17}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.21}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.31}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.32}}@{}}
\toprule
Name & Study\_Continuous & Study\_Ordinal & Study\_Nominal \\
\midrule
\endhead
\emph{Name (Character)} & \emph{Hours studied per day} & \emph{Likert scale of amount of studying} & \emph{Whether or not they study every day} \\
Jesus & 5.0 & A great deal & Yes \\
Nicky & 4.5 & A great deal & Yes \\
Bradford & 3.2 & A moderate amount & Yes \\
Sylvia & 1.7 & A small amount & Yes \\
Martha & 0.2 & Rarely & Yes \\
Lillian & 0.0 & Never & No \\
Trayvon & 0.0 & Never & No \\
\bottomrule
\end{longtable}

We can make any continuous variable into an ordinal and nominal variable and any ordinal variable into a nominal variable. But if we have a nominal variable we cannot make it ordinal, nor can we make an ordinal variable continuous. In other words, continuous variables \emph{contain more information}. Often, we want to avoid losing information and \emph{always} keep the variable at the highest level of measurement. Continuous has more information than ordinal has more information than nominal.

Another way to put it: never do a median split and avoid ``collapsing'' categories when you can. You're losing information from your data by doing so.

\hypertarget{normal-distribution}{%
\section{Normal distribution}\label{normal-distribution}}

A very important distribution of data is known as the \textbf{normal distribution}. You may have also heard it called a bell-shaped curve. It has really important statistical properties which is why most of the inferential statistics we'll be learning in this class are \emph{parametric statistics} that assume our data has a \emph{normal distribution}.

Some of the important statistical properties of the normal distribution:

\begin{itemize}
\item
  Data are equally distributed on both sides of the mean.
\item
  Skew and kurtosis are equal to 0, which is to say there is no skew or bad kurtosis.
\item
  The mean is equal to the median, and both are the exact center of the distribution of data. In other words, if your mean and median are \emph{not} the same, you know you have skewed data! In fact, if your median \textless{} mean then you have positive skew and if your median \textgreater{} mean then you have negative skew.
\item
  We know the percentage of cases within 1, 2, 3, etc. standard deviations from the mean.
\end{itemize}

\hypertarget{key-terms}{%
\section{Key Terms}\label{key-terms}}

This chapter will cover some basic key terms you should recall from PSYC 190 if you are in PSYC 290 or from earlier in the semester if you are in PSYC 790. These terms will come up repeatedly throughout the semester.

\hypertarget{study-design-terms}{%
\subsection{Study design terms}\label{study-design-terms}}

Some terms you should be familiar with:

\begin{itemize}
\item
  \textbf{Between-group/subject design}: different people are in each condition; participants are only exposed to a single condition
\item
  \textbf{Correlational research}: a study in which causality cannot be claimed; correlation does not infer causation! It is, however, one of three necessary conditions to infer causality. It is a \emph{necessary} but \emph{insufficient alone} condition.
\item
  \textbf{Cross-sectional research}: also called non-experimental research; the IV is not manipulated and there is no random assignment. Furthermore, data is only collected at one time point (as opposed to longitudinal research)
\item
  \textbf{Experimental research}: the IV is manipulated and there is random assignment
\item
  \textbf{Falsification}: A key way we separate science from pseudo-science is that we attempt to \emph{falsify}~our hypotheses as opposed to try \emph{verify}~our hypotheses. Null hypothesis significance testing (NHST) is about falsifying the null hypothesis; we can never truly verify our alternative hypothesis.
\item
  \textbf{Hypothesis}: What we think the answer to our research question is (often our alternative hypothesis). The alternative and null hypotheses must be mutually exclusive (a result can't satisfy both) and exhaustive (all possible results are specified)

  \begin{itemize}
  \item
    \textbf{Alternative hypothesis}: Often that the IV had \textbf{an} effect on the DV; can be specified as a two-tailed (an effect) or one-tailed (greater/less than) hypothesis
  \item
    \textbf{Null hypothesis}: Often the \emph{nill} hypothesis in that the IV had \textbf{no} effect on the DV
  \end{itemize}
\item
  \textbf{Qualitative methods}: Broadly, methods that focus on words and meaning (e.g., interviews)
\item
  \textbf{Quantitative methods}: Broadly, methods that focus on numbers and statistics (e.g., Likert scales)
\item
  \textbf{Quasi-experimental research}: the IV is manipulated but there is no random assignment
\item
  \textbf{Randomization}: participants are randomly assigned to conditions
\item
  \textbf{Repeated-measures design}: participants are repeatedly measured on the dependent variable, either across conditions or across time
\item
  \textbf{Theory}: A description of a behavior that makes predictions about future behaviors
\item
  \textbf{Variation}:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Systematic}: researcher something systematically error into the study, especially into one condition over another. For example, by randomly assigning participants into one of two conditions, we are introducing systematic variability between participants. However, it could be unintentional systematic variation; for example, perhaps we have two researchers collecting data and one is mean and the other is nice, and so participants respond differently depending on which researcher collects data from them.
  \item
    \textbf{Unsystematic}: random variation
  \end{itemize}
\item
  \textbf{Within-group/subject design}: the same person is in all conditions
\end{itemize}

\hypertarget{variables}{%
\subsection{Variables}\label{variables}}

We tend to talk about two different types of variables in our studies:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Independent variable} (IV; also known as the predictor variable): this is the variable that is thought to be the cause of some effect. In experimental research, it is the variable that is manipulated.
\item
  \textbf{Dependent variable} (DV; also known as the outcome variable): this is the variable that is thought to be affected by changes in the IV.
\end{enumerate}

There are other types of variables we may be interested in:

\begin{itemize}
\tightlist
\item
  \textbf{Confounding variable}: a variable that affects or is related to both the independent and dependent variable
\item
  \textbf{Covariate}: a variable that only affects or is only related to the dependent variable
\end{itemize}

\hypertarget{reliability-and-validity}{%
\subsection{Reliability and validity}\label{reliability-and-validity}}

\includegraphics{images/01-intro/reliability-validity.jpg}

\begin{itemize}
\item
  \textbf{Reliability}: the consistency of a measure by time (test-retest reliability), across items (internal consistency) or across different researchers (inter-rater reliability)
\item
  \textbf{Validity}: the extent to which a test measures what it claims to measure

  \begin{itemize}
  \item
    \textbf{Construct validity}: validity of inferences about the higher order constructs that represent sampling particulars. There are multiple types of construct validity; here are a few:

    \begin{itemize}
    \tightlist
    \item
      \textbf{Content validity}: experts using their judgment that something measures what it is supposed to measure
    \item
      \textbf{Convergent validity}: correlations among two theoretically related constructs (or measurements) are strong and positive
    \item
      \textbf{Divergent validity}: correlations among two theoretically not-related constructs (or measurements) are zero/null
    \item
      \textbf{Criterion validity}: content on one test (predictor) correlates with performance on relevant criterion measures (outcome)
    \end{itemize}
  \item
    \textbf{Statistical validity}: validity of inferences about the correlation between treatment and outcome
  \item
    \textbf{Internal validity}: validity about whether the observed relationship between A and B reflects a causal relationship between A and B
  \item
    \textbf{External validity}: validity of inferences about whether the cause-effect relationship holds over variation in persons, places, treatment variables, and measurement variables
  \end{itemize}
\end{itemize}

\hypertarget{other-terms}{%
\subsection{Other terms}\label{other-terms}}

If other terms come up in the course of the semester that you believe should belong in this key term website, include it in your weekly reflection so I can update this page!

\hypertarget{overview-of-jamovi}{%
\chapter{Overview of jamovi}\label{overview-of-jamovi}}

jamovi is a free and open statistical software that helps us run our descriptive and inferential statistics. Why are we using jamovi and not another program?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Did I mention it's free? You won't ever have to pay a dime to use the software in the future.
\item
  It's open source, meaning that the statistical community helps support and improve the program. As jamovi says, ``jamovi is made by the scientific community, for the scientific community.''
\item
  It's built on top of the R statistical language, meaning you can begin learning how to code (if you want). I do all of my statistical analyses using R in a different program called RStudio (actually this book was developed in RStudio and hosted on GitHub!). It's a very powerful tool which is also free and open source.
\item
  It's incredibly easy to learn and use. I have taught statistics using both SPSS and jamovi, and students greatly prefer jamovi.
\item
  It promotes reproducibility. jamovi will save your data, analyses, options, and results all in one file so you can easily pick up where you left off. This will make your homework and future data analyses a breeze.
\end{enumerate}

\hypertarget{additional-jamovi-videos}{%
\section{Additional jamovi videos}\label{additional-jamovi-videos}}

If you would like additional videos on working with jamovi, I recommend either the \href{https://www.linkedin.com/learning/introduction-to-jamovi/}{Introduction to jamovi LinkedIn Learning course} by Barton Poulson, founder of \href{https://datalab.cc/jamovi/}{datalab.cc}. However, at this point the videos are a bit outdated so I am no longer assigning them.

\hypertarget{opening-data-in-jamovi}{%
\section{Opening data in jamovi}\label{opening-data-in-jamovi}}

I occasionally get questions on how to open .sav files (SPSS files) in jamovi. Here's a video walking you through that.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=e{-}09OfLVs2U"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{descriptive-statistics}{%
\section{Descriptive statistics}\label{descriptive-statistics}}

As a reminder, \textbf{descriptive statistics} are used to summarize, organize, and overall \emph{describe} our sample data.

\hypertarget{data-variables}{%
\subsection{Data variables}\label{data-variables}}

First, it's important to understand the different types of variables in jamovi and how they map onto our levels of measurement.

Variables in jamovi can be one of three data types:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Integer, meaning the values are discrete whole numbers
\item
  Decimal, meaning the values are numbers with decimals
\item
  Text, meaning the values are alphanumeric, not just numeric
\end{enumerate}

Furthermore, variables in jamovi can be one of four measure types:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \includegraphics{images/03-jamovi/variable-nominal.png} Nominal
\item
  \includegraphics{images/03-jamovi/variable-ordinal.png} Ordinal
\item
  \includegraphics{images/03-jamovi/variable-continuous.png} Continuous (meaning jamovi combines interval and ratio and doesn't distinguish between the two)
\item
  \includegraphics{images/03-jamovi/variable-id.png} ID (used for any identifying variable you likely wouldn't ever analyze, like participant ID number or name)
\end{enumerate}

There are a few great things about jamovi when it comes to these data variables. First, jamovi will try to automatically determine what the data and measure types are when you type in data or when you open a dataset; this is fabulous, until it goes wrong. It's important that you always double check your data and measure types first!

Second, those little icons will be really helpful to let you know what variables can go in which boxes. For example, we would never analyze a nominal variable as our dependent variable for a t-test, and jamovi will help remind you of that. When performing an independent samples t-test, the dependent variables box will have a little ruler icon indicating you should be putting continuous variables in that box. Similarly, it will tell you to put nominal or ordinal variables in the grouping variable (independent variable) box. Sweet!

\hypertarget{exploring-your-data}{%
\subsection{Exploring your data}\label{exploring-your-data}}

In the third chapter of the LinkedIn Learning videos, you learned about data exploration, which are descriptive statistics. Exploring our data is partly to describe our data and partly to check our data before performing inferential statistics. jamovi puts all our descriptive statistics into one useful analysis under the Exploration tab called \texttt{Descriptives}.

You first learned about various descriptive statistics. In the \texttt{Descriptives} analysis, these are under the \texttt{Statistics} drop-down menu. There are a ton of possible options!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Sample size}: you can ask for the sample size (\texttt{N}) and number of missing values (\texttt{Missing})
\item
  \textbf{Percentile values}: these are useful for creating quartiles (\texttt{Cut\ points\ for\ 4\ equal\ groups}) or \texttt{Percentiles} of various sizes.
\item
  \textbf{Dispersion}: you should already be familiar with most of the measures of dispersion, particularly the \texttt{Minimum} and \texttt{Maximum} and the \texttt{Std.\ deviation} (SD) and \texttt{Variance} (which is just SD\textsuperscript{2}). We'll learn about the \texttt{S.\ E.\ Mean} later.
\item
  \textbf{Central Tendency}: similarly, you should also be familiar with all of the measures of central tendency: \texttt{Mean}, \texttt{Median}, \texttt{Mode}, and \texttt{Sum}.
\item
  \textbf{Distribution}: you should also be familiar with both \texttt{Skewness} and \texttt{Kurtosis} and later we will learn what those values mean and how that helps us test for normality
\item
  \textbf{Normality}: lastly, there is a statistical test for normality called the \texttt{Shapiro-Wilk} test that we will learn about later.
\end{enumerate}

In small examples, we might write-up our descriptive statistics into a paragraph\footnote{This comes from \href{https://thesiscommons.org/bk57d/}{Wanzer (2017) Developmentally appropriate evaluations: How evaluation practices differ across age of participants}}:

\includegraphics[width=6.27083in,height=\textheight]{images/02-stats-foundations/example1.png}

In examples with many variables, we might write-up our descriptive statistics into a table\footnote{This comes from \href{https://psycnet.apa.org/record/2018-49650-001}{Wanzer et al.~(2020) Experiencing flow while viewing art: Development of the aesthetic experience questionnaire}}:

\includegraphics[width=4.16667in,height=\textheight]{images/02-stats-foundations/example2.png}

\hypertarget{visualizing-your-data}{%
\subsection{Visualizing your data}\label{visualizing-your-data}}

``A picture is worth a thousand words,'' and in a world in which journal articles have word count limits, figures and graphs are priceless. They are also an incredibly powerful way to examine your data because it can often illuminate patterns you may not be able to see through a table.

jamovi has some plots built into its platform, both under the \texttt{Plots} drop-down menu in the \texttt{Descriptives} analysis and as options for many of the inferential statistical analyses. For the latter, I will provide some guidance on best practices for visualizing inferential results in the relevant subsequent chapters. For now, let's go over the various \texttt{Plots} in the \texttt{Descriptives} analysis.

First, there are two \textbf{Histogram} options: \texttt{Histogram} and \texttt{Density}. These are useful for seeing the overall distribution of your data and to help check for normality. Which should you use? I think they're both pretty great, and in fact you can combine the two to have a histogram plot with a density overlay. I like this option best.

There are three options under \textbf{Box Plots}: \texttt{Box\ plot}, \texttt{Violin} (which is really a density plot with its mirror image!), and \texttt{Data} (which can be Jittered or Stacked; I prefer Jittered so you can see the density of data points really well. Personally, I love checking all three boxes. This gives you the best of all three: the distribution of your data with the \texttt{Violin} option, the quartiles and mean with the \texttt{Box\ plot} option, and a visualization of all your data points using the \texttt{Data} option, which is really useful because the other two options can be \emph{hiding} weird things in your data.

\textbf{Remember: it is incredibly important to always visualize your data!} You never know what descriptive statistics may be hiding.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=d2wU0kmCJEY"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

Lastly, there is an option under \textbf{Bar Plots} for (you guessed it) a \texttt{Bar\ plot}. It will add error bars to your bar plot, but now that you know what can be hiding under descriptive statistics (bar plots only show the mean and error) you will hopefully avoid using these in the future when you can show the actual data itself.

\hypertarget{expanding-your-data-visualization}{%
\subsubsection{Expanding your data visualization}\label{expanding-your-data-visualization}}

Although these can be useful plots, I often do most of my data visualizations in other platforms. For most of my work, I use Excel because I find it pretty easy to make beautiful graphs. Here's an example of a visualization I made in Excel\footnote{This comes from \href{https://doi.org/10.1080/08993408.2020.1714313}{Wanzer et al.~(2020) Promoting intentions to persist in computing: An examination of six years of the EarSketch program}}:

\includegraphics{images/02-stats-foundations/example3.png}

For some more complicated figures, I turn to the \texttt{ggplot2} package in R. Here's an example of a visualization I made in R\footnote{This comes from \href{https://journals.sagepub.com/doi/10.1177/1098214020920710}{Wanzer (2020) What is evaluation? Perspectives of how evaluation differs (or not) from research}}:

\includegraphics{images/02-stats-foundations/example4.png}

In this class, we'll learn about effective data visualization later in the semester. I will provide some brief tutorials to help you get started, but please note that learning data visualization should be a course unto itself, so we will not be able to cover everything.

\hypertarget{cleaning-data}{%
\section{Cleaning data}\label{cleaning-data}}

There are four basic types of cleaning we will be learning about: checking your data is setup correctly, computing new variables, transforming variables, and using filters.

The following video walks through some of these data cleaning techniques.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=BGOZtlHRv6k"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{data-setup}{%
\subsection{Data setup}\label{data-setup}}

As previously mentioned, it's really important to check that the data types and measurement types of your variables are correct. You should open the Setup (\includegraphics[width=0.15625in,height=\textheight]{images/03-jamovi/menu-variable-edit.png}) option under the Data tab to check.

When you're in Setup, here's the things you should be doing for all variables:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Make sure the variable name is meaningful to you. You may also want to change it to something that will appear nicely in your data visualizations or tables (e.g., don't write \texttt{Q35} but rather \texttt{BDI\ Score}).
\item
  Add a description to your variable so you have more context. Maybe you write \texttt{Average\ score\ of\ all\ BDI\ items} for the description of your \texttt{BDI\ Score} variable.
\item
  Check your measure and data types are correct.
\item
  Specify if there is a code for missing values. Make sure the code \emph{does not}~match the code you use for actual variables! For example, if I have a variable that ranges from 0-10, then I wouldn't use 9 as a code for missing values; instead, I might use 99 or -9.
\item
  Add labels to levels. For example, the variable \texttt{Athlete} is 0 for non-athlete and 1 for athlete. Rather than keeping just the 0 and 1, you can specify under Levels that 0 is non-athlete.
\end{enumerate}

\hypertarget{compute}{%
\subsection{Compute}\label{compute}}

Sometimes you need to create new variables from your raw (meaning uncleaned) data. Perhaps you collected data on a scale that has five items. Normally, we create an average score of all the five items and that new \emph{computed} average score is what we use in our analyses.

Let's open the Big 5 dataset built into jamovi. You can open this dataset by clicking the three horizontal lines on the top left of jamovi (the menu), choose Open, then select Data Library. In the main Data Library folder is a dataset called Big 5.

This dataset has the scores on all five subscales of the Big Five personality test. Let's imagine we want the average score of the entire Big Five test. We would click on the Data tab and choose \texttt{Compute}. We would rename the computed variable (e.g., \texttt{Big5\_Avg}), add in a description, and then create the formula.

In this case, we need to select the function \texttt{MEAN}. Below the function, it provides a template of what the formula should look like. We need to specify the function \texttt{MEAN()}, add all the variables we want to calculate in the mean (i.e., the five subscales of the Big 5), and there are two alternative options: \texttt{ignore\_missing} is defaulted to 0 (meaning DON'T ignore missing, or rather include missing) and \texttt{min\_valid} is defaulted to 0 (meaning it's ignoring this; perhaps you only want to include people that have at least three valid cases).

The basic formula, then is to do MEAN(var1, var2, \ldots{} varn). You can see what we need to do with this dataset below. There's actually no missing data, so the two additional arguments aren't necessary for us to worry about.

\includegraphics{images/03-jamovi/compute.png}

If you'd like to learn more about computed variables in jamovi, \href{https://blog.jamovi.org/2017/11/28/jamovi-formulas.html}{check out this jamovi blog post on the topic}.

\hypertarget{transform}{%
\subsection{Transform}\label{transform}}

Sometimes we want to take an existing variable and transform it in some way or we want to do a computation across multiple variables (e.g., reverse-score multiple items in a dataset). If you want to learn more about transforming variables, \href{https://blog.jamovi.org/2018/10/23/transforming-variables.html}{the jamovi blog has a great blog post on the topic}.

\hypertarget{recoding}{%
\subsubsection{Recoding}\label{recoding}}

Maybe we want to recode variables. Perhaps we want to recode the Neuroticism scale into low, moderate, and high extraversion. The scale ranges from 1-5, so I'm going to say that scores between 1-2.333 are low, 2.334 to 3.666 is moderate, and 3.667 to 5 is high. First, I create a new Transform variable:

\includegraphics{images/03-jamovi/transform1.png}

Then I need to specify the transformation. Click Edit to do so (or, when creating a new transformation, click the transformation and select Create New Transform). We need to specify the recode conditions. Click \texttt{Add\ recode\ condition} twice. For the first formula, we want to specify that if the \$source (meaning the score for the variable we're using for the transformation, in this case Neuroticism) is less than or equal to 2.333, then it will be recoded as \texttt{low}. Notice the use of apostrophes around the text! We do the same for moderate. Then we can end with an else statement: all other values (else) are recoded as \texttt{high}. We can either let it auto determine the measure type, but I like to be in control of my data and therefore specify it is an ordinal variable.

\includegraphics{images/03-jamovi/transform2.png}

\hypertarget{multiple-transformations}{%
\subsubsection{Multiple transformations}\label{multiple-transformations}}

Maybe we instead want to do a computation across multiple variables. Perhaps we have multiple items that need to be reverse-scored, or in our case we want to use our previous \texttt{Low\_mod\_high} transformation to perform on \emph{all} the subscales of the Big 5.

We can click a new variable (e.g., Openness), select Transform, rename the variable, and select the \texttt{Low\_mod\_high} transformation we already used. Voila! The work we did previously can easily be used again in this analysis.

\hypertarget{filters}{%
\subsection{Filters}\label{filters}}

Sometimes we only want to analyze certain pieces of our data. We can filter by rows and by columns. \href{https://blog.jamovi.org/2018/04/25/jamovi-filters.html}{Check out this blog post by jamovi on more details of filters}.

\hypertarget{row-filters}{%
\subsubsection{Row filters}\label{row-filters}}

Maybe we only want to analyze data from people who are low in neuroticism. We would create the following filter:

\includegraphics{images/03-jamovi/filter-row.png}

You'll notice in the dataset it will add a new column named \texttt{Filter\ 1} (the name of the filter) and there will either be an X or a green check mark indicating whether it's removed (X) or kept (check) in the analyses.

If you want to take off the filter, but keep it available, click on the filter column and toggle the green button on the top right from \texttt{active} to \texttt{inactive}. It will then grey out the column.

A couple things to note:

\begin{itemize}
\item
  Notice that to say it equals to \texttt{low} you have to use a double equal sign: \texttt{==}
\item
  Another common thing you may want to specify is that the variable is \emph{not}~equal to something. You would use the following: \texttt{!=}
\item
  Otherwise you should be familiar with the other operations: \texttt{\textless{}}, \texttt{\textgreater{}}, \texttt{\textless{}=}, \texttt{\textgreater{}=}
\end{itemize}

\hypertarget{column-filters}{%
\subsubsection{Column filters}\label{column-filters}}

Column filters are useful when you want to use a filter for \emph{some} but not all of your analyses. Rather than creating a filter, we need to compute a new variable using the \texttt{FILTER()} function. For example, we can compute a new variable that is \texttt{FILTER(Neutoricism\_cat,\ Neuroticism\_cat\ ==\ \textquotesingle{}low\textquotesingle{}} . Then we could use that new variable in an analysis (in this case it's not very useful because there is no \emph{variability} in this variable, but there are useful times for using column filters for analyses).

\hypertarget{hypothesis-testing}{%
\chapter{Hypothesis testing}\label{hypothesis-testing}}

Now that we've covered descriptive statistics and are familiar with our statistical software, it's time to turn to inferential statistics. Remember, we conduct inferential statistics because we often cannot collect data from an entire population. Therefore, we collect a sample to draw inferences about the population of interest.

One of the ways we make inferences is using hypothesis testing. Regardless of the inferential statistic we are performing, hypothesis testing goes through the same procedures:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write your hypothesis (aka the alternative hypothesis) and its accompanying null hypothesis.
\item
  Set the criteria for a decision of whether to support or reject the null hypothesis
\item
  Perform the test statistic (this step has a little bit more to it, but we'll get to it later!)
\item
  Interpret your results and make a decision
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=Eqs9L6gDaJg"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

Let's go through each of these in turn, using a hypothetical example.

\hypertarget{an-example-of-hypothesis-testing}{%
\section{An example of hypothesis testing}\label{an-example-of-hypothesis-testing}}

Imagine a researcher wants to replicate Alburt Bandura's famous Bobo doll experiment. In this study, the researcher randomly assigns 30 six-year-old children to one of two conditions: one group watches a video of an adult showing aggressive behavior toward a Bobo doll and the other group watches a video of an adult passively playing with a Bobo doll. After watching their assigned video, children then went to the same room from the videos with the same Bobo doll. Researchers observed for aggressive behaviors\footnote{Technically, it's that the \emph{residuals} need to be normally distributed, but in the case of t-tests and ANOVAs the results are the same if we test for normality of residuals or the dependent variable.}.

\hypertarget{write-your-hypotheses}{%
\subsection{1. Write your hypotheses}\label{write-your-hypotheses}}

The first step is to write out our hypotheses. We need to write our \textbf{alternative} and \textbf{null} hypotheses.

The alternative hypothesis is typically what we expect the results of the study to be. We often expect to see \emph{something}; that there \emph{is} an effect. We usually write this out as H\textsubscript{1}.

The null hypothesis is typically what we \emph{don't} expect the results of the study to be. It is often that there was \emph{no} effect of the study. We usually write this out as H\textsubscript{0}.

The two hypotheses--our alternative and null hypotheses--must be \textbf{mutually exclusive} and \textbf{exhaustive}. Mutually exclusive means a potential result of the study cannot support both the alternative and null hypothesis; it must exclusively support only one. Exhaustive means the entire possible universe of results must be captured in our two hypotheses; it must exhaust all possible results.

We might also have \textbf{directional} or \textbf{non-directional} hypotheses. Directional hypotheses are also called one-tailed hypotheses because only one tail of the distribution would lead us to fail to reject the null hypothesis. Non-directional hypotheses are such that we don't know whether the difference will be greater or less than 0, but we just think there will be a difference; these are also called two-tailed hypotheses because both tails of the distribution would lead us to fail to reject the null hypothesis. This will make a little more sense below and a lot more sense in the next chapter.

What might the hypotheses be for our example study? There should be theory and research to support alternative hypotheses. There is ample research now that viewing aggression leads to aggression through imitation and observed learning. Therefore, the researcher likely has a hypothesis that watching the aggressive adult will lead to more aggressive behavior than watching the passive adult.

Therefore, our hypotheses would be:

\textbf{H\textsubscript{1}}: Children watching the video with the adult aggressively playing with the Bobo doll will exhibit \emph{more} aggressive behaviors than children watching the video with the adult playing passively.

\textbf{H\textsubscript{0}}: There will be \emph{no difference} in children's aggressive behaviors between the two groups or children watching the video with the adult aggressively playing with the Bobo doll will exhibit \emph{fewer} aggressive behaviors than children watching the video with the adult playing passively.

Note that we now satisfy mutual exclusivity (no possible overlap in the hypotheses) and exhaustiveness (all possible results are captured).

A common error in a directional hypothesis like this is to forget that the null hypothesis is both no difference \emph{and} the opposite. In other words, we have three possible options for our null and alternative hypotheses based on direction (\(\mu\) is the Greek letter ``mu'' and we often use it to signify the mean):

\begin{longtable}[]{@{}llll@{}}
\toprule
& Two-tailed & One-tailed (greater) & One-tailed (less than) \\
\midrule
\endhead
\textbf{Alternative} (H\textsubscript{1}) & \(\mu_1\) != \(\mu_2\) & \(\mu_1\) \textgreater{} \(\mu_2\) & \(\mu_1\) \textless{} \(\mu_2\) \\
\textbf{Null} (H\textsubscript{0}) & \(\mu_1\) == \(\mu_2\) & \(\mu_1\) \textless= \(\mu_2\) & \(\mu_1\) \textgreater= \(\mu_2\) \\
\bottomrule
\end{longtable}

Since we're talking about mean differences, we could also reformulate the above table slightly differently:

\begin{longtable}[]{@{}llll@{}}
\toprule
& Two-tailed & One-tailed (greater) & One-tailed (less than) \\
\midrule
\endhead
\textbf{Alternative} (H\textsubscript{1}) & \(\mu_{diff}\) != 0 & \(\mu_{diff}\) \textgreater{} 0 & \(\mu_{diff}\) \textless{} 0 \\
\textbf{Null} (H\textsubscript{0}) & \(\mu_{diff}\) == 0 & \(\mu_{diff}\) \textless= 0 & \(\mu_{diff}\) \textgreater= 0 \\
\bottomrule
\end{longtable}

Note: != means ``not equal'' like the  symbol. I write != because that is the notation that R uses for ``not equal.''

Similarly, you might be wondering why I use == instead of just =. Again, this is the notion R uses for ``exactly equal to.'' In R, a single equal sign is usually equivalent to the assignment operator (e.g., x = 10 means assign 10 to the variable x).

\hypertarget{set-the-criteria-for-a-decision}{%
\subsection{2. Set the criteria for a decision}\label{set-the-criteria-for-a-decision}}

Our hypotheses simply state ``more aggressive'' or ``no difference/less aggressive.'' What constitutes \emph{more}? What constitutes \emph{no difference}? We have to specify that.

No difference seems easy. That's a difference of zero, right? Well, not exactly, because it's highly unlikely we would get an \emph{exact} difference of zero. Therefore the question is: which values are close enough to a difference of zero that we'd still say that there is no difference? If our values are within that range, then we would fail to reject the null hypothesis. If our values are \emph{outside}~that range, then we would reject the null hypothesis.\footnote{Note my language carefully here: fail to reject the null hypothesis OR reject the null hypothesis. Note how I am \emph{not}~saying support the alternative hypothesis! Through null hypothesis significance testing, we are only ever testing the null hypothesis and therefore can only make conclusions about it. This is why we need replication studies to provide ample support for alternative hypotheses.}

Let's try to visualize this. We are saying that the null hypothesis is there is no difference (or less aggression), but at some point no difference turns into \emph{greater} difference. Furthermore, we have a directional hypothesis in that we do not think the difference will be negative, that children watching the adult play aggressively will exhibit fewer aggressive behaviors. Basically, we need to know what the critical value is in the figure below.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{04.0-hypothesis-testing_files/figure-latex/unnamed-chunk-2-1} 

}

\caption{Critical area of statistical significance}\label{fig:unnamed-chunk-2}
\end{figure}

We figure out that critical value based on what we set as our level of significance, also known as the \textbf{alpha level}. Most studies you read use the arbitrary \(\alpha\) = .05 (5\%), although we really should be thinking critically about what alpha level we use (more on that in the next chapter). In the visualization above, we set the alpha to 5\% and so the area shaded in red is exactly 5\% of the area under the curve of the normal distribution.

Our alpha is the level of which we are saying would be considered ``surprising'' versus ``not surprising.'' If we got a mean difference that fell in that red area, then we would consider that ``surprising'' \emph{if we believed the null hypothesis was true}. Basically, if we assume there is a mean difference of 0 (i.e., the null hypothesis), values past the critical value would be considered surprising enough that we would say that we reject the null hypothesis. This is why it is called \emph{null hypothesis significance testing}.

In other words, \emph{the area in red are values that are unlikely to occur if the null hypothesis (in this case, mean difference \textless= 0) were true.}

Now that we understand that a bit better, how do we find out our critical region? We do so based on our understanding of the incredible properties of the normal distribution! Back in the day before computers, some fancy mathematicians and statisticians figured out the exact \emph{t}-values based on things like the direction of our hypothesis, our alpha, and our degrees of freedom. Let's figure these out for our example:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Direction of our hypothesis}: we have already determined we're using a one-tailed hypothesis.
\item
  \textbf{Alpha}: let's just go with \(\alpha\) = .05 for now
\item
  \textbf{Degrees of freedom}: This is calculated by N - 2. We have 30 children total, so 30 - 2 is 28.
\end{enumerate}

We then go to a \href{http://www.z-table.com/t-value-table.html}{\emph{t-}value table like this one} and find the cell we are looking for to identify our critical t-value (\emph{t}\textsubscript{crit}). First, our one-tailed probability is .05 so we're going to look under the sixth column (t\textsubscript{.95}, one-tail = .05, two-tails = .10). Then we need to find the row for our degrees of freedom (df = 28). That leads us to a \emph{t\textsubscript{crit}} of \textbf{1.701}.

Therefore, we can now finalize this step. Our criteria for decision is as such:

\begin{itemize}
\item
  \emph{t\textsubscript{obt} \textgreater{} t\textsubscript{crit}} means we reject the null hypothesis.
\item
  \emph{t\textsubscript{obt} \textless{} t\textsubscript{crit}} means we fail to reject the null hypothesis
\end{itemize}

\hypertarget{perform-the-test-statistic}{%
\subsection{3. Perform the test statistic}\label{perform-the-test-statistic}}

We haven't learned how to calculate the test statistic yet, but no worries we will get there soon. We had 30 participants, 15 in each condition. The researcher performed the experiment and got the following results:

\begin{itemize}
\item
  Children who watched the video of the adult playing aggressively with the Bobo doll displayed an average of 51.10 aggressive behaviors (\emph{SD} = 3.50).
\item
  Children who watched the video of the adult playing passively with the Bobo doll displayed an average of 27.40 aggressive behaviors (\emph{SD} = 3.30).
\end{itemize}

That means the mean difference is 51.10 - 27.40 = 23.70. We'll learn how to conduct a t-test later, but for now you can just input the numbers into \href{https://www.usablestats.com/calcs/2samplet\&summary=1}{this calculator}. It nicely gives you a lot of the values, but the one we are looking for is the test statistic, which is \emph{t\textsubscript{obt}} = 19.08 (notice we round to two decimals). It also gives us our p-values based on the \emph{null} hypothesis, which in our case is that population 1 \textless{} population 2. The p-value is \textless{} .00001 but we never go to so many decimals, so we would say p \textless{} .001. The probability of getting a \emph{t}-value as large as we did it less than .1\% (less than our alpha of .05, so it is statistically significant). Very surprising!

\hypertarget{interpret-results-and-draw-a-conclusion.}{%
\subsection{4. Interpret results and draw a conclusion.}\label{interpret-results-and-draw-a-conclusion.}}

When \emph{t\textsubscript{obt} \textgreater{} t\textsubscript{crit}} we reject the null hypothesis which means our results are statistically significant (if our alpha is set to .05, then that means \emph{p} \textless{} .05).

On the other hand, when \emph{t\textsubscript{obt} \textless{} t\textsubscript{crit}} we fail to reject the null hypothesis which means our results are not statistically significant (if our alpha is set to .05, then that means \emph{p} \textgreater{} .05).

Since 19.08 \textgreater{} 1.701, we \emph{reject the null hypothesis that there is no difference in conditions or that children in the passive condition displayed more aggression than children in the aggressive condition.}

However, this is when \textbf{Type 1} and \textbf{Type 2} errors come into play. Just because we get a result \emph{does not automatically mean that result is 100\% accurate}. There are many things that could lead us to an inaccurate interpretation!

I like to use this table when discussing errors. On the far left column, we have our results: were they statistically significant (\emph{p} \textless{} .05) or not (\emph{p} \textgreater{} .05)? On the top row, we have whether \emph{in the real world} the null or alternative hypothesis is true. In reality, we can \emph{never} truly know whether the null or alternative hypothesis is true. We can at best approximate our understanding of the real world through replication!

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.52}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.24}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.24}}@{}}
\toprule
& H\textsubscript{0} is true & H\textsubscript{1} is true \\
\midrule
\endhead
\textbf{\emph{p}} \textbf{\textless{} .05} (statistically significant) & Type 1 error & Correct interpretation \\
\textbf{\emph{p}} \textbf{\textgreater{} .05} (statistically non-significant) & Correct interpretation & Type 2 error \\
\bottomrule
\end{longtable}

Therefore, any time we get a statistically significant result (\emph{p} \textless{} .05), then \emph{either} we made a correct interpretation \emph{or we made a Type 1 error!}

Similarly, any time we get a statistically non-significant results (\emph{p} \textgreater{} .05) then \emph{either} we made a correct interpretation \emph{or we made a Type 2 error}!

A common mistake is assuming that \emph{p} \textless{} .05 means that the alternative hypothesis is true. This is inaccurate because the \emph{p}-value is the probability of our data given the null hypothesis is true. It says nothing about the alternative hypothesis. Similarly, a common mistake is assuming \emph{p} \textgreater{} .05 means the alternative hypothesis is false. This is incorrect for the same exact reason.

Next week we'll learn a lot more about p-values, errors, and more. For now, tuck this piece of information into your brain to remember!

\hypertarget{final-note}{%
\subsection{Final note}\label{final-note}}

When you read journal articles, you'll note that they rarely discuss the null or alternative hypothesis. They may explain their research questions or their hypotheses (these hypotheses are their alternative hypotheses), but they rarely discuss the null.

This is not \emph{necessarily} a bad thing. Rather, what may be problematic with it is if researchers apply NHST without critically thinking about what their null hypothesis is or whether they have a one-sided hypothesis, which leads researchers to use defaults when the defaults may not be most appropriate. However, it would probably be a better thing if everyone clearly specified their alternative and null hypotheses if they are doing NHST.

\hypertarget{bean}{%
\chapter{BEAN}\label{bean}}

What a random chapter title right? Yes, but it's also an important acronym in hypothesis testing. BEAN stands for:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{B}eta (AKA power, which is technically 1 - \(\beta\))
\item
  \textbf{E}ffect size
\item
  \textbf{A}lpha
\item
  \textbf{N} (AKA sample size)
\end{enumerate}

The following sections will go through each of these in turn before ending with discussion on how all of these things interrelate. Although the BEAN acronym is useful (you'll find out why in a later section), I won't discuss them in that particular order.

\hypertarget{effect-sizes}{%
\section{Effect sizes}\label{effect-sizes}}

An \textbf{effect size} is a quantitative description of the strength of a phenomenon. There are two basic effect sizes we tend to talk about:

The \textbf{\emph{d}} family of effect sizes are standardized mean differences. They start at 0 (no mean difference) and can go up to infinity, with larger values meaning larger standardized mean differences. Some of the effect sizes in this family:

\begin{itemize}
\item
  Cohen's \emph{d} is perhaps the most popular standardized mean difference effect size. Generally, the equation is the mean difference divided by the pooled standard deviation, but in reality the equation differs based on a variety of scenarios and whether you are using a one-sample, independent samples, or paired samples \emph{t}-test.
\item
  Hedge's \emph{g} is a less biased version of Cohen's \emph{d}. Cohen's \emph{d} is particularly problematic for small sample sizes, so Hedge's \emph{g} is generally preferred, but you'll see that not all statistical programs provide this effect size. It's not that difficult to calculate Hedge's \emph{g} based on Cohen's \emph{d}, but just keep this information in mind.
\end{itemize}

The \textbf{\emph{r}} family of effect sizes are measures of strength of association. As you'll read about in the correlation and regression chapters, this family of effect sizes can describe the proportion of variance explained (e.g., r = .8 is 64\% variance explained, which is r-squared). Some of the effect sizes in this family:

\begin{itemize}
\item
  \emph{r} is a correlation. It's a standardized measure of the strength of association where \emph{r} = -1 or +1 means a perfect relationship and \emph{r} = 0 is no relationship at all.
\item
  \(\eta^2\) (eta-squared) measures the proportion of variance in the dependent variable associated with the different groups of the independent variable. This is considered a biased estimate, especially when trying to compare values across studies, so there are two more preferred effect sizes.
\item
  \(\eta^2_p\) (partial eta-squared) is calculated slightly differently and is considered a less biased estimate. This can allow for better comparisons of effect sizes across studies. It's still not perfect, though.
\item
  \(\omega^2\) (omega-squared) is calculated even more differently and is considered the least biased estimate. There is also \(\omega^2_p\) and \(\omega^2_G\) (generalized omega-squared) but we won't get into that.
\end{itemize}

If you nerded out over this information and want to learn more, \href{https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863/full}{check out this great journal article by Daniel Lakens}.

\hypertarget{small-medium-and-large-effect-sizes}{%
\subsection{Small, medium, and large effect sizes}\label{small-medium-and-large-effect-sizes}}

What is considered a small, medium, and large effect size? Quite frankly, \emph{it depends}.

You may have seen some heuristics online about what small, medium, and large is for Cohen's \emph{d} (e.g., .2, .5, and .8) and \emph{r} (e.g., .1, .3, and .5) but these heuristics should not be used without critical thought. In fact, Cohen (who is regularly cited for these heuristics) said that the way we should determine cut-offs is based on looking across studies to find what is considered small, medium, and large \emph{in that particular context}.

Lakens (who also did the great journal article on effect sizes above) has a fantastic new preprint out on \href{https://psyarxiv.com/9d3yf/}{Sample Size Justification}. In it, he provides an overview of six possible ways to determine which effect sizes are interesting:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  "Smallest effect size of interest: what is the smallest effect size that is theoretically and practically interesting?
\item
  Minimally statistically detectable effect: given the test and sample size, what is the critical effect size that can be statistically significant?
\item
  Expected effect size: which effect size is expected based on theoretical predictions or previous research?
\item
  Width of confidence interval: which effect sizes are excluded based on the expected width of the confidence interval around the effect size?
\item
  Sensitivity power analysis: across a range of possible effect sizes, which effects does a design have sufficient power to detect when performing a hypothesis test?
\item
  Distribution of effect sizes in a research area: what is the empirical range of effect sizes in a specific research are, and which effects are \emph{a priori} unlikely to be observed?" (p.~3)
\end{enumerate}

Basically, what does past research have to say about what effect size you can expect (\#3 and \#6)? What is the smallest effect size you care about (\#1)? What is the smallest effect size you can reasonably obtain (e.g., due to sample size limitations; \#2, \#3, and \#4)? This is the justification you use to determine what effect size you are looking for. This is important for when you are then determining what sample size you need, which will be discussed in a separate section.

\hypertarget{alpha-p-values}{%
\section{Alpha \& p-values}\label{alpha-p-values}}

Whereas effect sizes tell us about \emph{practical} significance, they do not tell us about \emph{statistical} significance. That is what \emph{p}-values are for: they tell us whether our results are \emph{statistically} significant or how surprising they are. The formal definition of a \textbf{\emph{p}-value} is that it is the probability of observing data that is as extreme or more extreme than the data you have observed, assuming the null hypothesis is true. There's two things to keep in mind about this definition:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The p-value is about the probability of our data. It is not about the probability of our hypothesis.
\item
  The p-value is based on the assumption that the null hypothesis is true. In null hypothesis significance testing, we are only ever testing against the null. We can never ``accept'' the alternative hypothesis but rather fail to reject the null. If we fail to reject the null enough times (and rarely reject the null) then it gives weighted evidence towards our alternative hypothesis, but we can never prove the alternative hypothesis is true.
\end{enumerate}

Another way we could think of the \emph{p}-value is: assuming there is no difference (i.e., the null hypothesis is true), how surprising is our data?

You may have heard of \emph{p}-values before. You may have heard about them in a previous statistics course or you may have heard of them in relation to the ``replication crisis.'' You may have heard about the journal that banned \emph{p}-values altogether. You may then be wondering why we are learning about \emph{p}-values if they seem so problematic that they should be banned.

The biggest problem with \emph{p}-values is that they are misunderstood, even by researchers. They are often misinterpreted. Daniel Lakens has a great \href{http://daniellakens.blogspot.com/2017/12/understanding-common-misconceptions.html}{blog post} on the topic and a great \href{https://www.coursera.org/learn/statistical-inferences}{MOOC} about improving your statistical inferences. You did one of the MOOC assignments last week in the ``Understanding common misconceptions about \emph{p}-values'' assignment. Whereas that assignment focused on understanding misconceptions, I will spend this chapter talking about what \emph{p}-values \emph{are.}

\hypertarget{alpha}{%
\subsection{Alpha}\label{alpha}}

The \emph{p}-value is the probability of the ``surprisingness'' of your data. We've already seen this chart from the last chapter where the area in red is our alpha region.

The alpha level is simply the level at which we consider the data \emph{so surprising} that we reject the null hypothesis. This area in red is also considered our critical test region and the region of statistical significance. Statistical significance depends on what we set our alpha at.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{05.2-p-values_files/figure-latex/unnamed-chunk-1-1} 

}

\caption{Critical area of statistical significance}\label{fig:unnamed-chunk-1}
\end{figure}

Why is alpha set at 5\% usually? It comes from Fisher (1925), who said something that eventually grew to tradition:

\begin{quote}
A deviation exceeding the standard deviation occurs about once in three trials. Twice the standard deviation is exceeded only about once in 22 trials, thrice the standard deviation only once in 370 trials\ldots. The value for which P = .05, or 1 in 20, is 1.96 or nearly 2 ; it is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not. Deviations exceeding twice the standard deviation are thus formally regarded as significant.
\end{quote}

Basically, .05 was convenient. It was 1/20. It was around 2 standard deviations from the mean in a normal distribution. For some reason, it caught on (maybe the ``formally regarded as significant'' was why).

However, a year later, even Fisher acknowledged we shouldn't just arbitrarily use \emph{p} = .05 as our alpha level.\footnote{Technically, it's that the \emph{residuals} need to be normally distributed, but in the case of t-tests and ANOVAs the results are the same if we test for normality of residuals or the dependent variable.} Rather, we should consider setting it at higher odds (e.g., \emph{p} = .01). He also argued, ``A scientific fact should be regarded as experimentally established only if a properly designed experiment \emph{rarely fails} to give this level of significance.'' (Fisher, 1926, p.~504).

In other words, we need to think critically about the alpha level we set \emph{and} we need to test an effect multiple times before we start thinking the alternative hypothesis is true. Let's discuss power before we start putting it all together.

\hypertarget{are-p-values-bad}{%
\subsection{Are p-values bad?}\label{are-p-values-bad}}

Some have argued that we should abandon the \emph{p}-value; this has led to things like journals completely banning \emph{p}-values altogether. However, I agree with Lakens that \href{https://psyarxiv.com/shm8v/}{``the practical alternative to the \emph{p}-value is the correctly used \emph{p}-value.''} That's to say: there is nothing \emph{wrong} with the \emph{p}-value inherently, and it can be useful. Rather, what's \emph{wrong} is that many people use them incorrectly.

\hypertarget{video}{%
\subsection{Video}\label{video}}

The following video walks through some of the effect sizes, alpha, and power stuff.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=v1GrXJmUkBw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-2}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{power}{%
\section{Power}\label{power}}

\textbf{Power} is the probability that you will observe a significance effect if there is a true effect. In other words, power is the probability of a statistically significant result assuming the alternative hypothesis is true. Let's compare this to our definition of the p-value: the probability of observing data that is as extreme or more extreme than the data you have observed, assuming the null hypothesis is true.

Power can range from 0-100\%, but typically people set it at 80\%. However, in practice, power is often far lower than 80\%, something we'll investigate in the final section of this chapter and in the homework.

Power is based on the assumption that the alternative hypothesis is true whereas the \emph{p}-value is based on the assumption that the null hypothesis is true. If we want to increase the likelihood of supporting our alternative hypothesis, then we should be doing all we can to increase our power!

Let's start putting all this together.

\hypertarget{alpha-power-and-error-rates}{%
\subsection{Alpha, power, and error rates}\label{alpha-power-and-error-rates}}

Here's all our definitions so far (remember, we can never truly know whether the null or alternative hypothesis is true):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Alpha is the value we set at for what constitutes a statistically significant result, assuming the null hypothesis is true.
\item
  Power is the value we set at for what constitutes a statistically significant result, assuming the alternative hypothesis is true.
\item
  A type I error is when we get a statistically significant result but in fact the null hypothesis is true.
\item
  A type II error is when we do not get a statistically significant result but in fact the alternative hypothesis is true.
\item
  A correct inference is when we either

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    get a statistically significant result when the alternative hypothesis is true \emph{or}
  \item
    when we do not get a statistically significant result when the null hypothesis is true.
  \end{enumerate}
\end{enumerate}

In the following table, determine where each of the pieces should go. Note that we have six things to populate but only four cells: each cell must contain at least one of the six things. Think critically here before testing your answers!

\begin{longtable}[]{@{}lcc@{}}
\toprule
& H\textsubscript{0} is true & H\textsubscript{1} is true \\
\midrule
\endhead
\textbf{\emph{p}} \textbf{\textless{} .05} (statistically significant) & A & B \\
\textbf{\emph{p}} \textbf{\textgreater{} .05} (statistically non-significant) & C & D \\
\bottomrule
\end{longtable}

Which cell should each of the following items go?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  alpha
\item
  power
\item
  type I error
\item
  Type II error
\item
  Correct inference (hint: there are 2!)
\end{enumerate}

\hypertarget{playing-with-alpha-power}{%
\subsection{Playing with alpha \& power}\label{playing-with-alpha-power}}

We'll eventually see how power, alpha, effect sizes, and sample size all interrelate. For now, let's examine how alpha and power relate to one another in the context of hypothesis testing.

\hypertarget{assuming-the-null-hypothesis-is-100-true}{%
\subsubsection{Assuming the null hypothesis is 100\% true}\label{assuming-the-null-hypothesis-is-100-true}}

\emph{Assuming the null hypothesis is 100\% true}, we could fill in the table with actual numbers. Let's also use the arbitrary values we often set alpha and power at: alpha = 5\% and power = 80\%. Here's the resulting table:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.64}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.18}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.18}}@{}}
\toprule
& H\textsubscript{0} is true & H\textsubscript{1} is true \\
\midrule
\endhead
\textbf{\emph{p}} \textbf{\textless{} .05} (statistically significant) & 5\% & 0\% \\
\textbf{\emph{p}} \textbf{\textgreater{} .05} (statistically non-significant) & 95\% & 0\% \\
\bottomrule
\end{longtable}

How did I get there? First, we're assuming the null hypothesis is 100\% true. Therefore, that column must add up to 100\%. If the null hypothesis is 100\%--and we know our hypotheses must be mutually exclusive--then the alternative hypothesis must be 0\% true. Therefore, that column must add up to 0\%. The whole table must equal to 100\% to exhaust all options.

Therefore, our power doesn't matter at all in this case. If the null is true, then it doesn't matter what power we have to detect the alternative effect \emph{because the alternative effect does not exist}. So we instead use alpha and put it in the upper left cell. Note that our alpha level is the Type I error rate we are setting!

If the whole table must equal to 100\%, and the left column must equal to 100\% because the null is 100\% true, then 100-5 = 95\% for the correct inference. In other words, if we tested this effect (that doesn't exist) 100 times, around 95\% of the time we would get a non-significant p-value (\emph{p} \textgreater{} .05) and about 5\% of the time we would get a significant p-value and be making a Type I error.

We can visualize our \emph{p}-value distribution using this \href{https://rpsychologist.com/d3/pdist/}{handy interactive calculator}. We set our effect size (ES) to be \emph{d} = 0, meaning there is no effect (i.e., the null hypothesis is true). This results in a uniform distribution of p-values. Exactly 5\% of p-values would fall between \emph{p} = 0 and \emph{p} = .05 (the shaded region to the right of the red dotted line). That aligns with our Type I error rate as well (5\%). Go ahead and play around with the interactive calculator and try moving the slider for sample size! Notice that it does absolutely nothing. We'll understand why when we put everything together.

\includegraphics{images/05-bean/null.png}

\hypertarget{assuming-the-alternative-hypothesis-is-100-true}{%
\subsubsection{Assuming the alternative hypothesis is 100\% true}\label{assuming-the-alternative-hypothesis-is-100-true}}

Let's try out the opposite: assume the alternative hypothesis is 100\% true, alpha is 5\%, and power is 80\%. What would you put in the table?

\begin{longtable}[]{@{}lcc@{}}
\toprule
& H\textsubscript{0} is true & H\textsubscript{1} is true \\
\midrule
\endhead
\textbf{\emph{p}} \textbf{\textless{} .05} (statistically significant) & 0\% & 80\% \\
\textbf{\emph{p}} \textbf{\textgreater{} .05} (statistically non-significant) & 0\% & 20\% \\
\bottomrule
\end{longtable}

How did I get those numbers? First, remember that the table must equal to 100\% (hypotheses must be exhaustive). Second, remember that the alternative hypothesis is 100\% true so that column must equal to 100\% (and because hypotheses must be mutually exclusive, the other column must equal to 0\%).

Therefore, it doesn't matter what we set alpha to. We cannot get a Type I error if the alternative hypothesis is true! We can only get a correct inference or make a Type II error.

We set power to 80\%, and power is the probability of getting a statistically significant result assuming the alternative hypothesis is true. Therefore it goes in the top right cell. Notice that power is the probability of correctly detecting a statistically significant effect!

With simple arithmetic, 100-80 = 20\% is our Type II error. If we were to test for this effect 100 times, about 80 times we would correctly detect the effect and about 20 times we would fail to detect the effect.

Let's visualize this. Go back to our \href{https://rpsychologist.com/d3/pdist/}{handy interactive calculator} and put \emph{d} = .8 as our effect size and \emph{n} = 25 per group to our sample size. Notice now what our distribution of p-values looks like! Rather than a uniform distribution, now we have a steep exponential distribution. I have chosen to highlight all p-values in the range of \emph{p} \textgreater{} .05, which in that selection is roughly 20\% (our Type II error rate from above). The number of \emph{p}-values \textless{} .05 is roughly 80\%. Play again with the ES slider and sample size slider. Notice now that it makes a difference to our power! You're getting a glimpse into how power depends on our alpha, effect size, and sample size. BEAN!

\includegraphics{images/05-bean/alternative.png}

\hypertarget{assuming-a-5050-split-on-the-null-and-alternative-hypotheses}{%
\subsubsection{Assuming a 50/50 split on the null and alternative hypotheses}\label{assuming-a-5050-split-on-the-null-and-alternative-hypotheses}}

In reality, we never truly know whether the null or alternative hypotheses are true. Maybe we're testing a new effect and we are completely 50/50 of whether the null or alternative hypothesis is true. Let's keep our alpha and power the same (5\% and 80\%, respectively) and fill out our table now:

\begin{longtable}[]{@{}lcc@{}}
\toprule
& H\textsubscript{0} is true & H\textsubscript{1} is true \\
\midrule
\endhead
\textbf{\emph{p}} \textbf{\textless{} .05} (statistically significant) & 2.5\% & 40\% \\
\textbf{\emph{p}} \textbf{\textgreater{} .05} (statistically non-significant) & 47.5\% & 10\% \\
\bottomrule
\end{longtable}

How did we get there? Again: the table must equal to 100\% and we specified ahead of time that we thought it was about 50\% true for each of the hypotheses, so each column must equal to 50\%. 50\% of 5\% (alpha) is 2.5\% and 50\% of 80\% (power) is 40\%. We then fill out the bottom row based on arithmetic.

Imagine this were your study and you got a significant \emph{p}-value. What could you conclude? Either you reject the null hypothesis or fail to reject the null hypothesis. But which one? In reality, we never know, but there are things we can do to increase the likelihood that our statistically significant result is because the alternative hypothesis is true and not the null hypothesis.

Right now, based on the values we have set (alpha = 5\% and power = 80\%), it is \emph{16 times more likely} that the alternative hypothesis is true than the null hypothesis is true (40/2.5 = 16). You might be fine with that, but what can we do to increase this likelihood?

\hypertarget{increasing-power}{%
\subsubsection{Increasing power}\label{increasing-power}}

Let's try it again, but this time let's increase our power to 95\% and keep our alpha at 5\% (50/50 on the hypotheses). Fill out the table!

\begin{longtable}[]{@{}lcc@{}}
\toprule
& H\textsubscript{0} is true & H\textsubscript{1} is true \\
\midrule
\endhead
\textbf{\emph{p}} \textbf{\textless{} .05} (statistically significant) & 2.5\% & 47.5\% \\
\textbf{\emph{p}} \textbf{\textgreater{} .05} (statistically non-significant) & 47.5\% & 2.5\% \\
\bottomrule
\end{longtable}

Now it is \emph{19 times more likely} (47.5/2.5 = 19) that the alternative hypothesis is true than the null hypothesis is true. Awesome! We have now discovered that increasing power increases the likelihood our alternative hypothesis is true if we get a statistically significant result.

\hypertarget{decreasing-alpha}{%
\subsubsection{Decreasing alpha}\label{decreasing-alpha}}

Let's do another example in which we still have a 50/50 on the hypotheses but we reduce our alpha to 1\% and keep our power at 80\%. Fill out the table!

\begin{longtable}[]{@{}lcc@{}}
\toprule
& H\textsubscript{0} is true & H\textsubscript{1} is true \\
\midrule
\endhead
\textbf{\emph{p}} \textbf{\textless{} .05} (statistically significant) & .5\% & 40\% \\
\textbf{\emph{p}} \textbf{\textgreater{} .05} (statistically non-significant) & 49.5\% & 10\% \\
\bottomrule
\end{longtable}

Now it is \emph{80 times more likely} (40/.5 = 80) that the alternative hypothesis is true than the null hypothesis is true. Awesome! We have now discovered that decreasing alpha increases the likelihood our alternative hypothesis is true if we get a statistically significant result.

\hypertarget{your-turn-increasing-power-and-decreasing-alpha}{%
\subsubsection{Your turn: Increasing power AND decreasing alpha}\label{your-turn-increasing-power-and-decreasing-alpha}}

Let's see what happens when we both increase power AND decrease alpha. Fill out the table on your own. When we assume the null and alternative hypotheses are 50\% likely each, and we set our alpha to 1\% and our power to 95\%, how much more likely is it that the alternative hypothesis is true than the null hypothesis is true?

\hypertarget{video-1}{%
\subsection{Video}\label{video-1}}

The following walks through this power stuff some more.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=\_9ImSIP609I"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{sample-size-power-analysis}{%
\section{Sample size \& power analysis}\label{sample-size-power-analysis}}

Sample size is the total number of participants in a study. In a between-subjects study, we often describe how many participants are in each group; although it is best if there are equal numbers in each group, there are times when that may not be the case.

Often, the biggest question we want to know is: what sample size do I need for my study? Daniel Lakens has a great new \href{https://psyarxiv.com/9d3yf/}{preprint} out on the topic. We often cannot measure the entire population, but some other ways we can determine the sample size are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Resource constraints: sometimes time and budget limits our sample size
\item
  Accuracy or an \emph{a priori} power analysis: based on the statistical power we hope to achieve (which is in turn based on the effect size we expect)
\item
  Heuristics: some prespecified rule or norm that is described in the literature (to be avoided as much as possible)
\end{enumerate}

The first option is more of a research methods discussion and will not be discussed here. The third option is to be avoided as much as possible. Therefore, that leads us to the second option, which is to conduct an \emph{a priori} power analysis.

\hypertarget{bean-power-analysis}{%
\subsection{BEAN: Power analysis}\label{bean-power-analysis}}

We previously saw how alpha and power relate to one another. In the \href{https://rpsychologist.com/d3/pdist/}{interactive calculator} you also started to discover that effect sizes and sample size also relate to alpha and power. This is the power of the BEAN: if you know three out of the four of BEAN, you can determine the fourth. Power, effect sizes, alpha, and sample sizes all interrelate!

Typically, there are three things we may be interested in figuring out:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What sample size do I need given the effect size of interest, alpha level, and power level?
\item
  What power do I have to detect the effect size of interest given my alpha level and sample size?
\item
  What effect size can I reasonably detect given my alpha level, power level, and sample size?
\end{enumerate}

There is software out there to help you conduct power analyses. The most popular is \href{https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower.html}{G*Power}.

For our purposes, we're going to simplify things and use the jpower module in jamovi. This can calculate power for an independent samples t-test, a paired samples t-test, and a one-sample t-test. Our previous example in the last chapter (the Bobo doll experiment) has two groups in a between-subjects design. Next chapter you'll learn how to determine what statistical test you would perform, but for now I will just tell you that we would conduct an independent samples t-test with this experiment's data.

In the jpower module, choose your statistical test in the drop-down menu; in this case, let's choose independent samples t-test. Next, you specify what you want to calculate: your N per group (sample size), power, or effect size. It will grey out that box in the three boxes below. Let's discuss them in turn:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Minimally-interesting effect size: it shows the lower case Greek letter delta here, but we can essentially think of it as a Cohen's \emph{d} value. Go back to the effect size section for help in determining your smallest effect size of interest.
\item
  Minimum desired power: remember from the last section that when we increase power, we increase the likelihood of both obtaining statistically significant results \emph{and} the likelihood that a statistically significant result because the alternative hypothesis is true than that the null hypothesis is true.
\item
  N for group 1: this is the sample size in one of your two groups.
\item
  Relative size of group 2 to group 1: if your sample sizes are equal in both groups, leave it at 1. If they aren't, you need to figure out the ratio. For example, if one group is \emph{n} = 20 and the other is \emph{n}~= 40 then you would change this box to ``2''. You can easily calculate this by dividing \emph{n}\textsubscript{2} by \emph{n}\textsubscript{1}.
\item
  \(\alpha\) (type I error rate): remember from the last section that when we decrease power, we increase the likelihood of obtaining non-significant results when the null hypothesis is true \emph{and} increase the likelihood that a statistically significant result means the alternative hypothesis is true. You shouldn't increase it above .05, but you should consider whether it would be useful to decrease it in your case.
\item
  Tails: specify whether you have a two-tailed (non-directional) or one-tailed (directional) hypothesis.
\end{enumerate}

There are also options for four types of plots and whether to have explanatory text. For now, keep the explanatory text checked because it will help explain what is going on in the results. The plots are optional and I encourage you to check them out to see if they help you understand what is going on.

\hypertarget{power-analysis-example-1}{%
\subsection{Power analysis example \#1}\label{power-analysis-example-1}}

Let's return to our example that we used in our \href{https://rpsychologist.com/d3/pdist/}{interactive calculator} before. We are going to calculate Power, set our effect size at \(\delta\) = .8, N for group 1 at 25, Relative size of group 2 to group 1 at 1 (equal sample sizes), and \(\alpha\) (type I error rate) to .05. We'll assume we have a two-tailed hypothesis for now. You should get the following results. This table specifies that we defined the sample size, effect size, and alpha, which results in a power calculation of 79\%.

\includegraphics[width=3.67708in,height=\textheight]{images/05-bean/power-table.png}

The results also provide a useful explanation:

\begin{quote}
A design with a sample size of 25 in each group can detect effect sizes of 0.8 with a probability of at least 0.791, assuming a two-sided criterion for detection that allows for a maximum Type I error rate of a=0.05.
\end{quote}

This assumes that an effect size of .8 is the smallest effect size of interest. The next table shows us the power to detect various other effect sizes based on our alpha and sample size:

\begin{longtable}[]{@{}ccc@{}}
\toprule
True effect size & Power to detect & Description \\
\midrule
\endhead
0 \textless{} d = 0.566 & 50\% & Likely miss \\
0.566 \textless{} d = 0.809 & 50\% -- 80\% & Good chance of missing \\
0.809 \textless{} d = 1.041 & 80\% -- 95\% & Probably detect \\
d = 1.041 & 95\% & Almost surely detect \\
\bottomrule
\end{longtable}

In other words, we are almost sure to detect really large effect sizes (d \textgreater{} 1.04), but we'll likely miss really small effect sizes (d \textless{} .56). This gives us a good hint to the relationship among BEAN: holding alpha and sample size constant, as effect sizes go up power goes up.

The Power Contour plot can show a bit more about how power (color), effect size (y-axis) and sample size (x-axis) all relate to one another. Notice how the x-axis is not linear. We are learning some more about the relationship among BEAN: increasing our sample size increases our power, holding alpha and effect size constant.

\includegraphics[width=4.76042in,height=\textheight]{images/05-bean/power-contour.png}

The next two plots are basically the Power Contour plot, but they shift power to the y-axis and either show effect size or N on the x-axis.

The last plot (Power Demonstration) helps us visualize our Type I and Type II errors and correct inferences nicely. The purple distribution is our null hypothesis distribution (centered at \emph{d} = 0) and the green distribution is our alternative hypothesis distribution (centered at \emph{d}~= .8). The vertical dashed lines are the critical values of obtaining \emph{p} \textless{} .05 on either side of the null distribution (so 2.5\% on either side). The dark green area is therefore our power (80\%) and the dark purple areas are our Type I error rate (5\%). The light green area to the left of the dashed line is our Type II error rate (20\%) and the light purple area is the probability of a correct inference assuming the null is true (95\%). Keep in mind that these are the distributions of \emph{both} hypotheses though, and in reality only one is true. We can just never know which is true; we can at best approximate it through repeated testing of effects.

\includegraphics[width=5.55208in,height=\textheight]{images/05-bean/power-demo.png}

\hypertarget{play-with-jpower}{%
\subsection{Play with jpower}\label{play-with-jpower}}

Play around some more with jpower. Try calculating other things (e.g., sample size or effect size). Play with power and see what increasing it does to your effect size and sample size. Play with effect sizes and see what decreasing them does to your power and sample size. Play with alpha (don't go higher than .05) and see what that does to your power, effect size, and sample size. And lastly, play with your sample size and see what it does to your power and effect size.

Your assignments for this unit will have you conduct power analyses based on various scenarios, so playing around with jpower will help prepare you for them.

\hypertarget{inferential-statistics}{%
\chapter{Inferential statistics}\label{inferential-statistics}}

We've learned about hypothesis testing for inferential statistics two chapters ago and learned about some specific components of statistical testing in the last chapter. We have alluded to the fact that there are multiple inferential statistics we can perform, and that is the purpose of this chapter.

Although there are many more types, we are going to cover two basic types of inferential statistics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Parametric statistics}, which have an assumption of normal distribution
\item
  \textbf{Non-parametric statistics}, which have no assumptions about the distribution of the data
\end{enumerate}

\hypertarget{choosing-the-correct-statistical-test}{%
\section{Choosing the correct statistical test}\label{choosing-the-correct-statistical-test}}

It is important that you learn how to identify \emph{which} inferential statistic you should perform. This chart can help you determine what statistical test to perform. Note that on the right dark red boxes are parametric tests, light red boxes are non-parametric tests, and white boxes will not be covered in this class at all (in fact, there are many others not even shown that we won't cover!). Data types are indicated in either blue (continuous), green (categorical), or teal (both). Number of variables or levels of the variables are either 1 (light orange), 2/2+ (orange), or 3+ (dark orange). Between-subjects designs, meaning designs with different participants in each group, are in black whereas within-subjects designs, meaning designs with the same participants in each group, are in light grey.

\includegraphics{images/Statistical Choices.png}

Note: if you are a student in PSYC 290 or 790, you have access to a high-resolution PDF of this chart on Canvas.

First, you need to determine what level of measurement your dependent variable (DV) is. We will only be covering statistical tests that have \emph{one} dependent variable. Therefore, you need to know whether the variable is categorical (i.e., nominal or ordinal) or it's continuous (i.e., interval or ratio).

Next, you need to determine how many independent variables (IVs) there are and then what level of measurement your IV(s) are. In the case of a single categorical IV, we also need to know how many levels there are to the IV (i.e., how many categories there are). For categorical variables, we also need to know if the participants are different (i.e., between-subjects) or the same (i.e., within-subjects) within each level of the category.

Lastly, for many of the statistical tests we need to know whether we meet the assumptions of parametric tests. If we don't meet the assumption, then there are alternative tests we can perform. We'll learn about assumption checking in the next section of this chapter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=Q9sbIMCck1Q"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

We can both \emph{forward map} and \emph{backwards map} with the chart above. Forward mapping involves understanding your data and your research question and then determining what statistical test to perform. Forward mapping is mostly what you need to understand how to do! Backwards mapping involves determining what kind of data is needed to perform a particular statistical test. This is more for educational and understanding purposes and generally is not how you analyze data.

Let's do some examples of forwards mapping. You may want to read the example and try your hand at it first and then check your answers!

\hypertarget{forward-mapping-choose-the-correct-test}{%
\subsection{Forward mapping: Choose the correct test}\label{forward-mapping-choose-the-correct-test}}

A researcher is interested in understanding whether athletes have higher English scores than non-athletes. In other words, what is the effect of athletic status on English test scores?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What is the DV? What is the level of measurement? It's English test scores, which is a continuous variable.
\item
  How many IVs are there? We only have one IV, and it is athletic status.
\item
  What is the level of measurement of the IV? Athletic status is a categorical variable.
\item
  How many categories to the IV? Athletic status is measured as either athlete or non-athlete, so there are 2 levels.
\item
  Are the same or different participants used in each category? People can either be an athlete or not an athlete, but they can't be both, so this is a between-subjects variable (aka ``different'').
\item
  Do data meet the assumptions for parametric tests? We don't know. We would need to test this. For now, let's assume we meet the assumptions.
\item
  Statistical test? Independent t-test
\end{enumerate}

A researcher is interested to know whether people perform better on the exam at the start, middle, or end of the semester. The researchers has all participants complete all three exams.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What is the DV? What is the level of measurement? In this case, the exam is our DV and it's a continuous variable.
\item
  How many IVs are there? We only have one IV, and it is time of the exam.
\item
  What is the level of measurement of the IV? The time of the exam is a categorical variable.
\item
  How many categories to the IV? Type of test has three categories: start, middle, or end of the semester.
\item
  Are the same or different participants used in each category? Although the researcher could have designed a between-subjects design, this particular study has all participants participate in all conditions, so it is a within-subjects design (aka ``same'').
\item
  Do data meet the assumptions for parametric tests? We don't know. We would need to test this. For now, let's assume we meet the assumptions.
\item
  Statistical test? One-way repeated measures ANOVA
\end{enumerate}

\hypertarget{backwards-map-determine-the-data-you-need}{%
\subsection{Backwards map: Determine the data you need}\label{backwards-map-determine-the-data-you-need}}

Let me start off by saying we don't normally do this. We perform the test based on the data we have. But in our learning, we also want to ensure we learn all the tests. Imagine I gave you a dataset and wanted you to perform two different tests that I told you about.

Here are the variables in the dataset:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Mile time (continuous variable ranging from 5-30 minutes)
\item
  BMI (categorical variable of underweight, normal, or overweight)
\item
  Happiness at the start of the semester (continuous variable ranging from 0-10)
\item
  Happiness at the end of the semester (continuous variable ranging from 0-10)
\end{enumerate}

If I told you I wanted you to perform a dependent t-test, what data would you use?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Assuming we meet the assumptions for a parametric test, we need to find a situation in which we have 1 continuous variable and 1 categorical variable with 2 levels in which participants are the \emph{same} within each category (i.e., within-subjects variable).
\item
  We only have three continuous variables: mile time and our two happiness variables.
\item
  If we rethink happiness, we can realize that it's really a within-subjects variable. We are measuring happiness (our continuous DV) across two time points (start and end of the semester).
\item
  Therefore, we could perform a dependent t-test with our two happiness data points and see whether happiness differs across time in the semester.
\end{enumerate}

If I told you I wanted you to perform a one-way independent ANOVA, what data would you use?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Assuming we meet the assumptions for a parametric test, we need to find a continuous DV and a single categorical IV with 3 or more levels in which participants are \emph{different} across categories (i.e., between-subjects design).
\item
  We only have three continuous variables: mile time and our two happiness variables.
\item
  We only have one categorical variable (BMI), and it has 3 levels: underweight, normal, overweight.
\item
  Now this is where we need to think critically. What would be the most interesting test here? How BMI affects happiness or how BMI affects mile time? Weight and performance on running a mile seem to make most sense here. Therefore, we could look at how BMI affects mile time. Though keep in mind we are not randomizing here and so this is \emph{not} an experimental design!
\end{enumerate}

\hypertarget{checking-assumptions}{%
\section{Checking assumptions}\label{checking-assumptions}}

There are four basic assumptions of most parametric tests:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Normal distribution
\item
  Interval or ratio (i.e., continuous) dependent variable
\item
  Homogeneity of variances
\item
  Independent scores
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=tNojQp7DQt8"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

Let's discuss these in turn and how to test for them.

\hypertarget{normal-distribution-1}{%
\subsection{Normal distribution}\label{normal-distribution-1}}

For all our statistics, our dependent variable needs to be normally distributed.\footnote{Technically, it's that the \emph{residuals} need to be normally distributed, but in the case of t-tests and ANOVAs the results are the same if we test for normality of residuals or the dependent variable.} We have already covered what the normal distribution is multiple times, so let's move on to how to test for normality. There are four ways to test for normality \textbf{and we should test for normality using as many tests as we possibly can!}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Visualize the distribution
\item
  Test the skew and kurtosis
\item
  Conduct a Shapiro-Wilk test
\item
  Visualize the Q-Q plot
\end{enumerate}

\hypertarget{visualize-the-distribution}{%
\subsubsection{VIsualize the distribution}\label{visualize-the-distribution}}

In jamovi, we can go to the Explorations option and choose Descriptives. Under Plots, we can choose a histogram and/or density plot (figure on the left) or boxplot and/or violin plot and/or data points (figure on the right). We can just look at this data and visually inspect with our eyes whether the data is normally distributed. Height looks pretty fairly normally distributed in this case.

\includegraphics[width=4.16667in,height=\textheight]{images/06-inferential/histogram.png}

\includegraphics[width=4.16667in,height=\textheight]{images/06-inferential/boxplot.png}

\hypertarget{test-the-skew-and-kurtosis}{%
\subsubsection{Test the skew and kurtosis}\label{test-the-skew-and-kurtosis}}

In jamovi, we can go to the Explorations option and choose Descriptives. Under statistics, choose skew and kurtosis. You'll have to do a bit more work to actually figure out whether the skew and kurtosis is problematic though.

For height, here is our skew and kurtosis:

\begin{longtable}[]{@{}ll@{}}
\toprule
& \\
\midrule
\endhead
\textbf{Descriptives} & \textbf{Height} \\
Skewness & .230 \\
Std. error skewness & .121 \\
Kurtosis & .113 \\
Std. error kurtosis & .241 \\
\bottomrule
\end{longtable}

We need to calculate \emph{z}-scores for skew and kurtosis. We do that by dividing the value by its standard error:

\begin{itemize}
\item
  Skew: .230 / .121 = 1.90
\item
  Kurtosis: .113 / .241 = .47
\end{itemize}

How do we know if it's problematic? \textbf{If the \emph{z}-score for skew or kurtosis are less than \textbar1.96\textbar{} then it is \emph{not} statistically significant and \emph{is} normally distributed.} However, if the \emph{z} \textgreater{} \textbar1.96\textbar{} then it \emph{is} statistically significant and \emph{is not} normally distributed. In this case, both skew and kurtosis z-scores are less than 1.96 so we meet the assumption of normal distribution as evidenced by skew and kurtosis.

\hypertarget{shapiro-wilk-test}{%
\subsubsection{Shapiro-Wilk test}\label{shapiro-wilk-test}}

In jamovi, we can go to the Explorations option and choose Descriptives. Under statistics, choose Shapiro-Wilk. It will provide you the Shapiro-Wilk W test statistic and its respective p-value. In our case, Shapiro-Wilk's for height is 68.03, \emph{p} = .070. \textbf{If the Shapiro-Wilk's test is \emph{not} statistically significant then it \emph{is} normally distributed.} However, if the Shapiro-Wilk's test \emph{is} statistically significant then it \emph{is not} normally distributed. In this case, our Shapiro-Wilk's test is not statistically significant so we meet the assumption of normal distribution as evidenced by the Shapiro-Wilk's test.

\hypertarget{q-q-plot}{%
\subsubsection{Q-Q plot}\label{q-q-plot}}

Last, we can visualize the Q-Q plot. In jamovi, we can go to the Explorations option and choose Descriptives. Under plots, choose Q-Q plot. We don't need to go into details of what is being visualized, but what we are looking for is that the data points fall along the diagonal line. On the figure on the left, we can see that the data is pretty well falling on the diagonal line (with small deviations at the tails) so we can say it looks normally distributed. However, on the figure on the right, the data points deviate from the diagonal line pretty significantly and so we can say it does not look normally distributed.

\includegraphics{images/06-inferential/qqplot.png}

Remember we should look at all pieces of evidence to determine whether we meet the assumption of normal distribution. Typically, all four will support each other, but there are times when some evidence contradicts other evidence. You'll have to use your best judgment there, and often the visual inspection is the one I prioritize (e.g., if it doesn't look normally distributed but then the other tests suggest it is, I would probably be cautious and just say we don't meet the assumption).

\hypertarget{intervalratio-data}{%
\subsection{Interval/ratio data}\label{intervalratio-data}}

If we are performing a test that has a continuous DV, then the variable must be measured at the interval or ratio level. It is important that the data has proportional intervals between levels of the variable, and ordinal variables often do not meet this assumption.

It is very important to avoid treating ordinal variables as continuous variables. We cannot calculate a mean or difference between ordinal values, but we \emph{can} for continuous variables. What is often done--and is often inappropriate to do--is treat Likert-scale items as a continuous DV. What we \emph{can} do is take a sum or average of multiple Likert-scale items and treat that sum or average as a continuous DV.

There is no ``test'' we can perform here. Rather, you will need to improve in recognizing whether data is interval/ratio (continuous) or ordinal (categorical).

\hypertarget{homogeneity-of-variance}{%
\subsection{Homogeneity of variance}\label{homogeneity-of-variance}}

Our third assumption is that the variance in the DV needs to be the same at each level of the IV. If we fail to meet the assumption, we say we have heterogeneity. It might help you to remember that the prefix \emph{homo} means same and \emph{hetero} means different.

We can test this assumption in two ways.

\hypertarget{visualize-the-distribution-of-data-across-groups}{%
\subsubsection{Visualize the distribution of data across groups}\label{visualize-the-distribution-of-data-across-groups}}

First, we can look at the data points across groups. This can be done by choosing a plot in the Descriptives analysis and adding your IV to the ``Split By'' box. For example, here's an example of data that violates the assumption of homogeneity of variance (gender by mile time):

\includegraphics[width=5.20833in,height=\textheight]{images/06-inferential/homogeneity.png}

Similarly, the variance for Gender == 0 (male) is 6796.20 whereas the variance for Gender == 1 (female) is 15401.55. Clearly, there is much greater variability for females than males for time it takes to run the mile.

\hypertarget{levenes-test}{%
\subsubsection{Levene's test}\label{levenes-test}}

When we perform inferential statistics that have the assumption of homogeneity of variance, in jamovi there will be a check box to check the assumption. It will perform Levene's test. Here's the result of Levene's test for the independent t-test examining the effect of gender on mile duration:

\begin{longtable}[]{@{}lrrrr@{}}
\toprule
Levene's & F & df1 & df2 & p \\
\midrule
\endhead
MileMinDur & 41.33 & 1 & 381 & \textless.001 \\
\bottomrule
\end{longtable}

Like the other tests above, \textbf{a non-significant Levene's test means we meet the assumption of homogeneity of variance.} However, if Levene's test is statistically significant, then we fail to meet the assumption of homogeneity of variance and have heterogeneity of variance. In this case, our test is statistically significant so, in combination with our plot above, we say we violated this assumption.

\hypertarget{independent-scores}{%
\subsection{Independent scores}\label{independent-scores}}

In between-subjects designs (e.g., the independent t-test or one-way ANOVA), data from different participants should be independent meaning that the response of one participant does not influence the response of another participant. We violate this assumption in the case of nested data (e.g., when our sample consists of students in three different classrooms, it is likely that students within classrooms are more similar than we would expect otherwise).

In within-subjects designs (e.g., the dependent t-test or repeated measures ANOVA), we automatically violate the assumption because \emph{of course} the scores of one participant in one condition will relate to their scores on another condition. However, their scores should still not influence any other participant's response.

This is another assumption, like interval/ratio data, that we do not ever \emph{test} but is a function of knowing our data.

\hypertarget{violated-assumptions}{%
\section{Violated assumptions}\label{violated-assumptions}}

What do you do if you have violated assumptions? Let's first talk about the assumptions we don't test (interval/ratio data and independent scores) before we turn to the other two assumptions (normality and homogeneity of variance).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=ypF1omeM{-}7g"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{intervalratio-data-1}{%
\subsection{Interval/ratio data}\label{intervalratio-data-1}}

If you are trying to perform a statistical test with a categorical DV, the answer is simple: perform the test that requires a categorical DV and do not try to treat it as continuous. For example, if you have an ordinal DV and a categorical IV, you can perform a chi-square. If you have an ordinal DV and a continuous IV, you can perform a logistic regression (we won't be covering that in this class). Go back to the section on choosing the correct statistical test and you'll see four options of statistical tests that can be performed with a categorical DV.

\hypertarget{independent-data}{%
\subsection{Independent data}\label{independent-data}}

We won't be covering it in this class, but if you violate this assumption then you need to use a statistical test that accounts for nested data or can correlate the errors among dependent data. For example, multilevel modeling (aka hierarchical modeling) is one approach.

\hypertarget{normality-or-homogeneity-of-variance}{%
\subsection{Normality or homogeneity of variance}\label{normality-or-homogeneity-of-variance}}

If you violate either normality or homogeneity of variance, there are a few options you can choose.

\hypertarget{remove-outliers}{%
\subsubsection{Remove outliers}\label{remove-outliers}}

First, double check that you do not have any outliers. How do you know if data is an outlier? To look for outliers in single variables (aka univariate outliers), you can just look at your data. To look for multivariate outliers (outliers across multiple variables), you can look at Mahalanobis distance or Cook's distance, which you would need to use the Rj editor to perform in jamovi and we won't cover in this class.

What can you do in case of outliers?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ignore them, but this is not a good solution
\item
  Delete the outlier cases, but this is not recommended either because you lose data and we now know how important it is to have a large sample size
\item
  Winsorize, trim, or modify your data, especially if there are only a few outliers
\item
  Transform the variable, especially if there are a lot of outliers
\end{enumerate}

\hypertarget{winsorize-or-trim-the-data}{%
\subsubsection{Winsorize or trim the data}\label{winsorize-or-trim-the-data}}

Winsorizing is used when both tails of the distribution have outliers whereas trimming is used when it's just one or a few outliers on one side of the distribution. In both cases, we replace the extreme valuse with the next-most-extreme values. There's more to Winsorizing than what I've described here, so I encourage you to learn more if you are interested.

We can do this through the Transform feature on jamovi. For example, here's what it looks like to trim the Reading variable to get rid of the few scores on the far left of the histogram. We want to take those values less than 60 and replace their scores with a new score of 60.

\includegraphics{images/03-jamovi/winsorize.png}

\hypertarget{transforming-data}{%
\subsubsection{Transforming data}\label{transforming-data}}

If we violate the assumption of normality or homogeneity of variance (or both!) then we can explore whether transformations of the entire variable can improve the normality of our data. There are a variety of different transformations you can try, and here's a list of a few:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.10}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.28}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.20}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.20}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.22}}@{}}
\toprule
Name & Syntax & Corrects for positive skew? & Corrects for negative skew? & Corrects for unequal variances? \\
\midrule
\endhead
Log & log(X) & Yes & No & Yes \\
Square Root & sqrt(X) & Yes & No & Yes \\
Reciprocal & 1/X & Yes & No & Yes \\
Reverse Score & \vtop{\hbox{\strut (1+MAX) - X}\hbox{\strut then do one of the above transformations}} & No & Yes & No \\
\bottomrule
\end{longtable}

When you perform a transformation, then you need to check whether the transformation actually improved the situation. How do you do that? Check normality and homogeneity of variance again with your newly transformed data! You should check with the 4 methods to test for normality and 2 methods to test for homogeneity of variance.

\hypertarget{non-parametric-tests}{%
\subsubsection{Non-parametric tests}\label{non-parametric-tests}}

If all else fails--meaning there are no outliers or no transformations fix the violated assumption(s)--then you can perform a non-parametric test. These tests have \emph{no} assumption of normally distributed data or homogeneity of variance! As you saw in the chart about choosing the correct statistical test, many of our parametric tests have non-parametric equivalents.

When we cover each individual statistical test (e.g., independent t-test) we will also cover its non-parametric equivalent (e.g., Mann-Whitney test). So stay tuned and just remember you have this option if you violate assumptions!

\hypertarget{t-tests}{%
\chapter{t-tests}\label{t-tests}}

The t-test looks at difference in means between two things (e.g., groups, time, observations). There are three different types of t-tests:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \textbf{one-sample t-test} tests how the sample mean relates to the population mean.
\item
  The \textbf{independent t-test} has two \emph{independent} groups. The participants or things in group 1 are \emph{not} the same as the participants or things in group 2. This is a between-subjects design in which different participants are in the two groups.
\item
  The \textbf{dependent t-test} has \emph{dependent} or \emph{paired} data. The dependent variable is measured at two different times or for two different conditions for all participants or things. This is a within-subjects design in which case the same participants are in both groups.
\end{enumerate}

\hypertarget{one-sample-t-test}{%
\section{One sample t-test}\label{one-sample-t-test}}

\hypertarget{overview}{%
\subsection{Overview}\label{overview}}

The one-sample t-test is used to test the difference between our sample's mean on the dependent variable and the mean of the population.

There are three different types of alternative hypotheses we could have for the one sample t-test:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Two-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): The sample mean has a different mean than the population mean.
  \item
    \(H_0\): There is no difference in means between the sample and population.
  \end{itemize}
\item
  \textbf{One-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): The sample has a greater mean than the population.
  \item
    \(H_0\): The mean for the sample is less than or equal to the mean for the population.
  \end{itemize}
\item
  \textbf{One-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): The sample has a smaller mean than the population.
  \item
    \(H_0\): The mean for the sample is greater than or equal to the mean for the population.
  \end{itemize}
\end{enumerate}

This is also the first time we'll be doing the full hypothesis testing procedures!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Specify the hypotheses
\item
  Look at the data
\item
  Check assumptions
\item
  Perform the test
\item
  Interpret results
\end{enumerate}

\hypertarget{specify-the-hypotheses}{%
\subsection{Specify the hypotheses}\label{specify-the-hypotheses}}

For this chapter, we're going to work with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``zeppo''. This dataset is hypothetical data of 20 psychology students taking Dr.~Zeppo's introductory statistics class. Dr.~Zeppo wants to know if the psychology students tend to get the same grade as everyone else (\emph{M} = 67.5) or whether they get a higher or lower grade. As students in a psychology course, we're going to assume psychology students get higher grades.

First, it may be useful to understand what our dependent and independent variables are. Our dependent variable is the outcome variable, and in this case it's the grade students get in the course. Our independent variable that is presumed to ``cause'' the outcome, and in this case it's our sample of psychology students whom we're comparing to our population of all students.

Therefore our hypotheses can be written up as such:

\begin{itemize}
\tightlist
\item
  \(H_1\): Psychology students get higher grades than the population of Dr.~Zeppo's students.
\item
  \(H_0\): There is no difference in student grades between psychology students and the population of Dr.~Zeppo's students.
\end{itemize}

Relatedly, we want to be clear about our alpha value. We'll stick with the norm of \(\alpha\) = .05. Therefore, for our results to be statistically significant we want our \emph{p}-value to be less than our \(\alpha\) and so we want \emph{p} \textless{} .05.

\hypertarget{look-at-the-data}{%
\subsection{Look at the data}\label{look-at-the-data}}

If you learn one thing through this course, it is that \emph{you should always look at your data!!!} Descriptive and inferential statistics can sometimes hide weird things with your data, so it's incredibly important you look at it first.

\hypertarget{data-set-up}{%
\subsubsection{Data set-up}\label{data-set-up}}

To conduct the independent t-test, we first need to ensure our data is set-up properly in our dataset. This requires having two columns: one with our continuous dependent variable and one indicating which group the participant is in. Each row is a unique participant or unit of analysis.

Below is the first ten rows of our data from the zeppo dataset.

\includegraphics{images/07.1-one_sample_t-test/data.png}

\hypertarget{describe-the-data}{%
\subsubsection{Describe the data}\label{describe-the-data}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. Our overall data consists of 20 cases and the students in our dataset have a mean grade of 72.30 (\emph{SD} = 9.52). The minimum and maximum values look accurate; theoretically, student grades should range from 0-100. Lastly, the distribution of data looks possibly not normally distributed. Although we have a pretty small sample size, we can proceed with our analyses. First, though, we need to check our assumptions.

\includegraphics{images/07.1-one_sample_t-test/descriptives.png}

\includegraphics[width=5.44792in,height=\textheight]{images/07.1-one_sample_t-test/plot.png}

\hypertarget{check-assumptions}{%
\subsection{Check assumptions}\label{check-assumptions}}

\hypertarget{assumptions}{%
\subsubsection{Assumptions}\label{assumptions}}

As a parametric test, the independent t-test has the same assumptions as other parametric tests (minus homogeneity of variance):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The dependent variable is \textbf{normally distributed}
\item
  The dependent variable is \textbf{interval or ratio} (i.e., continuous)
\item
  Scores are \textbf{independent} between groups
\end{enumerate}

We cannot test the second and third assumptions; rather, those are based on knowing your data.

However, we can and should test for the first assumption. Fortunately, the independent samples t-test in jamovi has two check boxes under ``Assumption Checks'' that lets us test for normality.

\hypertarget{checking-assumptions-1}{%
\subsubsection{Checking assumptions}\label{checking-assumptions-1}}

One thing to keep in mind in all statistical software is that we often check assumptions simultaneously to performing the statistical test. However, we should always check assumptions first before looking at and interpreting our results. Therefore, whereas the instructions for performing the test are below, we discuss checking assumptions here first to help ingrain the importance of always checking assumptions for interpreting results.

\hypertarget{testing-normality}{%
\paragraph{Testing normality}\label{testing-normality}}

jamovi easily allows us to check for normality using the Shapiro-Wilk test and the Q-Q plot. The Shapiro-Wilk test was not statistically significant (W = .96, \emph{p} = .586); therefore, this indicates the data is normally distributed. Furthermore, the lines are fairly close to the diagonal line in the Q-Q plot. We can conclude that we satisfy the assumption of normality.

\includegraphics{images/07.1-one_sample_t-test/normality.png}")

Remember that we can also test for normality by \textbf{looking at our data} (e.g., a histogram or density plot, which you can see above) and by examining \textbf{skew and kurtosis}. However, you will need to view them using Exploration --\textgreater{} Descriptives, not in the t-tests menu. Here is our skew and kurtosis:

\begin{itemize}
\item
  \textbf{Skew}: \(-.53/.51 = -1.04\)
\item
  \textbf{Kurtosis}: \(.07/.99 = .07\)
\end{itemize}

Remember that we divide the value by its standard error to determine the z-score. If the absolute value of it is below 1.96 then we assume it is normally distributed. Both skew and kurtosis meet the assumption of normality. In addition, so did all our other pieces of evidence of normality: Shapiro-Wilk's, visual examination of the distribution, and the Q-Q plot. Therefore we can assume we met the assumption of normality.

\hypertarget{perform-the-test}{%
\subsection{Perform the test}\label{perform-the-test}}

Now that we've satisfied the assumptions, we can perform the one sample t-test. Here are the steps for doing so in jamovi:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to the Analyses tab, click the T-Tests button, and choose ``One Sample T-Test''.
\item
  Move your dependent variable \texttt{x} to the Dependent Variables box.
\item
  Under Tests, select \texttt{Student\textquotesingle{}s}. We'll learn about Wilcoxon rank when we discuss violated assumptions.
\item
  Under Hypothesis, input the population mean. In our case, it is \texttt{67.5} (this is the mean given to us by Dr.~Zeppo). Also, select the hypothesis that matches your hypothesi. In our case, select \texttt{\textgreater{}\ Test\ value} because we believe psychology students have a higher mean than the test value (population mean).
\item
  Under Additional Statistics, select \texttt{Mean\ difference}, \texttt{Effect\ size}, \texttt{Descriptives}, and (optionally) \texttt{Descriptives\ plots}.
\item
  Under Assumption Checks, select both options: \texttt{Normality\ test} and \texttt{Q-Q\ plot}.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics{images/07.1-one_sample_t-test/setup.png}

\hypertarget{interpret-results}{%
\subsection{Interpret results}\label{interpret-results}}

Once we are satisfied we have satisfied the assumptions for the independent t-test, we can interpret our results.

\includegraphics{images/07.1-one_sample_t-test/results.png}

Our p-value is less than our alpha value of .05, so our results are statistically significant. Like most of the statistics we'll come across, the larger the t-statistic (or F-statistic, or chi-square statistic\ldots), the smaller the p-value will be. Therefore, we reject our null hypothesis that the population mean is less than or equal to the sample mean of psychology students.

However, remember what we've learned in the previous chapters! We rejected the null hypothesis, but there's always the chance that we've made a type 1 error.

\hypertarget{write-up-the-results-in-apa-style}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style}}

When writing up the results of a statistical test, we should always include the following information:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Description of your research question and/or hypotheses.
\item
  Description of your data. If you fail to meet assumptions, you should specify that and describe what test you chose to perform as a result.
\item
  The results of the inferential test, including what test was performed, the test value and degrees of freedom, p-value, and effect size.
\item
  Interpretation of the results, including any other information as needed.
\end{enumerate}

We can write up our results in APA something like this:

\begin{quote}
Dr.~Zeppo's psychology colleague hypothesized that his psychology students have a higher grade than the population of his students. Psychology students (\emph{M} = 72.30, \emph{SD} = 9.52, \emph{n} = 20) had significantly higher grades than the population of Dr.~Zeppo's students (\emph{M} = 67.50), \emph{t} (19) = 2.25, \emph{p} = .046, \emph{d} = .50.
\end{quote}

Let's analyze that against the 4 things we need to report:

\begin{quote}
\textbf{\#1} Dr.~Zeppo's psychology colleague hypothesized that his psychology students have a higher grade than the population of his students. \textbf{\#4} Psychology students \textbf{\#2} (\emph{M} = 72.30, \emph{SD} = 9.52, \emph{n} = 20) \textbf{\#4} had significantly higher grades than the population of Dr.~Zeppo's students (\emph{M} = 67.50), \textbf{\#3} \emph{t} (19) = 2.25, \emph{p} = .046, \emph{d} = .50.
\end{quote}

Note that this is not the only way we can write up the results in APA format. The key is that we include all four pieces of information as specified above.

Also note that the M, SD, n, t, p, and d are all italicized! This is an important part of APA style to remember.

\hypertarget{visualize-the-results}{%
\subsubsection{Visualize the results}\label{visualize-the-results}}

By selecting \texttt{Descriptives\ plots} in the setup, you get the figure below. Personally, I don't think this is a very good plot. It's not very informative. It just provides the mean (circle), 95\% confidence interval (blue bars), and the median.

\includegraphics{images/07.1-one_sample_t-test/results-plot.png}

Another default option in jamovi is via the Descriptives analysis. You can ask for the boxplot, violin plot, and data of your dependent variable split by your independent variable. This is a much better option. Not only does it show us our mean (black bars) and interquartile range (via the boxplot), but it also shows our distribution (violin plot) and data points (grey dots). This is much more informative. You can see this in the \emph{Look at your data} section above. I would prefer to see the graph at the beginning of this chapter than the one that jamovi provides in your analysis.

\hypertarget{in-case-of-violated-assumptions}{%
\subsection{In case of violated assumptions}\label{in-case-of-violated-assumptions}}

If you fail to meet the assumption of normality, and no transformation fixes the data, then you can use the Wilcoxon W test.

The Wilcoxon W is not calculated based on the mean but rather the median. It has no assumptions about the distribution of data. Therefore, it is a non-parametric test. Here is what the output for the student's t-test and Wilcoxon W look like in jamovi:

\includegraphics{images/07.1-one_sample_t-test/wilcoxon.png}

To conduct this in jamovi, under Tests select \texttt{Wilcoxon\ W}. You will interpret the results similarly to the one sample t-test:

\begin{quote}
Dr.~Zeppo's psychology colleague hypothesized that his psychology students have a higher grade than the population of his students. Using a Wilcoxon W test, psychology students (\emph{Mdn} = 75.00, \emph{SD} = 9.52, \emph{n} = 20) had a higher grade than the population of Dr.~Zeppo's students (\emph{M} = 67.5), \emph{W} = 161, \emph{p} = .038, \(r_{bn}\) = .53.
\end{quote}

Note that we no longer report the mean but rather the median. That is because Wilcoxon W is based on the median, not the mean score.

\hypertarget{additional-information}{%
\subsection{Additional information}\label{additional-information}}

\hypertarget{positive-and-negative-t-values}{%
\subsubsection{Positive and negative t values}\label{positive-and-negative-t-values}}

Students often worry about positive or negative t-statistic values and are unsure how to interpret it. Positive or negative t-statistic values simply occur based on which group is listed first. Our t-statistic above is positive because we tested the difference between our sample and the population: (sample - population) = (72.3 - 67.5) = 4.80.

However, if our sample and population means were reversed, our mean difference would -4.80 and our t-statistic would be -2.25.

All that is to say, \emph{your positive or negative t-statistic is arbitrary}. So do not fret!

One last note: this positive or negative t-statistic is only relevant for the t-test. You will not get negative values for the F-statistic or chi-square tests!

\hypertarget{your-turn}{%
\subsection{Your turn!}\label{your-turn}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

Perform one sample t-tests based on the following research questions. Think critically about whether you should be using a one-tailed or two-tailed hypothesis and check your assumptions so you know which test to use!

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Do the students in our dataset have a higher Writing score than the passing score (\emph{M} = 70)?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis?
  \item
    Which statistic should you use based on your assumptions?
  \item
    Do the students in our dataset have a higher Writing score than the passing score?
  \end{itemize}
\item
  \textbf{Do the students in our dataset have the same national average height of college students (\emph{M} = 68 inches)?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis?
  \item
    Which statistic should you use based on your assumptions?
  \item
    Do the students in our dataset have the same national average height of college students)?
  \end{itemize}
\end{enumerate}

\hypertarget{independent-t-test}{%
\section{Independent t-test}\label{independent-t-test}}

\hypertarget{overview-1}{%
\subsection{Overview}\label{overview-1}}

The independent t-test is used to test the difference in our dependent variable between two different groups of observations. Our grouping variable is our independent variable. In other words, we use the independent t-test when we have a research question with a \textbf{continuous dependent variable} and a \textbf{categorical independent variable with two categories in which \underline{different} participants are in each category}.

The independent t-test is also called the independent samples t-test and the Student's t-test.

There are three different types of alternative hypotheses we could have for the independent t-test:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Two-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): Group 1 has a different mean than Group 2.
  \item
    \(H_0\): There is no difference in means between the two groups.
  \end{itemize}
\item
  \textbf{One-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): Group 1 has a greater mean than Group 2.
  \item
    \(H_0\): The mean for Group 1 is less than or equal to the mean for Group 2.
  \end{itemize}
\item
  \textbf{One-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): Group 1 has a smaller mean than Group 2.
  \item
    \(H_0\): The mean for Group 1 is greater than or equal to the mean for Group 2.
  \end{itemize}
\end{enumerate}

\hypertarget{specify-your-hypotheses}{%
\subsection{Specify your hypotheses}\label{specify-your-hypotheses}}

For this chapter, we're going to work with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``Harpo''.This dataset is hypothetical data of 33 students taking Dr.~Harpo's statistics lectures. We have two tutors for the class, Anastasia (\emph{n} = 15) and Bernadette (\emph{n} = 18). Our research question is ``Which tutor results in better student grades?'' We don't have a hypothesis that one does better than the other. Therefore our hypotheses can be written up as such:

\begin{itemize}
\tightlist
\item
  \(H_1\): There is a difference in student grades between Anastasia's and Bernadette's classes.
\item
  \(H_0\): There is no difference in student grades between Anastasia's and Bernadette's classes.
\end{itemize}

From now on, we'll assume our \(\alpha\) is .05 as default; however, remember that we should think critically about our alpha value when hypothesis testing!

\hypertarget{look-at-the-data-1}{%
\subsection{Look at the data}\label{look-at-the-data-1}}

\hypertarget{data-set-up-1}{%
\subsubsection{Data set-up}\label{data-set-up-1}}

To conduct the independent t-test, we first need to ensure our data is set-up properly in our dataset. This requires having two columns: one with our continuous dependent variable and one indicating which group the participant is in. Each row is a unique participant or unit of analysis.

Below is the first ten rows of our data from the Harpo dataset.

\includegraphics{images/02-independent_t-test/independent_t-test_data.png}

In the data above, what is your \textbf{independent variable}? What is your \textbf{dependent variable}?

\hypertarget{describe-the-data-1}{%
\subsubsection{Describe the data}\label{describe-the-data-1}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. Our overall data consists of 33 cases and the students in our dataset have a mean grade of 71.55 (SD = 7.80). The minimum and maximum values look accurate; theoretically, student grades should range from 0-100. Lastly, the distribution of data looks nice and normally distributed. Although we have a pretty small sample size, especially within each group, we can proceed with our analyses. First, though, we need to check our assumptions.

\includegraphics{images/02-independent_t-test/independent_t-test_descriptives_all.png}

\includegraphics[width=5.5in,height=\textheight]{images/02-independent_t-test/independent_t-test_plot_all.png}

\hypertarget{check-assumptions-1}{%
\subsection{Check assumptions}\label{check-assumptions-1}}

\hypertarget{assumptions-1}{%
\subsubsection{Assumptions}\label{assumptions-1}}

As a parametric test, the independent t-test has the same assumptions as other parametric tests:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The dependent variable is \textbf{normally distributed}
\item
  Variances in the two groups are roughly equal (i.e., \textbf{homogeneity of variances})
\item
  The dependent variable is \textbf{interval or ratio} (i.e., continuous)
\item
  Scores are \textbf{independent} between groups
\end{enumerate}

We cannot test the third and fourth assumptions; rather, those are based on knowing your data.

However, we can and should test for the first two assumptions. Fortunately, the independent samples t-test in jamovi has two check boxes under ``Assumption Checks'' that lets us test for both assumptions.

\hypertarget{checking-assumptions-2}{%
\subsubsection{Checking assumptions}\label{checking-assumptions-2}}

One thing to keep in mind in all statistical software is that we often check assumptions simultaneously to performing the statistical test. However, we should always check assumptions first before looking at and interpreting our results. Therefore, whereas the instructions for performing the test are below, we discuss checking assumptions here first to help ingrain the importance of always checking assumptions for interpreting results.

\hypertarget{testing-normality-1}{%
\paragraph{Testing normality}\label{testing-normality-1}}

jamovi easily allows us to check for normality using the Shapiro-Wilk test and the Q-Q plot. The Shapiro-Wilk test was not statistically significant (W = .98, \emph{p} = .827); therefore, this indicates the data is normally distributed. Furthermore, the lines are fairly close to the diagonal line in the Q-Q plot. We can conclude that we satisfy the assumption of normality.

\includegraphics{images/02-independent_t-test/independent_t-test_normality.png}

Remember that we can also test for normality by \textbf{looking at our data} (e.g., a histogram or density plot, which you can see above) and by examining \textbf{skew and kurtosis}. However, you will need to view them using Exploration --\textgreater{} Descriptives, not in the t-tests menu. Here is our skew and kurtosis:

\begin{itemize}
\item
  \textbf{Skew}: \(.06/.41 = .15\)
\item
  \textbf{Kurtosis}: \(.33/.80 = .41\)
\end{itemize}

Remember that we divide the value by its standard error to determine the z-score. If the absolute value of it is below 1.96 then we assume it is normally distributed. Both skew and kurtosis meet the assumption of normality. In addition, so did all our other pieces of evidence of normality: Shapiro-Wilk's, visual examination of the distribution, and the Q-Q plot. Therefore we can assume we met the assumption of normality.

\includegraphics{images/02-independent_t-test/independent_t-test_skewkurtosis.png}

\hypertarget{testing-homogeneity-of-variance}{%
\paragraph{Testing homogeneity of variance}\label{testing-homogeneity-of-variance}}

We test for homogeneity of variance using the Levene's test. The Levene's test was not statistically significant (\emph{F} {[}1, 31{]} = 2.49, \emph{p} = .125); therefore, this indicates our data satisfies the assumption of homogeneity of variance. However, I would add a caveat that we have a small sample of data (\emph{n} = 15 for Anastasia and \emph{n} = 18 for Bernadette) and the standard deviations are quite different from one another (SD = 9.00 vs 5.77, respectively). We should have tried to collect more data.

\includegraphics{images/02-independent_t-test/independent_t-test_homogeneity.png}

\hypertarget{perform-the-test-1}{%
\subsection{Perform the test}\label{perform-the-test-1}}

Now that we've satisfied the assumptions, we can perform the independent t-test. Here are the steps for doing so in jamovi:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to the Analyses tab, click the T-Tests button, and choose ``Independent Samples T-Test''.
\item
  Move your dependent variable \texttt{grade} to the Dependent Variables box and your independent variable \texttt{tutor} to the Grouping Variable box.
\item
  Under Tests, select \texttt{Student\textquotesingle{}s}. We'll learn about Welch's and Mann-Whitney U under the violated assumptions section.
\item
  Under Hypothesis, select the hypothesis that matches your research question. In our case, select \texttt{Group\ 1\ \ Group\ 2} because we have a two-sided hypothesis.
\item
  Under Additional Statistics, select \texttt{Mean\ difference}, \texttt{Effect\ size}, \texttt{Descriptives}, and (optionally) \texttt{Descriptives\ plots}.
\item
  Under Assumption Checks, select all three options: \texttt{Homogeneity\ test}, \texttt{Normality\ test}, and \texttt{Q-Q\ plot}.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics{images/02-independent_t-test/independent_t-test_setup.png}

\hypertarget{interpret-results-1}{%
\subsection{Interpret results}\label{interpret-results-1}}

Once we are satisfied we have satisfied the assumptions for the independent t-test, we can interpret our results.

\includegraphics{images/02-independent_t-test/independent_t-test_ind-results.png}

Our p-value is less than our alpha value of .05, so our results are statistically significant. Like most of the statistics we'll come across, the larger the t-statistic (or F-statistic, or chi-square statistic\ldots), the smaller the p-value will be. Therefore, we reject our null hypothesis that there is no difference between the two groups.

\hypertarget{write-up-the-results-in-apa-style-1}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-1}}

When writing up the results of a statistical test, we should always include the following information:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Description of your research question and/or hypotheses.
\item
  Description of your data. If you fail to meet assumptions, you should specify that and describe what test you chose to perform as a result.
\item
  The results of the inferential test, including what test was performed, the test value and degrees of freedom, p-value, and effect size.
\item
  Interpretation of the results, including any other information as needed.
\end{enumerate}

We can write up our results in APA something like this:

\begin{quote}
The research question was whether there was a difference in student grades between Anastasia's and Bernadette's classes. Anastasia's students (\emph{M} = 74.53, \emph{SD} = 9.00, \emph{n} = 15) had significantly higher grades than Bernadette's students (\emph{M} = 69.06, \emph{SD} = 5.77, \emph{n}~= 18), \emph{t} (31) = 2.12, \emph{p} = .043, \emph{d} = .74.
\end{quote}

Let's analyze that against the 4 things we need to report:

\begin{quote}
\textbf{\#1:} The research question was whether there was a difference in student grades between Anastasia's and Bernadette's classes. \textbf{\#4} Anastasia's students \textbf{\#2} (\emph{M} = 74.53, \emph{SD} = 9.00, \emph{n} = 15) \textbf{\#4 cont.} had significantly higher grades than Bernadette's students \textbf{\#2} (\emph{M} = 69.06, \emph{SD} = 5.77, \emph{n}~= 18), \textbf{\#3} \emph{t} (31) = 2.12, \emph{p} = .043, \emph{d} = .74.
\end{quote}

Sometimes, people like to put the statistics inside a parentheses. In that case, you need to change the parentheses around the degrees of freedom as brackets. Here's another example write-up of the results in APA style:

\begin{quote}
\textbf{\#1} I tested the difference in grades between Anastasia's students \textbf{\#2} (\emph{M} = 74.53, \emph{SD} = 9.00, \emph{n} = 15) and Bernadette's students (\emph{M} = 69.06, \emph{SD} = 5.77, \emph{n}~= 18). \textbf{\#3} An independent samples t-test showed that the 5.48 mean difference between the tutor's student was statistically significant (\emph{t} {[}31{]} = 2.12, \emph{p} = .043, \emph{d} = .74). \textbf{\#4} Therefore, we reject the null hypothesis that there is no difference in grades between the two classes.
\end{quote}

Note that these are not the only way we can write up the results in APA format. The key is that we include all four pieces of information as specified above.

\hypertarget{visualize-the-results-1}{%
\subsubsection{Visualize the results}\label{visualize-the-results-1}}

By selecting \texttt{Descriptives\ plots} in the setup, you get the figure below. Personally, I don't think this is a very good plot. It's not very informative. It just provides the mean (circle), 95\% confidence interval (blue bars), and the median.

\includegraphics{images/02-independent_t-test/independent_t-test_plot2.png}

Another default option in jamovi is via the Descriptives analysis. You can ask for the boxplot, violin plot, and data of your dependent variable split by your independent variable. This is a much better option. Not only does it show us our mean (black bars) and interquartile range (via the boxplot), but it also shows our distribution (violin plot) and data points (grey dots). This is much more informative.

\includegraphics{images/02-independent_t-test/independent_t-test_plot.png}

Oftentimes, people display results in a simple bar chart, often adding error bars (either 95\% CI or SE error bars). But this is also not a great chart because it lacks information about the underlying distribution of data. Therefore, for the independent t-test I recommend the visualization shown above.

\hypertarget{video-2}{%
\subsection{Video}\label{video-2}}

Here's a video walking through the independent t-test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=Pg1EA0eh2p0"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{in-case-of-violated-assumptions-1}{%
\subsection{In case of violated assumptions}\label{in-case-of-violated-assumptions-1}}

If you fail to meet one or both of the assumptions of normality (and no transformations fixed your data) and homogeneity of variances, jamovi has the alternative statistics easily built in. Here's what statistic you should choose based on satisfying assumptions:

\begin{longtable}[]{@{}lll@{}}
\toprule
& \textbf{Normality: satisfied} & \textbf{Normality: not satisfied} \\
\midrule
\endhead
\textbf{Homogeneity of Variance: satisfied} & Student's t-test & Mann-Whitney U \\
\textbf{Homogeneity of Variance: not satisfied} & Welch's t-test & Mann-Whitney U \\
\bottomrule
\end{longtable}

The Welch's t-test has three main differences from the independent samples t-test: (a) the standard error (SE) is not a pooled estimate, (b) the degrees of freedom are calculated very different (not \emph{N} - 2), and (c) it does not have an assumption of homogeneity of variance. Note that Welch's t-test is \emph{not} a non-parametric test because it still has the assumption of a normal distribution.

The Mann-Whitney U is not calculated based on the mean but rather the median and compares ranks of values across the two groups: it has no assumptions about the distribution of data or homogeneity of variances. Therefore, it is a non-parametric test. Here is what the output for all three tests look like:

\includegraphics{images/02-independent_t-test/independent_t-test_full-results.png}

\hypertarget{welchs-t-test}{%
\subsubsection{Welch's t-test}\label{welchs-t-test}}

To conduct this in jamovi, under Tests select \texttt{Welch\textquotesingle{}s}. You will interpret the results similarly to the independent t-test:

\begin{quote}
Using a Welch's t-test, there was not a statistically significant difference in grades between Anastasia's students (\emph{M} = 74.53, \emph{SD} = 9.00, \emph{n} = 15) and Bernadette's students (\emph{M} = 69.06, \emph{SD} = 5.77, \emph{n} = 18), \emph{t} (23.02) = 2.03, \emph{p} = .054, \emph{d} = .72.
\end{quote}

Why is it no longer statistically significant? Which result should you trust? In reality, the difference in \emph{p}-values is likely due to chance. However, the independent t-test and Welch's test have different strengths and weaknesses. If the two populations really do have equal variances, then the independent t-test is slightly more powerful (lower Type II error rate) than the Welch's test. However, if they \emph{don't} have the same variances, then the assumptions of the independent t-test are violated and you may not be able to trust the results; you may end up with a higher Type I error rate. So it's a trade-off.

Which should you use? I tend to prefer always using Welch's t-test because if the variances are equal, then there will be practically no difference between the independent and Welch's t-test. But if the variances are not equal, then Welch's t-test will outperform the independent t-test. For that reason, defaulting to the Welch's t-test makes most sense to me.

\hypertarget{mann-whitney-u-test}{%
\subsubsection{Mann-Whitney U test}\label{mann-whitney-u-test}}

If you do not satisfy the assumption of normality (regardless of whether you satisfy the assumption of homogeneity of variance), you should either try to transform your data to be normally distributed or you will need to use a non-parametric test. In this case, if you originally wanted to perform an independent t-test, the non-parametric equivalent test is the Mann-Whitney U test.

I will not go into specifics, but the idea behind the Mann-Whitney U test is that you take all the values (regardless of group) and rank them. You then sum the ranks across groups and calculate your U statistic and p-value. You interpret the p-value like you normally would, but there are differences in how we report the results because this statistic is based on the \emph{median} not the \emph{mean}.

\begin{quote}
Using the Mann-Whitney U test, there was a statistically significant difference in grades between Anastasia's students (\emph{Mdn} = 76, \emph{n} = 15) and Bernadette's students (\emph{Mdn} = 69, \emph{n}~= 18), \emph{U} = 79.50, \emph{p} = .046, \(r_{pb}\) = .41.
\end{quote}

\hypertarget{your-turn-1}{%
\subsection{Your turn!}\label{your-turn-1}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

Perform independent t-tests based on the following research questions. Think critically about whether you should be using a one-tailed or two-tailed hypothesis and check your assumptions so you know which test to use!

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Does height differ by gender (Gender: male = 0, female = 1)?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis?
  \item
    Which statistic should you use based on your assumptions?
  \item
    Does height differ by gender?
  \end{itemize}
\item
  \textbf{Do athletes (Athlete: athletes = 1, non-athlete = 0) have faster sprint times than non-athletes?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis?
  \item
    Which statistic should you use based on your assumptions?
  \item
    Do athletes have faster sprint times than non-athletes?
  \end{itemize}
\item
  \textbf{Do students who live on campus (LiveOnCampus: on campus = 1, off campus = 0) have higher English scores than students who live off campus?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis?
  \item
    Which statistic should you use based on your assumptions?
  \item
    Does students who live on campus have higher English scores?
  \end{itemize}
\item
  \textbf{Does athletic status relate to math scores?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis?
  \item
    Which statistic should you use based on your assumptions?
  \item
    Does athletic status relate to math scores?
  \end{itemize}
\end{enumerate}

\hypertarget{dependent-t-test}{%
\section{Dependent t-test}\label{dependent-t-test}}

\hypertarget{overview-2}{%
\subsection{Overview}\label{overview-2}}

The dependent t-test is used to test the difference in our dependent variable between two categories in which participants are the \emph{same} across categories. Our category variable is our independent variable. In other words, we use the dependent t-test when we have a research question with a \textbf{continuous dependent variable} and a \textbf{categorical independent variable with two categories in which the \underline{same} participants are in each category}.

The dependent t-test is also called a dependent samples t-test or paired samples t-test.

There are three different types of alternative hypotheses we could have for the dependent t-test:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Two-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): There is a difference in means between the two time points or conditions.
  \item
    \(H_0\): There is no difference in means between the two time points or conditions.
  \end{itemize}
\item
  \textbf{One-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): The mean at time 1 or condition 1 is greater than the mean at time 2 or condition 2.
  \item
    \(H_0\): The mean at time 1 or condition 1 is less than or equal to the mean at time 2 or condition 2.
  \end{itemize}
\item
  \textbf{One-tailed}

  \begin{itemize}
  \tightlist
  \item
    \(H_1\): The mean at time 1 or condition 1 is smaller than the mean at time 2 or condition 2.
  \item
    \(H_0\): The mean at time 1 or condition 1 is greater than or equal to the mean at time 2 or condition 2.
  \end{itemize}
\end{enumerate}

\hypertarget{specify-your-hypotheses-1}{%
\subsection{Specify your hypotheses}\label{specify-your-hypotheses-1}}

For this chapter, we're going to work with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``Chico''. This dataset is hypothetical data from Dr.~Chico's class in which students took two tests: one early in the semester and one later in the semester. Dr.~Chico thinks that the first test is a ``wake up call'' for students. When they realise how hard her class really is, they'll work harder for the second test and get a better mark. Is she right?

First, let's determine our hypotheses. For this one, can you determine the null and alternative hypotheses based on Dr.~Chico's research question?

\hypertarget{look-at-the-data-2}{%
\subsection{Look at the data}\label{look-at-the-data-2}}

\hypertarget{data-set-up-2}{%
\subsubsection{Data set-up}\label{data-set-up-2}}

To conduct the dependent t-test, we first need to ensure our data is set-up properly in our dataset. This requires having two columns: one is our dependent variable score for the participant in one category and the other column is our dependent variable score for the participant in the other category. Each row is a unique participant or unit of analysis.

\includegraphics{images/03_dependent_t-test/dependent_data.png}

In the data above, what is your \textbf{independent variable}? What is your \textbf{dependent variable}?

\hypertarget{describe-the-data-2}{%
\subsubsection{Describe the data}\label{describe-the-data-2}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. Our overall data consists of 20 cases (students) and the average grade is 56.98 (\emph{SD} = 6.62) at the first test and 58.38 (\emph{SD} = 6.41) at the second test. We have no missing cases, and our minimum and maximum values look accurate; theoretically, student grades should range from 0-100. Lastly, the distribution of data looks fairly normally distributed, although I'm personally a little worried about our small sample size. Before we can proceed with our analyses, we'll need to check our assumptions.

\includegraphics{images/03_dependent_t-test/dependent_descriptives.png}

\hypertarget{check-assumptions-2}{%
\subsection{Check assumptions}\label{check-assumptions-2}}

\hypertarget{assumptions-2}{%
\subsubsection{Assumptions}\label{assumptions-2}}

As a parametric test, the dependent t-test has the same assumptions as other parametric tests minus the homogeneity of variance assumption because we are dealing with the same people across categories

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \emph{differences in scores} in the dependent variable are \textbf{normally distributed}
\item
  The dependent variable is \textbf{interval or ratio} (i.e., continuous)
\item
  Scores are \textbf{independent} \emph{across participants}
\end{enumerate}

We cannot \emph{test} the second and third assumptions; rather, those are based on knowing your data.

However, we can and should test for the first assumption. Fortunately, the dependent samples t-test in jamovi has two check boxes under ``Assumption Checks'' that lets us test normality.

\hypertarget{checking-assumptions-3}{%
\subsubsection{Checking assumptions}\label{checking-assumptions-3}}

One thing to keep in mind in all statistical software is that we often check assumptions simultaneously to performing the statistical test. However, we should always check assumptions first before looking at and interpreting our results. Therefore, whereas the instructions for performing the test are below, we discuss checking assumptions here first to help ingrain the importance of always checking assumptions for interpreting results.

\hypertarget{testing-normality-2}{%
\paragraph{Testing normality}\label{testing-normality-2}}

Notice how our dependent variable is really the difference in scores, and therefore that is what we are testing for normality. We test for normality using the Shapiro-Wilk test and the Q-Q plot. The Shapiro-Wilk test was not statistically significant (W = .97, \emph{p} = .678); therefore, this indicates the data is normally distributed. Furthermore, the lines are fairly close to the diagonal line in the Q-Q plot (although it's a bit hard to tell because our sample size is small). We can conclude that we satisfy the assumption of normality.

\includegraphics{images/03_dependent_t-test/dependent_normality.png}

\hypertarget{perform-the-test-2}{%
\subsection{Perform the test}\label{perform-the-test-2}}

Now that we've satisfied the assumptions, we can perform the dependent t-test. Here are the steps for doing so in jamovi:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to the Analyses tab, click the T-Tests button, and choose ``Paired Samples T-Test''.
\item
  Move both measurements of your dependent variable (\texttt{grade\_test1} and \texttt{grade\_test2}) to the Paired Variables box.
\item
  Under Tests, select \texttt{Student\textquotesingle{}s}. We'll learn more about the Wilcoxon rank option, which is an option if you fail to meet the assumption of normality.
\item
  Under Hypothesis, choose the correct hypothesis based on our hypotheses from above! In this case, the answer is ``Measure 1 \textless{} Measure 2''
\item
  Under Additional Statistics, select \texttt{Mean\ difference}, \texttt{Effect\ size}, \texttt{Descriptives}, and (optionally) \texttt{Descriptives\ plots}.
\item
  Under Assumption Checks, select both options: \texttt{Normality\ test} and \texttt{Q-Q\ plot}. You'll check these assumptions first, which is discussed above.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics{images/03_dependent_t-test/dependent_setup.png}

\hypertarget{interpreting-results}{%
\subsection{Interpreting results}\label{interpreting-results}}

Once we are satisfied we have satisfied the assumptions for the dependent t-test, we can interpret our results.

\includegraphics{images/03_dependent_t-test/dependent_results.png}

Our p-value is less than .05, so our results are statistically significant. Therefore, we reject the null hypothesis that there is no difference between the two groups.

\hypertarget{write-up-the-results-in-apa-style-2}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-2}}

When writing up the results of a statistical test, we should always include the following information:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Description of your research question and/or hypotheses.
\item
  Description of your data. If you fail to meet assumptions, you should specify that and describe what test you chose to perform as a result.
\item
  The results of the inferential test, including what test was performed, the test value and degrees of freedom, p-value, and effect size.
\item
  Interpretation of the results, including any other information as needed.
\end{enumerate}

We can write up our results in APA something like this:

\begin{quote}
Dr.~Chico tested whether students performed better on the second test compared to the first test. The 20 students in performed better on the second test (\emph{M} = 58.38, \emph{SD} = 6.41) than they did on the first test (\emph{M} = 56.98, \emph{SD} = 6.62), \emph{t}(19) = 6.48, \emph{p} \textless{} .001, \emph{d} = 1.45.
\end{quote}

Remember in the previous chapter that our t-test can be negative but we can always flip the interpretation.

\hypertarget{visualize-the-results-2}{%
\subsubsection{Visualize the results}\label{visualize-the-results-2}}

By selecting \texttt{Descriptives\ plots} in the setup, you get the figure below. Personally, I don't think this is a very good plot. It's not very informative. It just provides the mean (circle), 95\% confidence interval (blue bars), and the median.

\includegraphics{images/03_dependent_t-test/dependent_results_plot.png}

Another option is to use the Descriptives plots available in jamovi, which we see above in the Look at the data section above. I wish there were a way to combine them into one graph, but unfortunately there isn't within jamovi. Instead, you'll have to go into the Rj editor and use R code to reshape the data from wide format to long format and then call the descriptives syntax to produce the plot. You \emph{could} copy-paste the data into a new dataset, but I always try to avoid manual work when doing analyses because something \emph{always} goes wrong.

Here's what this looks like in jamovi:

\includegraphics{images/03_dependent_t-test/dependent_results_plot2.png}

To make our lives a bit easier, here is the code in the Rj editor that you can copy-paste (that kind of copy-pasting I allow!) into your own jamovi. You'll need to edit things like the list of names in line 3, the name of your DV (line 4), the name of your IV (line 5), and re-specify those names in line 9.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{long }\OtherTok{\textless{}{-}} \FunctionTok{reshape}\NormalTok{(data, }
                \AttributeTok{direction =} \StringTok{"long"}\NormalTok{, }
                \AttributeTok{varying =} \FunctionTok{list}\NormalTok{(}\FunctionTok{names}\NormalTok{(data)[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]),}
                \AttributeTok{v.names =} \StringTok{"Test Score"}\NormalTok{,}
                \AttributeTok{timevar =} \StringTok{"Test Time"}\NormalTok{)}


\NormalTok{jmv}\SpecialCharTok{::}\FunctionTok{descriptives}\NormalTok{(}\AttributeTok{data =}\NormalTok{ long,}
                  \AttributeTok{formula =} \StringTok{\textasciigrave{}}\AttributeTok{Test Score}\StringTok{\textasciigrave{}} \SpecialCharTok{\textasciitilde{}} \StringTok{\textasciigrave{}}\AttributeTok{Test Time}\StringTok{\textasciigrave{}}\NormalTok{,}
                  \AttributeTok{box =} \ConstantTok{TRUE}\NormalTok{,}
                  \AttributeTok{violin =} \ConstantTok{TRUE}\NormalTok{,}
                  \AttributeTok{dot =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{video-3}{%
\subsection{Video}\label{video-3}}

Here's a video walking through the dependent t-test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=ywMPrS9Bo3Q"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-2}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{in-case-of-violated-assumptions-2}{%
\subsection{In case of violated assumptions}\label{in-case-of-violated-assumptions-2}}

If you violated the assumption of normality and no transformation fixed your data, then you can perform the non-parametric version of the dependent t-test called the Wilcoxon Rank test. As a reminder, non-parametric tests do not make assumptions about the distribution of data because it deals with the \emph{median} not the \emph{mean}.

Here is the output for both the dependent t-test and the Wilcoxon rank test:

\includegraphics{images/03_dependent_t-test/dependent_results_full.png}

\hypertarget{wilcoxon-rank}{%
\subsubsection{Wilcoxon rank}\label{wilcoxon-rank}}

To conduct this in jamovi, under Tests select \texttt{Wilcoxon\ rank}. You will interpret the results similarly to the dependent t-test:

\begin{quote}
Using Wilcoxon rank test, students' test scores were significantly higher at the second test (\emph{Mdn} = 59.70) than at the first test (\emph{Mdn} = 57.70), W = 2.00, \emph{p} \textless{} .001.
\end{quote}

The note about tied values is not necessary to discuss. It is just telling us one participant had identical values for both test1 and test2 (student15). You can check this yourself in the dataset

\hypertarget{your-turn-2}{%
\subsection{Your turn!}\label{your-turn-2}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

Perform dependent t-tests based on the following research questions. Think critically about whether you should be using a one-tailed or two-tailed hypothesis and check your assumptions so you know which test to use!

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\textbf{Note}: Technically, none of our data is suitable for a dependent t-test in this dataset. We will pretend that the four test score variables (\texttt{English}, \texttt{Reading}, \texttt{Math}, and \texttt{Writing}) are really four measurements of the same underlying test. In reality, we would analyze this data using correlation.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Do students perform better on the English test than they do the Writing test?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis?
  \item
    Which statistic should you use based on your assumptions?
  \item
    Do students perform better on the English test than they do the Writing test?
  \end{itemize}
\item
  \textbf{Does students' English scores relate to their Reading scores?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis?
  \item
    Which statistic should you use based on your assumptions?
  \item
    Does students' English scores relate to their Reading scores?
  \end{itemize}
\end{enumerate}

\hypertarget{chi-square}{%
\chapter{Chi-Square}\label{chi-square}}

The chi-quare is a categorical data analysis which is simply data analysis with categorical data. It's usually nominal data, although there are a couple tests we may use with ordinal data. There are two basic types of chi-square tests we'll be covering:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\chi^2\) \textbf{goodness-of-fit}: used with one variable to find if the observed frequencies match the expected frequencies
\item
  \(\chi^2\) \textbf{test of independence (or association)}: used with two variables to find if the observed frequencies match the expected frequencies. In other words, are the two nominal variables independent or associated with one another?

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \textbf{Fisher's exact test}: This is an alternative to the \(\chi^2\) test of independence that we use when our frequencies are small.
  \item
    \textbf{McNemar's test}: This is an alternative to the \(\chi^2\) test of independence that we have a 2x2 repeated-measures design. For example, perhaps we examine pass/fail rates before and after a training.
  \end{enumerate}
\end{enumerate}

Because these tests are all with categorical data, there are no assumptions about the distribution of the data. For that reason, these are all \emph{non-parametric statistics}.

\hypertarget{chi-square-goodness-of-fit}{%
\section{Chi-Square Goodness-of-Fit}\label{chi-square-goodness-of-fit}}

\hypertarget{overview-3}{%
\subsection{Overview}\label{overview-3}}

The \(\chi^2\) (chi-square) goodness-of-fit tests whether an observed frequency distribution of a nominal variable matches an expected frequency distribution. Our hypotheses for the chi-square goodness-of-fit test is as follows:

\begin{itemize}
\item
  \(H_0\): The observed frequencies match the expected frequencies.
\item
  \(H_1\): At least one observed frequency doesn't match the expected frequency.
\end{itemize}

However, these are \emph{not} how you should report your hypotheses. You should specify your hypotheses in relation to the nature of your data. For example, if we have a deck of cards and want to see if people don't choose cards randomly, the null hypothesis would be that there is a 25\% probability of getting each hearts, clubs, spades, and diamonds.

\hypertarget{specify-the-hypotheses-1}{%
\subsection{Specify the hypotheses}\label{specify-the-hypotheses-1}}

Let's run an example with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``randomness''. This dataset has participants pull two cards from a deck. For now, we're just going to work with \texttt{choice\_1}. We're interested in finding out if participants pull cards randomly from the deck.

\begin{itemize}
\item
  \(H_0\): Participants pull cards randomly from the deck. In other words, there is a 25\% probability of pulling each hearts, clubs, spades, and diamonds.
\item
  \(H_1\): Participants pull cards not at random from the deck. In other words, participants have a different probability than 25\% of pulling at least one of the types of cards.
\end{itemize}

\hypertarget{look-at-the-data-3}{%
\subsection{Look at the data}\label{look-at-the-data-3}}

\hypertarget{data-set-up-3}{%
\subsubsection{Data set-up}\label{data-set-up-3}}

Our data set-up for a chi-square goodness-of-fit test is pretty simple, We just need a single column with the nominal category that each participant is in.

\includegraphics{images/09-chi-square/chi-square_data.png}

\hypertarget{describe-your-data}{%
\subsubsection{Describe your data}\label{describe-your-data}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. With nominal variables like \texttt{choice\_1}, we should request Frequency tables, not descriptive statistics like the mean and median. The mean for \texttt{choice\_1} would be, quite frankly, meaningless. What's the average card type? It can't exist. So we do frequencies instead.

Notice how jamovi is pretty smart here and knows not to give us the mean, median, minimum, and maximum. Check the box for Frequency tables to receive those. From our data, we see that most participants pulled a hearts card first (\emph{n} = 64, 32\%) followed by diamonds (\emph{n} = 51, 26\%), spades (\emph{n} = 50, 25\%), and finally clubs (\emph{n} = 35, 18\%).

\includegraphics{images/09-chi-square/chi-square_descriptives.png}

A bar plot can visualize these descriptive statistics nicely.

\includegraphics[width=3.125in,height=\textheight]{images/09-chi-square/chi-square_bar.png}

\hypertarget{check-assumptions-3}{%
\subsection{Check assumptions}\label{check-assumptions-3}}

The chi-square goodness-of-fit test has just one assumption: \textbf{Expected frequencies are sufficiently large}, which is usually greater than 5.

\hypertarget{perform-the-test-3}{%
\subsection{Perform the test}\label{perform-the-test-3}}

To perform the chi-square goodness of fit test, do the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  From the `Analyses' toolbar select `Frequences' - `One sample proportion tests - N outcomes'.
\item
  Move \texttt{choice\_1} into the Variable box.
\item
  Select \texttt{Expected\ counts}.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics{images/09-chi-square/chi-square_setup.png}

\hypertarget{interpret-results-2}{%
\subsection{Interpret results}\label{interpret-results-2}}

\includegraphics{images/09-chi-square/chi-square_results.png}

The first table shows us our observed frequencies (our data) and expected frequencies (N/k = 200/4 = 50). The second table gives us our results. Our p-value is less than our alpha of .05 so we can reject the null hypothesis that the observed frequencies match our expected frequencies.

\hypertarget{write-up-the-results-in-apa-style-3}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-3}}

We can write up our results in APA something like this:

\begin{quote}
Of the 200 participants in the experiment, 64 selected hearts for their first choice, 51selected diamonds, 50 selected spades, and 35 selected clubs. A chi-square goodness-of-fit test was conducted to test whether the choice probabilities were identical for all four suits. The results were statistically significant (\(\chi^2\) {[}3{]} = 8.44; \emph{p} = .038), suggesting that people did not select suits purely at random.
\end{quote}

\hypertarget{visualize-the-results-3}{%
\subsubsection{Visualize the results}\label{visualize-the-results-3}}

The bar chart from above does a decent job of visualizing the results. Although it would be difficult to do in jamovi, we could do a revised chart in Excel pretty easily. Instead of counts, perhaps we care more about percentages, and adding a line for the expected frequency (25\%). Here's an example, using instructions from \href{https://exceljet.net/chart/column-chart-with-target-line}{this tutorial}:

\includegraphics[width=5.20833in,height=\textheight]{images/09-chi-square/chi-square_excel.png}

\hypertarget{video-4}{%
\subsection{Video}\label{video-4}}

Here's a video walking through the chi-square goodness of fit test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=Pg1EA0eh2p0"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{additional-information-1}{%
\subsection{Additional information}\label{additional-information-1}}

\hypertarget{different-expected-frequencies}{%
\subsubsection{Different Expected Frequencies}\label{different-expected-frequencies}}

As you can tell, jamovi automatically assumed equal proportions of frequencies. However, there might be times when you don't want to make that assumption. Maybe we're testing the whether our sample frequencies match the population frequencies and those are uneven (e.g., whether our 40/60 gender split matches the 36/64 gender split in the population).

We can use the \texttt{Expected\ Proportions} in the setup to specify different expected frequencies.

For example, maybe we think our deck is a little stacked in favor of red cards--or we think our participants are more likely to choose red cards than black cards. We can specify our expected proportions and then interpret the results. In this case, participants do not seem more likely to choose red cards based on the expected frequencies we provided.

\includegraphics{images/09-chi-square/chi-square_results2.png}

\hypertarget{your-turn-3}{%
\subsection{Your turn!}\label{your-turn-3}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Are there equal numbers of athletes and non-athletes?} (\texttt{Athlete} variable)

  \begin{itemize}
  \item
    Do you meet the assumptions?
  \item
    Are the observed frequencies similar to the expected frequencies?
  \item
    What is your chi-square value, rounded to two decimal places?
  \end{itemize}
\item
  \textbf{I happen to know the school this data comes from has 40\% athletes and 60\% non-athletes. Does our data match the school population?}

  \begin{itemize}
  \item
    Change your Expected Proportions ratio to .6 for non-athletes and .4 for athletes.
  \item
    Are the observed frequencies similar to the expected frequencies?
  \item
    What is your chi-square value, rounded to two decimal places?
  \end{itemize}
\item
  \textbf{Are there equal numbers of freshmen, sophomores, juniors, and seniors?} (\texttt{Rank} variable)

  \begin{itemize}
  \item
    Do you meet the assumptions?
  \item
    Are the observed frequencies similar to the expected frequencies?
  \item
    What is your chi-square value, rounded to two decimal places?
  \end{itemize}
\end{enumerate}

\hypertarget{chi-square-test-of-independence}{%
\section{Chi-Square Test of Independence}\label{chi-square-test-of-independence}}

\hypertarget{overview-4}{%
\subsection{Overview}\label{overview-4}}

The \(\chi^2\) (chi-square) test of independence (or association) tests whether an observed frequency distribution of a nominal variable matches an expected frequency distribution, but unlike the goodness of fit test we are looking at the relationship, independence, or association between two variables.

Our basic hypotheses for the chi-square goodness-of-fit test is as follows:

\begin{itemize}
\item
  \(H_0\): The observed frequencies match the expected frequencies.
\item
  \(H_1\): At least one observed frequency doesn't match the expected frequency.
\end{itemize}

However, these are \emph{not} how you should report your hypotheses. You should specify your hypotheses in relation to the nature of your data. See below for an example.

\hypertarget{specify-your-hypotheses-2}{%
\subsection{Specify your hypotheses}\label{specify-your-hypotheses-2}}

Let's run an example with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``chapek9''. This dataset indicates the ID number of the participant, the species (robot or human), and their preference of the three things (puppy, flower, or data).

For this example, imagine we are watching a show about the planet \emph{Chapek 9}. On this planet, for someone to gain access to their capital city they must prove they're a robot, not a human. In order to determine whether or not a visitor is human, the natives ask whether the visitor prefers puppies, flowers, or large, properly formatted data files.

\begin{itemize}
\item
  \(H_0\): Humans and robots have similar preferences.
\item
  \(H_1\): Humans and robots have different preferences.
\end{itemize}

\hypertarget{look-at-the-data-4}{%
\subsection{Look at the data}\label{look-at-the-data-4}}

\hypertarget{data-set-up-4}{%
\subsubsection{Data set-up}\label{data-set-up-4}}

Our data set-up for a chi-square test of independence is pretty simple, We just need two columns of nominal data, with one row per participant. Here's our data for our example we'll be working with, which you can find in the lsj-data called \texttt{chapek9}:

\begin{longtable}[]{@{}lll@{}}
\toprule
ID & species & choice \\
\midrule
\endhead
1 & robot & flower \\
2 & human & data \\
3 & human & data \\
4 & human & data \\
5 & robot & data \\
6 & human & flower \\
7 & human & data \\
8 & robot & data \\
9 & human & puppy \\
10 & robot & flower \\
\bottomrule
\end{longtable}

\hypertarget{describe-the-data-3}{%
\subsubsection{Describe the data}\label{describe-the-data-3}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. Remember that for nominal variables we should report frequency statistics, not means and medians and such. Bar plots continue to be a good way of visualizing the data.

\includegraphics{images/11-independence/independence_data.png}

\hypertarget{check-assumptions-4}{%
\subsubsection{Check assumptions}\label{check-assumptions-4}}

The chi-square test of independence has the following assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Expected frequencies are sufficiently large}, which is usually greater than 5. If you violate this assumption, you can use Fisher's exact test.
\item
  Data are \textbf{independent} of one another, meaning each case contributes to only one cell of the table. If you violate this assumption, you may be able to use the McNemar test. This requires knowing how your data was collected. If it's a within-subjects design that should be answered using a chi-square, then most likely you want to use McNemar's test. If it's a between-subjects design that should be answered using a chi-square, then you most likely meet this assumption and can perform the chi-square test of independence.
\end{enumerate}

\hypertarget{perform-the-test-4}{%
\subsection{Perform the test}\label{perform-the-test-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  From the `Analyses' toolbar select `Frequencies' - `Independent Samples - \(\chi^2\) test of association'.
\item
  Move \texttt{choice} into rows and \texttt{species} into columns. Note that the placement in rows or columns doesn't really matter, but because we typically work with portrait pages I tend to prefer putting in rows whatever variable has more levels. In this case, choice has 3 levels and species only 2 so I like to put choice in rows and species in columns.
\item
  Under the Statistics tab, select \(\chi^2\) under Tests and \texttt{Phi\ and\ Cramer\textquotesingle{}s\ V} under Nominal.
\item
  Optionally, you can request under the Cells tab to show the expected counts and the row, column, and total percentages.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics{images/11-independence/independence_setup.png}

\hypertarget{interpreting-results-1}{%
\subsection{Interpreting results}\label{interpreting-results-1}}

\includegraphics{images/11-independence/independence_results.png}

The first table shows us our observed frequencies. The second table gives us our results. Our p-value is less than .05 so we can reject the null hypothesis that the observed frequencies match our expected frequencies.

jamovi also gives us our Cramer's V value. Note that it does not provide Phi because we don't have a perfect square table (e.g., 2x2 or 3x3). These are measures of effect size for the chi-square. Cramer's V can be interpreted similar to a correlation (ranges from 0 to 1, with higher scores meaning stronger relationships between the variables).

\hypertarget{write-up-the-results-in-apa-style-4}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-4}}

We can write up our results in APA something like this:

\begin{quote}
Pearson's \(\chi^2\) test of independence showed a significant association between species and choice, \(\chi^2\) (2) = 10.72, \emph{p} = .005, Cramer's V = .24. Robots appeared to be more likely to say they prefer flowers and humans appeared to be more likely to say they prefer data. Robots and humans appeared to be equally likely to prefer puppies.
\end{quote}

I would either write-up the observed frequencies above or, ideally, I would share the contingency table with my observed frequencies.

\hypertarget{visualize-the-results-4}{%
\subsubsection{Visualize the results}\label{visualize-the-results-4}}

This one is also a visualization that would likely do better in Excel than in jamovi. There are two that I think work well for this dataset and our research questions. The first is a clustered column chart:

\includegraphics[width=5.20833in,height=\textheight]{images/11-independence/independence_excel1.png}

The second is a stacked bar chart with connected lines:

\includegraphics[width=5.20833in,height=\textheight]{images/11-independence/independence_excel2.png}

\hypertarget{video-5}{%
\subsection{Video}\label{video-5}}

Here's a video walking through the chi-square test of independence.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=6a5soxXTfkw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{in-case-of-violated-assumptions-3}{%
\subsection{In case of violated assumptions}\label{in-case-of-violated-assumptions-3}}

\hypertarget{fishers-exact-test}{%
\subsubsection{Fisher's exact test}\label{fishers-exact-test}}

If you violate the assumption that there your expected frequencies are sufficiently large and you have a 2x2 table, you can still perform the \(\chi^2\) test of independence but instead of selecting \(\chi^2\)you'll select \texttt{Fisher\textquotesingle{}s\ exact\ test}. You'll interpret your results exactly the same but specify you used Fisher's exact test.

\hypertarget{additional-information-2}{%
\subsection{Additional information}\label{additional-information-2}}

\hypertarget{ordinal-variables}{%
\subsubsection{Ordinal variable(s)}\label{ordinal-variables}}

If either of your variables are ordinal, instead of selecting \texttt{Phi\ and\ Cramer\textquotesingle{}s\ V} you should select \texttt{Gamma} or \texttt{Kendall\textquotesingle{}s\ tau-b}. Which do you choose? \texttt{Kendall\textquotesingle{}s\ tau-b} should only be chosen if you have a square table (e.g., 3x3, 4x4, 5x5) whereas \texttt{Gamma} can be done with any size table. \texttt{Kendall\textquotesingle{}s\ tau-b} will be a slightly more conservative estimate compared to \texttt{Gamma}.

\hypertarget{your-turn-4}{%
\subsection{Your turn!}\label{your-turn-4}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Is Athlete related to Gender?}

  \begin{itemize}
  \item
    Do you meet the assumptions?
  \item
    Which test should you perform?
  \item
    Are the observed frequencies similar to the expected frequencies?
  \item
    What is your chi-square value, rounded to two decimal places?
  \end{itemize}
\item
  \textbf{Is Gender related to Rank?}

  \begin{itemize}
  \item
    Do you meet the assumptions?
  \item
    Which test should you perform?
  \item
    Are the observed frequencies similar to the expected frequencies?
  \item
    What is your chi-square value, rounded to two decimal places?
  \end{itemize}
\end{enumerate}

\hypertarget{mcnemars-test}{%
\section{McNemar's Test}\label{mcnemars-test}}

\hypertarget{overview-5}{%
\subsection{Overview}\label{overview-5}}

McNemar's test is based on the \(\chi^2\) (chi-square) test of independence (or association), but is used in a repeated measures or within-subjects design. Our basic hypotheses for the McNemar test is as follows:

\begin{itemize}
\item
  \(H_0\): The observed frequencies match the expected frequencies.
\item
  \(H_1\): At least one observed frequency doesn't match the expected frequency.
\end{itemize}

We'll go over a brief example so you're familiar with this test, but in practice I don't see this statistic often so we won't go over it any further than this.

\hypertarget{specify-your-hypotheses-3}{%
\subsection{Specify your hypotheses}\label{specify-your-hypotheses-3}}

For example, suppose we're working with the \emph{Australian Generic Political Party} (AGPP) and your job is to find out how effective AGPP political advertisements are. You gather 100 people and ask them to watch the AGPP ads. You ask participants before and after viewing ads whether they intend to vote for the AGPP. Therefore, the alternative hypothesis is that intentions to vote for the AGPP don't match the expected frequency of intentions to vote.

\hypertarget{look-at-the-data-5}{%
\subsection{Look at the data}\label{look-at-the-data-5}}

\hypertarget{data-set-up-5}{%
\subsubsection{Data set-up}\label{data-set-up-5}}

Our data set-up for McNemar's test is pretty simple. We just need two columns of nominal data, with one row per participant and each column being the same variable at two different time points. Here's our data for our example we'll be working with, which you can find in the lsj-data called \texttt{agpp}:

\begin{longtable}[]{@{}lll@{}}
\toprule
ID & response\_before & response\_after \\
\midrule
\endhead
subj.1 & no & yes \\
subj.2 & yes & no \\
subj.3 & yes & no \\
subj.4 & yes & no \\
subj.5 & no & no \\
subj.6 & no & no \\
subj.7 & no & no \\
subj.8 & no & yes \\
subj.9 & no & no \\
subj.10 & no & no \\
\bottomrule
\end{longtable}

\hypertarget{perform-the-test-5}{%
\subsection{Perform the test}\label{perform-the-test-5}}

Let's run an example with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``agpp''. This dataset indicates the ID number of the participant and whether they would vote for AGPP before and after viewing the ads.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  From the `Analyses' toolbar select `Frequencies' - `Paired Samples - McNemar test'.
\item
  Move \texttt{response\_before} into rows and \texttt{response\_after} into columns. Note that the placement in rows or columns doesn't really matter.
\item
  Under the Statistics tab, select \(\chi^2\) under Tests.
\item
  Optionally, you can request under to show the row and column percentages.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics{images/12-mcnemar/mcnemar_setup.png}

\hypertarget{interpret-results-3}{%
\subsection{Interpret results}\label{interpret-results-3}}

\includegraphics{images/12-mcnemar/mcnemar_results.png}

The first table shows us our observed frequencies. The second table gives us our results. Our p-value is less than .05 so we can reject the null hypothesis that the observed frequencies match our expected frequencies. Unfortunately, looking at our table it also shows that the ads had a negative effect: people were less likely to vote AGPP after seeing the ads.

\hypertarget{write-up-the-results-in-apa-style-5}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-5}}

We can write up our results in APA something like this:

\begin{quote}
McNemar's test indicated that support for AGPP changed from before to after reviewing the AGPP advertisement, \(\chi^2\) (1) = 13.33, \emph{p} \textless{} .001. Most participants continued to not vote for AGPP after the ad (\emph{n} = 65) and a few continued to vote for AGPP after the ad (\emph{n} = 5). However, many participants who originally stated they would vote for AGPP changed to no longer voting for AGPP after the ad (\emph{n} = 25); only five people who originally would not vote for AGPP changed to vote for AGPP after the ad.
\end{quote}

\hypertarget{anova}{%
\chapter{ANOVA}\label{anova}}

ANOVA stands for \textbf{AN}alysis \textbf{O}f \textbf{VA}riance. ANOVAs analyze the variation between and within groups. There are multiple types of ANOVAs based on the nature of the independent variable(s):

\begin{longtable}[]{@{}ll@{}}
\toprule
\textbf{Nature of IV(s)} & \textbf{Type of ANOVA} \\
\midrule
\endhead
1 between-subjects IV & One-way ANOVA \\
1 within-subjects IV & Repeated-measures ANOVA \\
2+ between-subjects IVs & Independent factorial ANOVA \\
2+ within-subjects IVs & Repeated measures factorial ANOVA \\
2+ IVs mixed between/within & Mixed factorial ANOVA \\
1+ IV with a continuous covariate & ANCOVA \\
\bottomrule
\end{longtable}

Furthermore, there are ANOVAs for when there are multiple dependent variables (called the MANOVA or \textbf{M}ultiple \textbf{ANOVA}, as well as the MANCOVA or \textbf{M}ultiple \textbf{ANCOVA}) but we will not discuss them in this class.

\hypertarget{one-way-anova}{%
\section{One-way ANOVA}\label{one-way-anova}}

\hypertarget{overview-6}{%
\subsection{Overview}\label{overview-6}}

The one-way analysis of variance (ANOVA) is used to test the difference in our dependent variable between \underline{three or more} different groups of observations. Our grouping variable is our independent variable. In other words, we use the one-way ANOVA when we have a research question with a \textbf{continuous dependent variable} and a \textbf{categorical independent variable with three or more categories in which different participants are in each category}.

The one-way ANOVA is also known as an independent factor ANOVA.

One thing to keep in mind is the one-way ANOVA is an omnibus statistic that tests against the null hypothesis that the three or more means are the same. It does not tell us where the mean differences are (e.g., that 1 \textgreater{} 2); for that, we need planned contrasts or post-hoc procedures, which you'll learn about in the next chapter. Therefore, the null and alternative hypotheses for the one-way ANOVA are as follows:

\begin{itemize}
\tightlist
\item
  \(H_0\): There is \textbf{no difference} in means between the groups. In other words, the means for the three or more groups are the \textbf{same}.
\item
  \(H_1\): There is \textbf{a difference} in means between the groups. To find the difference, you need to conduct planned contrasts or use post-hoc procedures.
\end{itemize}

\hypertarget{why-not-multiple-t-tests}{%
\subsubsection{Why not multiple t-tests?}\label{why-not-multiple-t-tests}}

Imagine we have three groups: fall, spring, and summer. We could just perform three separate t-tests: fall vs.~spring, fall vs.~summer, and spring vs.~summer.

However, the reason we do not perform multiple t-tests is because multiple t-tests means an increased Type I error rate. If I had performed three separate t-tests, set my alpha (Type I error rate) at 5\% for each test, and knew for a fact the effects do not actually exist, then each test has a probability of a Type I error rate of 5\%. Because we are running three tests, our alpha rate actually becomes 1 - (.95\textsuperscript{3})= 1 - .857 = 14.3\%! So now our \emph{familywise} or \emph{experimentwise} error rate is 14.3\%, not the 5\% we originally set alpha at.

With three groups, that's not so bad, but let's see what happens with more tests we perform:

\begin{itemize}
\tightlist
\item
  \textbf{1 test}: 1 - (.95\textsuperscript{1})= 1 - .95 = \textbf{5\%}
\item
  \textbf{2 tests}: 1 - (.95\textsuperscript{2})= 1 - .9025 = \textbf{9.8\%}
\item
  \textbf{3 tests}: 1 - (.95\textsuperscript{3})= 1 - .857 = \textbf{14.3\%}
\item
  \textbf{4 tests}: 1 - (.95\textsuperscript{4})= 1 - .814 = \textbf{18.6\%}
\item
  \textbf{5 tests}: 1 - (.95\textsuperscript{5})= 1 - .774 = \textbf{22.6\%}
\item
  \textbf{10 tests}: 1 - (.95\textsuperscript{10})= 1 - .598 = \textbf{40.1\%}
\item
  \textbf{20 tests}: 1 - (.95\textsuperscript{20})= 1 - .358 = \textbf{64.1\%}
\end{itemize}

Ouch! 10 tests would have a Type I error rate of 40\%! That means that if we performed 10 statistical tests (assuming the effect does not exist), then 40\% of the results could be statistically significant by chance alone and would be a false positive. That's not good!

Therefore, we use the one-way ANOVA as one test to see if there is a difference overall. We can also do things to control or limit our familywise error rate, which I'll get into later.

\hypertarget{specify-your-hypotheses-4}{%
\subsection{Specify your hypotheses}\label{specify-your-hypotheses-4}}

For this chapter, we're going to work with example data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``clinicaltrial'' (not Clinical Trial 2). This dataset is hypothetical data of a clinical trial in which you are testing a new antidepressant drug called \emph{Joyzepam}. In order to construct a fair test of the drug's effectiveness, the study involves three separate drugs to be administered. One is a placebo, and the other is an existing antidepressant / anti-anxiety drug called \emph{Anxifree}. A collection of 18 participants with moderate to severe depression are recruited for your initial testing. Because the drugs are sometimes administered in conjunction with psychological therapy, your study includes 9 people undergoing cognitive behavioral therapy (CBT) and 9 who are not. Participants are randomly assigned (doubly blinded, of course) a treatment, such that there are 3 CBT people and 3 no-therapy people assigned to each of the 3 drugs. A psychologist assesses the mood of each person after a 3 month run with each drug, and the overall improvement in each person's mood is assessed on a scale ranging from -5 to +5.

Our hypotheses for the one-way ANOVA are pretty simple:

\begin{itemize}
\tightlist
\item
  \(H_0\): There is \textbf{no difference} in mood between the three drugs.
\item
  \(H_1\): There is \textbf{a difference} in nood between the three drugs. However, we'll need the next chapter to figure out where those differences might be.
\end{itemize}

\hypertarget{look-at-the-data-6}{%
\subsection{Look at the data}\label{look-at-the-data-6}}

\hypertarget{data-set-up-6}{%
\subsubsection{Data set-up}\label{data-set-up-6}}

To conduct the one-way ANOVA, we first need to ensure our data is set-up properly in our dataset. This requires having two columns: one with our continuous dependent variable and one indicating which group the participant is in. Each row is a unique participant or unit of analysis.

Note that in this dataset we actually have two independent variables: \texttt{drug} and \texttt{therapy}. If we were looking at the effect of \texttt{therapy} on \texttt{mood.gain} (our DV) then we would only need to perform an independent samples t-test because there are only two groups (no.therapy and CBT). However, if we were looking at the effect of \texttt{drug} on \texttt{mood.gain}, which is our goal in this chapter, then we would perform a one-way ANOVA because there are three groups (placebo, anxifree, and joyzepam).

\includegraphics{images/04_one-way-anova/anova_data.png}

\hypertarget{describe-the-data-4}{%
\subsubsection{Describe the data}\label{describe-the-data-4}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. We see that there are 18 cases in our dataset (a bit small, but let's ignore that for now) with no missing data. The mean mood gain was .88 (\emph{SD} = .53) with a minimum mood gain of .10 and maximum of 1.80. Furthermore, there are 6 people in each of our three conditions in the study so we have a \emph{balanced} research design.

\includegraphics{images/04_one-way-anova/anova_descriptives.png}

In addition, we may want to look at the distribution of mood gain across our three conditions. In the Descriptives analysis, we can choose to ``split by'' \texttt{drug} and then ask for a box plot with violin and data points like below. Visually, it seems like joyzepam might be leading to greater mood gain than the other two conditions, but we need to analyze it statistically to know for sure!

\includegraphics{images/04_one-way-anova/anova_graph.png}

\hypertarget{anova-assumptions}{%
\subsection{Check assumptions}\label{anova-assumptions}}

\hypertarget{assumptions-3}{%
\subsubsection{Assumptions}\label{assumptions-3}}

As a parametric test, the one-way ANOVA has the same assumptions as other parametric tests:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The dependent variable is \textbf{normally distributed}
\item
  Variances in the two groups are roughly equal (i.e., \textbf{homogeneity of variances})
\item
  The dependent variable is \textbf{interval or ratio} (i.e., continuous)
\item
  Scores are \textbf{independent} between groups
\end{enumerate}

We cannot \emph{test} the third and fourth assumptions; rather, those are based on knowing your data.

However, we can and should test for the first two assumptions. Fortunately, the one-way ANOVA in jamovi has three check boxes under ``Assumption Checks'' that lets us test for both assumptions.

\hypertarget{anova-is-somewhat-robust-to-violations}{%
\subsubsection{ANOVA is (somewhat) robust to violations}\label{anova-is-somewhat-robust-to-violations}}

Although we should meet the assumptions as much as possible, in general the F-statistic is \emph{robust} to violations of normality and homogeneity of variance. This means that you can still run the one-way ANOVA if you violate the assumptions, but \emph{only when group sizes and variances are equal or nearly equal}. If you have vastly different variances (such as 2:1 ratio or greater) or vastly different group sizes (such as a 2:1 ratio or greater), and especially if one group is really small (such as 10 or fewer cases), then your F-statistic is likely to be very wrong. For example, if your larger group has the larger variance, then your F-statistic is likely to be non-significant or smaller than it should be; however, if your larger group has smaller variance,then your F-statistic is likely to be significant or bigger than it should be!

\hypertarget{checking-assumptions-4}{%
\subsubsection{Checking assumptions}\label{checking-assumptions-4}}

We test for normality using the Shapiro-Wilk test and the Q-Q plot; we can also test it with skew/kurtosis and looking at the distribution of data. The Shapiro-Wilk test was not statistically significant (W = .96, \emph{p} = .605); therefore, this indicates the data is normally distributed. Furthermore, the lines are fairly close to the diagonal line in the Q-Q plot. We can conclude that we satisfy the assumption of normality.

We test for homogeneity of variance using the Levene's test. The Levene's test was not statistically significant (\emph{F} {[}2, 15{]} = 1.45, \emph{p} = .266); therefore, this indicates our data satisfies the assumption of homogeneity of variance. However, I would add a caveat that we have a small sample of data (\emph{N} = 18); we should have tried to collect more data.

\includegraphics{images/04_one-way-anova/one-way_assumptions1.png}

\includegraphics{images/04_one-way-anova/one-way_assumptions2.png}

\hypertarget{perform-the-test-6}{%
\subsection{Perform the test}\label{perform-the-test-6}}

\textbf{Note}: Do not use the one-way ANOVA analysis in jamovi! The options there are too limited for our use. Instead, be sure you use the ANOVA analysis!!!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  To perform a one-way ANOVA in jamovi, go to the Analyses tab, click the \textbf{ANOVA} button, and choose ``ANOVA''.
\item
  Move your dependent variable \texttt{mood.gain} to the Dependent Variable box and your independent variable \texttt{drug} to the Fixed Factors box.
\item
  Select \(\omega^2\) (omega-squared) for your effect size.
\item
  Ignore the Model drop-down menu. If you are doing more complicated ANOVAs you will need this. We will ignore it.
\item
  In the Assumption Checks drop-down menu, select all three options: \texttt{Homogeneity\ test}, \texttt{Normality\ test}, and \texttt{Q-Q\ plot}.
\item
  Ignore the Contrasts and Post Hoc Tests drop-down menus for now. See the next chapter for more information.
\item
  In the Estimated Marginal Means drop-down menu, move your IV \texttt{drug} to the Marginal Means box and select \texttt{Marginal\ means\ plots}, \texttt{Marginal\ means\ tables}, and \texttt{Observed\ scores}, in addition to the pre-selected \texttt{Equal\ cell\ weights}.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics{images/04_one-way-anova/one-way_setup.png}

\hypertarget{interpret-results-4}{%
\subsection{Interpret results}\label{interpret-results-4}}

Once we are satisfied we have satisfied the assumptions for the one-way ANOVA, we can interpret our results.

\includegraphics{images/04_one-way-anova/one-way_results.png}

Our p-value is less than our alpha value of .05, so our results are statistically significant.

\hypertarget{write-up-the-results-in-apa-style-6}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-6}}

\textbf{Note}: This is sufficient if your results are not statistically significant. If your F-test is statistically significant, then you also need to report the group differences as described in the next chapter!

We can write up our results in APA something like this:

\begin{quote}
There is a significant difference in mood gain across the three drug conditions, \emph{F} (2, 15) = 18.61, \emph{p} \textless{} .001, \(\omega^2\) = .66.
\end{quote}

Sometimes, people like to put the statistics inside a parentheses. In that case, you need to change the parentheses around the degrees of freedom as brackets. Here's another example write-up of the results in APA style:

\begin{quote}
There is a significant difference in mood gain across the three drug conditions (\emph{F} {[}2, 15{]} = 18.61, \emph{p} \textless{} .001, \(\omega^2\) = .66).
\end{quote}

\textbf{Note}: Again. this write-up \emph{is not sufficient!!!} We need to add the stuff in the next chapter on group differences because our results are statistically significant. Otherwise, we could have stopped here if it was not statistically significant.

\hypertarget{visualize-the-results-5}{%
\subsubsection{Visualize the results}\label{visualize-the-results-5}}

You should visualize the results similarly to how you visualize the results for the independent samples t-test. The default graph in the estimated marginal means output for the ANOVA is not great in my opinion. Presenting the graph of the data in this case (see the graph under Look at the Data) is probably a better option.

\hypertarget{in-case-of-violated-assumptions-4}{%
\subsection{In case of violated assumptions}\label{in-case-of-violated-assumptions-4}}

The great news is that jamovi includes the Welch's F-statistic and the Kruskal-Wallis non-parametric test! The bad news is that you lose some functionality in jamovi when you use them because we use the One-Way ANOVA function instead of the ANOVA function.

As always, there is also the option to transform your data or remove outliers as an option before moving to the non-parametric statistical test. Refer back to the ``violated assumptions'' section of the inferential statistics chapter to remember how to transform your data!

Just like with the Welch's t-statistic (for the independent t-test), it does not have the assumption of equal variances so it's appropriate to use if your data is normally distributed but does not have homogeneous variances. Similarly, the Kruskal-Wallis test is the non-parametric version of the one-way ANOVA and should be used if you do not satisfy the assumption of normality.

Here's what statistic you should choose based on satisfying assumptions:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.30}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.35}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.35}}@{}}
\toprule
& \textbf{Normality: satisfied} & \textbf{Normality: not satisfied} \\
\midrule
\endhead
\textbf{Homogeneity of Variance: satisfied} & one-way ANOVA (but using the ANOVA function) & Kruskal-Wallis (using the one-way ANOVA function) \\
\textbf{Homogeneity of Variance: not satisfied} & Welch's F-test (using the one-way ANOVA function) & Kruskal-Wallis (using the one-way ANOVA function) \\
\bottomrule
\end{longtable}

\hypertarget{welchs-f-test}{%
\subsubsection{Welch's F-test}\label{welchs-f-test}}

To conduct this in jamovi, you will need to use the ``One-Way ANOVA'' test, not the ``ANOVA'' test. The unfortunate thing about this test is that it strangely does not provide effect sizes.

In jamovi, under Variances select \texttt{Don\textquotesingle{}t\ assume\ equal\ (Welch\textquotesingle{}s)}. Move \texttt{mood.gain} to the Dependent Variable box and \texttt{drug} to your Grouping Variable box. You will interpret the results similarly to the one-way ANOVA:

\includegraphics{images/04_one-way-anova/one-way_results_Welch.png}

\begin{quote}
Using a Welch's F-test, there is a significant difference in mood gain across the three drug conditions, \emph{F} (2, 9.49) = 26.32, \emph{p} \textless{} .001.
\end{quote}

\hypertarget{kruskal-wallis-test}{%
\subsubsection{Kruskal-Wallis test}\label{kruskal-wallis-test}}

To perform the Kruskal-Wallis test in jamovi, you will need to select under the ANOVA button ``One-Way ANOVA, Kruskal Wallis'' towards the bottom of the list of options. Move \texttt{mood.gain} to the Dependent Variables box and \texttt{drug} to the Grouping Variable box. Select Effect size; if you need post hoc comparisons select DSCF pairwise comparisons (see section below on group differences). You will interpret the results similarly to the one-way ANOVA:

\includegraphics{images/04_one-way-anova/one-way_results_Kruskal.png}

\begin{quote}
Using a Kruskal-Wallis test, there is a significant difference in mood gain across the three drug conditions, \(\chi^2\) (2) = 12.08, \emph{p} = .002, \(\epsilon^2\) = .71.
\end{quote}

Notice how in this case all three results converge and show there is a statistically significant difference in the results! The problem is\ldots{} differences in which groups? See the next chapter!

\hypertarget{additional-information-3}{%
\subsection{Additional information}\label{additional-information-3}}

\hypertarget{relationship-between-anova-and-t-test}{%
\subsubsection{Relationship between ANOVA and t-test}\label{relationship-between-anova-and-t-test}}

An ANOVA with two groups is identical to the t-test. That means the F and t statistics are directly related, and you will get the same p-value. For example, imagine you run a t-test and get a t-statistic of \emph{t} (16) = -1.31, \emph{p} = .210. If you ran it as a one-way ANOVA, you would get an F-statistic of \emph{F} (1, 16) = 1.71, \emph{p} = .210.

\(F = t^2\)

\(t = \sqrt{F}\)

Just a fun little bit of trivia! So if you accidentally do an F-test with two groups, no need to go back and redo the analyses (although you should if you are sharing your code for reproducibility). You can just convert your F to a t statistic easily!

\hypertarget{a-note-on-one-tailed-vs.-two-tailed-tests-in-the-anova}{%
\subsubsection{A note on one-tailed vs.~two-tailed tests in the ANOVA}\label{a-note-on-one-tailed-vs.-two-tailed-tests-in-the-anova}}

Unlike a t-test, we can't have a one-tailed test with an ANOVA. Our planned contrasts or post-hoc tests can tell us where differences are, and we can provide directional hypotheses there if we so choose.

\hypertarget{your-turn-5}{%
\subsection{Your turn!}\label{your-turn-5}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

Perform one-way ANOVAs based on the following research questions. Check your assumptions and ensure you are using the correct tests.

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Does students differ on English scores by rank (i.e., freshmen, sophomore, junior, senior)?}

  \begin{itemize}
  \item
    Do you satisfy the assumption of normality?
  \item
    Do you satisfy the assumption of homogeneity of variance?
  \item
    Which statistic should you use?
  \item
    Do students differ on English scores by rank?
  \end{itemize}
\item
  \textbf{Does smoking status (Smoking: Nonsmoker = 0, Past smoker = 1, Current smoker = 2) relate to sprint time?}

  \begin{itemize}
  \item
    Do you satisfy the assumption of normality?
  \item
    Do you satisfy the assumption of homogeneity of variance?
  \item
    Which statistic should you use?
  \item
    Does smoking status relate to sprint time?
  \end{itemize}
\end{enumerate}

\hypertarget{finding-group-differences}{%
\section{Finding Group Differences}\label{finding-group-differences}}

Often, we're not interested in just \emph{whether} there is a difference (which the F-statistic can tell us), but \emph{where} the differences are between groups (which the F-statistic cannot tell us). For that, we use either \underline{planned contrasts} when you have specific hypotheses you want to test or \underline{post-hoc comparisons} when you have no specific hypotheses.

\textbf{Note}: You \underline{do not} perform contrasts or post hoc comparisons if your overall \(F\) statistic is not statistically significant. You do not interpret group differences if you fail to reject the null hypothesis that there are no group differences!

Below I provide descriptive statistics for these results. You can get this information in jamovi either by asking for descriptives from the exploration tab, or by asking for the estimated marginal means tables in the ANOVA analysis.

\hypertarget{planned-contrasts}{%
\subsection{Planned Contrasts}\label{planned-contrasts}}

If you have before-analysis hypotheses of group differences in your data, you will use planned contrasts. You can find the planned contrasts in the ANOVA (but not the one-way ANOVA) setup as a drop-down menu. Note that while I show all six contrasts that jamovi provides, you do not normally do multiple contrasts. These are just shown for illustrative purposes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Deviation}: compares the effect of each category (except the first category) to the overall experimental effect. The order of categories is alphabetical or numerical order. Notice how anxifree is considered the first category.

  \includegraphics{images/04_one-way-anova/contrasts_deviation.png}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \textbf{Simple}: Each category is compared to the first category. The order of categories is alphabetical or numerical order. Notice how anxifree is considered the first category.

  \includegraphics{images/04_one-way-anova/contrasts_simple.png}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  \textbf{Difference}: Each category (except the first) is compared to the mean effect of all previous categories.

  \includegraphics{images/04_one-way-anova/contrasts_difference.png}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  \textbf{Helmert}: Each category (except the last) is compared to the mean effect of all subsequent categories.

  \includegraphics{images/04_one-way-anova/contrasts_helmert.png}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  \textbf{Repeated}: Each category is compared to the last category.

  \includegraphics{images/04_one-way-anova/contrasts_repeated.png}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\item
  \textbf{Polynomial}: Tests trends in the data. It will examine the \emph{n-1}\textsuperscript{th} degree based on the number of groups. In this case, because we have 3 groups it is testing both a linear (\textsuperscript{1}) and quadratic (\textsuperscript{2}) trend. If we had 5 groups, it would test a linear (\textsuperscript{1}), quadratic (\textsuperscript{2}), cubic (\textsuperscript{3}), and quartic (\textsuperscript{4}) trend. Note that your factor levels must be ordinal for a polynomial contrast to make sense.

  \includegraphics{images/04_one-way-anova/contrasts_polynomial.png}
\end{enumerate}

\textbf{Test yourself!} Which contrast do you think would make \underline{most sense} to test given that we want to know how our drug compares to the other two drugs?

\hypertarget{write-up-planned-contrasts-in-apa-style}{%
\subsubsection{Write up planned contrasts in APA style}\label{write-up-planned-contrasts-in-apa-style}}

Here's some example write-ups of the above results.

\begin{quote}
There is a significant difference in mood gain across the three drug conditions, \emph{F} (2, 15) = 18.61, \emph{p} \textless{} .001. Repeated contrasts showed that \emph{Joyzepam} (\emph{M} = 1.48, \emph{SD} = .21) outperformed both \emph{Anxifree} (\emph{M} = .72, \emph{SD} = .39; \emph{p} \textless{} .001) and the placebo condition (\emph{M} = .45, \emph{SD} = .28; \emph{p} \textless{} .001).
\end{quote}

Note how this next example makes no sense because our data is not ordinal, but here's an example polynomial write-up:

\begin{quote}
There is a significant difference in mood gain across the three drug conditions, \emph{F} (2, 15) = 18.61, \emph{p} \textless{} .001. There was not a significant linear trend across the drug conditions (\emph{p} = .150).
\end{quote}

\hypertarget{post-hoc-comparisons}{%
\subsection{Post hoc comparisons}\label{post-hoc-comparisons}}

Sometimes, we do not have any \emph{a priori} (or planned) predictions or hypotheses about our group differences. In this case, we use post hoc procedures. These procedures do \underline{pairwise comparisons} among all of our groups, like t-tests across each of our groups. As we noted on the first page of this handout, this can be highly problematic for our Type I error rate! Therefore, we must perform corrections to control our familywise error rate.

jamovi currently supports five types of post-hoc tests; I generally only use Tukey or Bonferonni:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{No correction}: This doesn't correct for a Type I error at all. Don't use this! I won't even show it. It's bad. Never use it. NEVER. You are warned!
\item
  \textbf{Tukey}: This is the post hoc test I use most often. It controls the Type I error rate well, but isn't as conservative of a control as the Bonferonni.
\item
  \textbf{Scheffe}: Honestly, I've never used it. I am not sure how it's calculated. Fortunately, we have other tests that work just fine for us (:
\item
  \textbf{Bonferroni}: This is the most conservative test. It's good if you only have a small number of comparisons to make or if you \emph{really} want to control your Type I error rate. If you have a lot of them to test , then you should use something else.
\item
  \textbf{Holm}: Honestly, I've never used it. I am not sure how it's calculated. Fortunately, we have other tests that work just fine for us (:
\end{enumerate}

Games-Howell for when you have unequal variances and Tukey for when you have equal variances. They will each calculate your p-values slightly differently but in a way to control for our Type I error rate as best it can. They are interpreted very similarly, so we will proceed with the Tukey's post hoc comparisons because we satisfied the assumption of equal variances.

To request post hoc tests from the one-way ANOVA, open the collapsed menu at the bottom of the setup menu. Select \texttt{Tukey\ (equal\ variances} under Post-Hoc Test and select \texttt{Mean\ difference}, \texttt{Report\ significance}, and \texttt{Flag\ significant\ comparisons} under Statistics. Optionally, you can request the \texttt{Test\ results\ (t\ and\ df)} although this is not necessary.

Below shows the post hoc test results for our one-way ANOVA. Notice the differences in p-values across the four post hoc tests and how all other values are the same. Notice how the Bonferroni is most conservative (i.e., has the largest p-values) and the Holm's is the least conservative (i.e., has the smallest p-values). Keep in mind you do not normally ask for multiple post hoc comparisons. Just pick one! Normally, I just pick Tukey's.

\includegraphics{images/04_one-way-anova/one-way_results_post-hoc.png}

\hypertarget{write-up-post-hoc-results-in-apa-style}{%
\subsubsection{Write up post hoc results in APA style}\label{write-up-post-hoc-results-in-apa-style}}

The way we would write up each of the post hoc comparisons is very similar. Given that I usually use Tukey, here is a write-up for those results:

\begin{quote}
There is a significant difference in mood gain across the three drug conditions, \emph{F} (2, 15) = 18.61, \emph{p} \textless{} .001. Post hoc comparisons using Tukey's HSD revealed that our drug \emph{Joyzepam} (\emph{M} = 1.48, \emph{SD} = .21) outperformed both \emph{Anxifree} (\emph{M} = .72, \emph{SD} = .39; \emph{p} = .002) and the placebo condition (\emph{M} = .45, \emph{SD} = .28; \emph{p} \textless{} .001); there were no differences between \emph{Anxifree} and the placebo condition (\emph{p} = .312).
\end{quote}

Writing up results in APA style is both a science and an art. There's a science to what you need to report. For example, you always report the statistics exactly the same: \emph{F} (df\textsubscript{WG}, df\textsubscript{BG}) = X.XX, \emph{p} = .XXX. You also always report the group means (\emph{M}) and standard deviations (\emph{SD}), although you can report them in-text like I did above or in a descriptives table like you can ask from jamovi.

However, there's also an art to it. Notice how I wrote that up in a way to summarize the findings as succinctly as possible. I could have said there was a difference between \emph{anxifree} and \emph{joyzepam} and a difference between \emph{joyzepam} and the placebo, but that's a lot more words and isn't written in a way to focus on what I'm hoping to see: that my drug \emph{joyzepam} performed better than the competitor \emph{anxifree} and a placebo condition.

This is where you need to think creatively and be very critical in checking that what you say makes sense. Read your write-ups carefully! Have someone else read it. Can they understand what you mean?

\hypertarget{video-6}{%
\subsection{Video}\label{video-6}}

Here's a video walking through the one-way ANOVA test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=NBxLBXtvp8E"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{in-case-of-violated-assumptions-5}{%
\subsection{In case of violated assumptions}\label{in-case-of-violated-assumptions-5}}

If you are using Welch's F-test using the One-Way ANOVA in jamovi, you should select under Post-Hoc Tests \texttt{Games-Howell\ (unequal\ variances)}. These will be interpreted similarly to the post hoc comparisons above.

If you are using the Kruskal-Wallis test, you will select the check-box for \texttt{DSCF\ pairwise\ comparisons}. This stands for the Dwass-Steel-Critchlow-Fligner test. All you need to know is that they, too, are interpreted similarly to the post hoc comparisons above.

Unfortunately, you cannot perform contrasts with either the Welch's F-test or Kruskal-Wallis test.

\hypertarget{your-turn-6}{%
\subsection{Your turn!}\label{your-turn-6}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

Perform one-way ANOVAs based on the following research questions. Check your assumptions and ensure you are using the correct tests.

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\textbf{Note}: These are the same questions as in the one-way ANOVA chapter, but now you focus on the group differences.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Does students differ on English scores by rank (i.e., freshmen, sophomore, junior, senior)?}

  \begin{itemize}
  \tightlist
  \item
    Perform Tukey's post hoc tests. What are the results of the post hoc comparison?
  \end{itemize}
\item
  \textbf{Does smoking status (Smoking: Nonsmoker = 0, Past smoker = 1, Current smoker = 2) relate to sprint time?}

  \begin{itemize}
  \tightlist
  \item
    Perform Tukey's post hoc tests. What are the results of the post hoc comparison?
  \end{itemize}
\end{enumerate}

\hypertarget{repeated-measures-anova}{%
\section{Repeated Measures ANOVA}\label{repeated-measures-anova}}

\hypertarget{overview-7}{%
\subsection{Overview}\label{overview-7}}

The repeated measures analysis of variance (ANOVA) is used to test the difference in our dependent variable between \underline{three or more} groups of observations in which all participants participate in all groups or levels. Our grouping variable is our independent variable. In other words, we use the one-way ANOVA when we have a research question with a \textbf{continuous dependent variable} and a \textbf{categorical independent variable with three or more categories in which the \underline{same} participants are in each category}.

The repeated measures ANOVA is also sometimes called the one-way related ANOVA.

There are two ways we could have the repeated measures ANOVA. Perhaps the same group of participants are measured in the same dependent variable at three or more time points. In this case, our independent variable is time and our dependent variable is whatever is measured at each time point.

\includegraphics{images/05-repeated-measures-anova/Laerd1.png}

The other way we might have the repeated measures ANOVA is if all our participants participate in all conditions of our study. In this case, our independent variable is the treatment or condition and the dependent variable is whatever is measured in each treatment or condition.

\includegraphics{images/05-repeated-measures-anova/Laerd2.png}

\hypertarget{specify-your-hypotheses-5}{%
\subsection{Specify your hypotheses}\label{specify-your-hypotheses-5}}

Let's run an example with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``broca''.

This dataset is hypothetical data in which six patients suffering from Broca's Aphasia (a language deficit commonly experienced following a stroke) complete three word recognition tasks. On the first (speech production) task, patients were required to repeat single words read out aloud by the researcher. On the second (conceptual) task, designed to test word comprehension, patients were required to match a series of pictures with their correct name. On the third (syntax) task, designed to test knowledge of correct word order, patients were asked to reorder syntactically incorrect sentences. Each patient completed all three tasks. The order in which patients attempted the tasks was counterbalanced between participants. Each task consisted of a series of 10 attempts. The number of attempts successfully completed by each patient are provided in the dataset.

Just like the one-way ANOVA, we have fairly simple hypotheses for the basic repeated measures ANOVA:

\begin{itemize}
\tightlist
\item
  \(H_0\): There is \textbf{no difference} in word recognition across the three tasks.
\item
  \(H_1\): There is \textbf{a difference} in word recognition across the three tasks.
\end{itemize}

\hypertarget{look-at-the-data-7}{%
\subsection{Look at the data}\label{look-at-the-data-7}}

\hypertarget{data-set-up-7}{%
\subsubsection{Data set-up}\label{data-set-up-7}}

To conduct the repeated measures ANOVA, we first need to ensure our data is set-up properly in our dataset. This requires multiple columns, one for each condition or time measurement, with the values indicating the measurement of the DV for that condition or time. Each row is a unique participant or unit of analysis.

So for our broca dataset, we have our Participant column indicating their participant number and then one column for each of the three word recognition tasks (speech, conceptual, syntax), with their scores on the knowledge test indicating the dependent variable for each condition.

\includegraphics{images/05-repeated-measures-anova/rm_data.png}

In the data above, what is your \textbf{independent variable}? What is your \textbf{dependent variable}?

\hypertarget{describe-the-data-5}{%
\subsubsection{Describe the data}\label{describe-the-data-5}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. We see that there are only six cases total (oof, really small data set!) and the average test score on each of the three conditions. It appears participants did best on the speech condition, but we'll need to run our repeated measures ANOVA to know for sure.

\includegraphics{images/05-repeated-measures-anova/rm_descriptives.png}

\hypertarget{check-assumptions-5}{%
\subsection{Check Assumptions}\label{check-assumptions-5}}

\hypertarget{assumptions-4}{%
\subsubsection{Assumptions}\label{assumptions-4}}

As a parametric test, the repeated measures ANOVA has the same assumptions as other parametric tests:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The dependent variable is \textbf{normally distributed}
\item
  Variances in the two groups are roughly equal (i.e., \textbf{homogeneity of variances}); in repeated measures ANOVA this is called the assumption of \textbf{sphericity}
\item
  The dependent variable is \textbf{interval or ratio} (i.e., continuous)
\item
  \sout{Scores are \textbf{independent} between groups} (this assumption is not relevant because all participants participate in all conditions)
\end{enumerate}

We cannot \emph{test} the third and fourth assumptions; rather, those are based on knowing your data.

However, we can and should test for the first two assumptions. Fortunately, the one-way ANOVA in jamovi has three check boxes under ``Assumption Checks'' that lets us test for both assumptions.

\hypertarget{what-is-the-sphericity-assumption}{%
\paragraph{What is the Sphericity Assumption?}\label{what-is-the-sphericity-assumption}}

The sphericity assumption is essentially the repeated measures ANOVA equivalent of homogeneity of variances. Sphericity means there is equality of variances of the \emph{differences} between treatment levels. For example, if there are three groups, then the difference in all three pairs of differences (1-2, 1-3, 2-3) need to have approximately equal variances. You only need to care about sphericity when there are at least three conditions, which is why we did not talk about this with the dependent t-test.

Fortunately, like the other assumption checks, testing for sphericity is as simple as a checkbox in jamovi.

\hypertarget{checking-assumptions-5}{%
\subsubsection{Checking assumptions}\label{checking-assumptions-5}}

We check assumptions using the ``Assumption Checks'' tab under the repeated measures ANOVA function.

To test normality, we select Q-Q plot. It is currently the only option we have available for testing normality in the repeated measures ANOVA.

So what we need to worry about is testing our assumption of sphericity. You should have checked the box \texttt{Sphericity\ tests} under the Assumption Checks drop-down menu. That produces the following output:

\includegraphics{images/05-repeated-measures-anova/rm-anova_sphericity.png}

Mauchly's test of sphericity tests the null hypothesis that the variances of the differences between the conditions are equal. Therefore, just like with our previous assumption checks, if Mauchly's test is non-significant (i.e., \emph{p} \textgreater{} .05, as is the case in this analysis) then it is reasonable to conclude that the variances of the differences are not significantly different. This means we satisfy the assumption of sphericity and can conclude that the variances of the differences are roughly equal.

If Mauchly's test had been statistically significant (\emph{p} \textless{} .05), then we would conclude that the assumption had \emph{not} been met. In that case, we would apply a correction to the \emph{F}-value obtained in the repeated measures ANOVA:

\begin{itemize}
\tightlist
\item
  If sphericity is violated and if the Greenhouse-Geisser value in the ``Tests of Sphericity'' table is \textgreater{} .75 then you should select the Huynh-Feldt correction and de-select the None option.
\item
  If sphericity is violated and if the Greenhouse-Geisser value is \textless{} .75, then you should select the Greenhouse-Geisser correction and de-select the None option.
\item
  If sphericity is not violated, then only select the None option.
\end{itemize}

You can select these corrections in the Assumption Checks drop-down menu.

\hypertarget{perform-the-test-7}{%
\subsection{Perform the test}\label{perform-the-test-7}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  To perform a repeated measures ANOVA in jamovi, go to the Analyses tab, click the ANOVA button, and choose ``Repeated Measures ANOVA''.
\item
  Under ``Repeated Measures Factors'' name your independent variable. In this case you can name it ``Task''. Rename the three levels of Task: Speech, Conceptual, and Syntax.
\item
  Under ``Repeated Measures Cells'' move the given variable into the correct level. For example, you'll move Speech to the Speech cell.
\item
  Select Generalised \(\eta^2\) as your measure of effect size.
\item
  In the Assumption Checks drop-down menu, select \texttt{Sphericity\ tests} and \texttt{Q-Q\ Plots}. You'll note that if you violate the assumption of sphericity, there are two corrections provided. These are described above.
\item
  In the Post Hoc Tests drop-down menu, select \texttt{Tukey}. Remember that we only interpret these if the overall \emph{F} is statistically significant.
\item
  In the Estimated Marginal Means drop-down menu, move Task to the Marginal Means box, select \texttt{Marginal\ means\ tables}, and select \texttt{Observed\ scores} . Uncheck \texttt{Equal\ cell\ weights}.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics{images/05-repeated-measures-anova/rm-anova_setup1.png}

\includegraphics{images/05-repeated-measures-anova/rm-anova_setup2.png}

\hypertarget{interpret-results-5}{%
\subsection{Interpret results}\label{interpret-results-5}}

Once we are satisfied we have satisfied the assumptions for the repeated measures, we can interpret our results.

\includegraphics{images/05-repeated-measures-anova/rm-anova_results.png}

You'll notice that jamovi provides you both a Within Subjects Effects table and Between Subjects Effects table. However, we only have a within-subjects effect (Task). Why did it give us a between-subjects table? With the repeated-measures ANOVA (which only has within-subjects IVs), this is just our \(SS_{BG}\). However, because we don't have one, it's not calculating anything. We can ignore it. It is only useful if we are conducting a mixed factorial ANOVA with both between-subjects and within-subjects effects (see chapter 9.4 on the factorial ANOVA).

Therefore, the Within Subjects Effects table is of most use to us. We can see that the overall effect of Task is statistically significant (\emph{p} = .013). Therefore we can look at our Post Hoc Tests results.

\includegraphics{images/05-repeated-measures-anova/rm-anova_tukey.png}

The Tukey post hoc differences show that there was a significant difference between speech and syntax (\emph{p} = .011), but not between conceptual and both speech and syntax. Last, we can look at the Estimated Marginal Means - Task table to see the group means for reporting purposes. This shows us that participants recognized significantly more words in the speech task than in the syntax task.

\hypertarget{write-up-the-results-in-apa-style-7}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-7}}

We can write this up in APA style similar to the one-way ANOVA.

\begin{quote}
A repeated measures ANOVA was performed examining how three tasks affected word recognition in patients suffering from Broca's Aphasia. Task significantly affected word recall, \emph{F} (2, 10) = 6.93, \emph{p} = .013, \(\eta^2_G\) = .41. Tukey's post hoc difference tests indicated that participants recognized significantly more words in the speech task (\emph{M} = 7.17, \emph{SE} = .62) than participants in the syntax task (\emph{M} = 4.33, \emph{SE} = .62; \emph{p}~= .011). There were no differences between the conceptual task (\emph{M} = 6.17, \emph{SE} = .62) and both the speech and syntax tasks.
\end{quote}

\hypertarget{visualize-the-results-6}{%
\subsubsection{Visualize the results}\label{visualize-the-results-6}}

Similar to the dependent t-test, I am not a fan of the output for the repeated measures ANOVA in jamovi under ``estimated marginal means.'' You could modify the same syntax for the dependent t-test (you'll need to change line 3 to be sure you're picking the correct lines of data, not just 2:3, and revise the names and such. You could also move the data into Excel and do bar graphs with error bars there instead.

\hypertarget{video-7}{%
\subsection{Video}\label{video-7}}

Here's a video walking through the repeated measures ANOVA test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=Fl6S9IBC1q0"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{in-case-of-violated-assumptions-6}{%
\subsection{In case of violated assumptions}\label{in-case-of-violated-assumptions-6}}

Here's what statistic you should choose based on satisfying assumptions:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.25}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.51}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.24}}@{}}
\toprule
& \textbf{Normality: satisfied} & \textbf{Normality: not satisfied} \\
\midrule
\endhead
\textbf{Sphericity: satisfied} & Repeated measures ANOVA & Friedman's test \\
\textbf{Sphericity: not satisfied} & Repeated measures ANOVA with one of the sphericity corrections & Friedman's test \\
\bottomrule
\end{longtable}

We have already discussed what to do if you violate the assumption of sphericity above; you select one of the two sphericity corrections based on the values of the sphericity tests.

If you violate the assumption of normality or if the dependent variable is ordinal, then you can use the Friedman test. You can select this using the Repeated Measures ANOVA - Friedman option under the ANOVA analysis.

\hypertarget{friedmans-test}{%
\subsubsection{Friedman's test}\label{friedmans-test}}

Friedman's test can only examine one within-subjects variable, so you will move all three conditions (Speech, Conceptual, and Syntax) to the Measures box. Select \texttt{Pairwise\ comparisons\ (Durbin-Conover} for post hoc comparisons and \texttt{Descriptives} for the Means and Medians. Optionally, you can select to plot either the Means or Medians. The setup is shown below.

\includegraphics{images/05-repeated-measures-anova/rm-anova_friedman_setup.png}

Once you've set-up the analysis, you can interpret the results. Overall, we continue to see a statistically significant result and that there is only a significant difference between speech and syntax.

\includegraphics{images/05-repeated-measures-anova/rm-anova_friedman.png}

We can write up the results similarly as before except using the median because as a non-parametric test it is analyzing the median and not the mean:

\begin{quote}
Friedman's test was performed examining how three tasks affected word recognition in patients suffering from Broca's Aphasia. Task significantly affected word recall, \(\chi^2\) (2) = 6.64, \emph{p} = .036. Pairwise comparisons using Durbin-Conover indicated that participants recognized significantly more words in the speech task (\emph{M} = 7.17, \emph{Mdn} = 7.50) than participants in the syntax task (\emph{M} = 4.33, \emph{Mdn} = 6.50; \emph{p} = .006). There were no differences between the conceptual task (\emph{M} = 6.17, \emph{Mdn} = 6.50) and both the speech and syntax tasks.
\end{quote}

\hypertarget{your-turn-7}{%
\subsection{Your turn!}\label{your-turn-7}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

Perform a repeated measures ANOVA based on the following research questions. Check your assumptions and ensure you are using the correct tests.

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Does students differ on their test scores (English, Reading, Math, Writing)?}

  \begin{itemize}
  \item
    Based on your understanding of the nature of the test scores, which statistic should you use?
  \item
    Should you apply a sphericity correction? If so, which one?
  \item
    Do students differ on their test scores?
  \item
    Should you perform a planned contrast or post hoc comparison?
  \item
    What are the results of the post hoc comparison?
  \end{itemize}
\end{enumerate}

\hypertarget{factorial-anova}{%
\section{Factorial ANOVA}\label{factorial-anova}}

\hypertarget{overview-8}{%
\subsection{Overview}\label{overview-8}}

Factorial ANOVA allows us to examine two or more independent variables (IVs) simultaneously. There are several types of factorial designs:

\begin{itemize}
\tightlist
\item
  \textbf{Independent factorial design}: several between-group (independent) IVs
\item
  \textbf{Repeated measures factorial design}: several within-group (repeated-measures) IVs
\item
  \textbf{Mixed factorial design}: some between-group and some within-group IVs
\end{itemize}

Furthermore, you may read about ANOVAs referred to as ``one-way'', ``two-way'', ``three-way'' or greater. This simply refers to how many independent variables there are. Factorial ANOVAs are sometimes also referenced by how many groups per IV there are; for example, a 2 x 3 ANOVA is a factorial ANOVA in which the first IV has two conditions and the second IV has three conditions. You would also specify which IVs are between-group and which are within-group. For example, you might write that your design is a 2 (between-subjects: gender) x3 (within-subjects: task) mixed factorial.

We won't be going into too much detail on the different factorial ANOVA designs. Instead, I will walk through illustrative cases so that if you want to apply them in the future you can mimic the procedures below.

\hypertarget{independent-factorial-anova}{%
\subsection{Independent Factorial ANOVA}\label{independent-factorial-anova}}

The independent factorial ANOVA has multiple between-group IVs. Let's run an example with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``rtfm''. This data has two IVs: attend (whether or not the student turned up to lectures) and reading (whether or not the student actually read the textbook). 1 = they did and 0 = they did not.

Because we do not have a within-group IV, we will select the ANOVA analysis. Move grade to your Dependent Variable box and both attend and reading to your Fixed Factors. Select all the same options as you did for the one-way ANOVA (i.e., \(\omega^2\), assumption checks, Tukey's post hoc tests for the two variables attend and reading, estimated marginal means).

Let's go through the output (check that your output matches!) and then discuss how to write up the results in APA format. First, we need to check assumptions. The Levene's test and Shapiro-Wilk's test are shown below. We can see that we meet the assumption of normality but fail to meet the assumption of homogeneity of variance. Unfortunately, we cannot perform a Welch's F-test with more than one independent factorial so we will note this failed assumption and move on.

\includegraphics{images/06-factorial-anova/independent-factorial_assumptions.png}

Let's look at the main results next. We got three lines of results in addition to the typical residuals (error). The first two lines are our main effects of \texttt{attend} and \texttt{reading} on grades. The p-values for both are statistically significant indicating attend affects grades and reading affects grades. However, it also added an interaction term of \texttt{attend\ *\ reading}, which is not statistically significant. This means we do not have an interaction between attend and reading on grades. Interactions will be discussed in more detail in the next section.

\includegraphics{images/06-factorial-anova/independent-factorial_results.png}

Although we could simply look at the means to know whether attending or reading had higher grades than not attending or not reading because there are only two conditions, we can also look at the post hoc tests and definitely need to look at them if we have three or more conditions per IV. These are shown below. Because the mean differences are negative, we can determine that the second group had higher means than the first group. We can confirm that with the estimated marginal means (not shown here).

\includegraphics{images/06-factorial-anova/independent-factorial_posthoc.png}

Last, we can write-up our results!

\begin{quote}
We were interested in knowing how attendance and reading affected student grades. An independent factorial ANOVA showed that both attendance (\emph{F} {[}1, 4{]} = 18.25, \emph{p} = .013, \(\omega^2\) = .26) and reading (\emph{F} {[}1, 4{]} = 44.17, \emph{p} = .003, \(\omega^2\) = .64) affected student grades; there was no significant interaction between attendance and reading (\emph{F} {[}1, 4{]} = 8.00, \emph{p} = .660, \(\omega^2\) = -.01). Post hoc comparisons using Tukey's HSD show that students who attended lectures (\emph{M} = 75.50, \emph{SE} = 2.98) had higher grades than students who did not (\emph{M}~= 57.50, \emph{SE} = 2.98; \emph{p} = .003, \emph{d} = 4.70); furthermore, students who read (\emph{M} = 80.50, \emph{SE} = 2.98) had higher grades than students who did not (\emph{M} = 52.50, \emph{SE} = 2.98; \emph{p} = .013; \emph{d} = 3.02).
\end{quote}

\hypertarget{interactions}{%
\subsubsection{Interactions}\label{interactions}}

Interactions occur when the effect of one IV on the DV depends on the lvel of the other IV. If you did not want to test for interaction effects, you could remove them from the Model Terms in the Model drop-down menu.

However, by default they will include them. If you have 2-3 IVs, it may be reasonable to look at these interactions. However, 3-variable interactions (e.g., IV1 * IV2 * IV3) are pushing it and 4-variable interactions are highly implausible. Be critical in which interaction terms you include!

jamovi can provide a plot of your interaction, which can be helpful to help interpret your results. Below is the plot for our interaction of attendance on reading.

\includegraphics{images/06-factorial-anova/independent-factorial_plot.png}

The parallel lines that are sloping upward tell me there is a significant main effect for both IVs but no interaction. How do I know that? With two variables, there are only so many interaction shapes possible. \href{https://courses.washington.edu/smartpsy/interactions.htm}{This website} does a fantastic time showing you all 8 combinations of the three effects (2 main effects and 1 interaction effect). Spend some time looking through it and familiarizing yourself with the plots!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=EynjbSDW56I"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{repeated-measures-factorial-anova}{%
\subsection{Repeated Measures Factorial ANOVA}\label{repeated-measures-factorial-anova}}

This is also sometimes called the two-way (or three-way or n-way, depending on the \emph{n} of IVs you have) repeated measures ANOVA. Let's go through an example repeated measures factorial ANOVA. The dataset is courtesy of \href{https://www.real-statistics.com/anova-repeated-measures/two-within-subjects-factors/}{Real Statistics Using Excel}.

\begin{quote}
A company has created a new training program for their customer service staff. To test the effectiveness of the program they took a sample of 10 employees and assessed their performance in three areas: ~Product (knowledge of the company's products and services), Client (their ability to relate to the customer with politeness and empathy) and Action (their ability to take action to help the customer). They then had the same 10 employees take the training course and rated their performance after the program in the same three areas. -\href{A\%20company\%20has\%20created\%20a\%20new\%20training\%20program\%20for\%20their\%20customer\%20service\%20staff.\%20To\%20test\%20the\%20effectiveness\%20of\%20the\%20program\%20they\%20took\%20a\%20sample\%20of\%2010\%20employees\%20and\%20assessed\%20their\%20performance\%20in\%20three\%20areas:\%20Product\%20(knowledge\%20of\%20the\%20companys\%20products\%20and\%20services),\%20Client\%20(their\%20ability\%20to\%20relate\%20to\%20the\%20customer\%20with\%20politeness\%20and\%20empathy)\%20and\%20Action\%20(their\%20ability\%20to\%20take\%20action\%20to\%20help\%20the\%20customer).\%20They\%20then\%20had\%20the\%20same\%2010\%20employees\%20take\%20the\%20training\%20course\%20and\%20rated\%20their\%20performance\%20after\%20the\%20program\%20in\%20the\%20same\%20three\%20areas.\%20Based\%20on\%20the\%20data\%20in\%20Figure\%201,\%20determine\%20whether\%20the\%20program\%20was\%20effective.}{Real Statistics Using Excel}
\end{quote}

You can find the dataset here to follow along: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Repeated-measures-factorial-ANOVA.xlsx}{Repeated-measures-factorial-ANOVA.xlsx Download}

In jamovi, select Repeated Measures ANOVA under the ANOVA analysis option. Here are the general steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In Repeated Measures Factors, you'll need to name both factors. Rename \texttt{RM\ Factor\ 1} to Time and \texttt{RM\ Factor\ 2} to Area. Under Time, specify two levels: Pre and Post. Under Area, specify three levels: Product, Client, and Action.
\item
  In Repeated Measures Cells, you'll now have six cells with the combinations of the 6 columns you have. Drag the variable from the left into the correct cell on the right. Be careful here! For example, you need to put the Pre-Product variable into the cell ``Pre, Product''.
\item
  Name your dependent variable label ``Performance'' and select `Generalised \(\eta^2\).
\item
  Under Assumption Checks, select Sphericity tests
\item
  Under Post Hoc Tests, move Area and Time over and select Tukey.
\item
  Under Estimated Marginal Means, move Time over into Term 1, Area into Term 2, and both Time and Area into Term 3. Select plots and tables, Observed scores, and Equal cell weights.
\end{enumerate}

Now let's go over selected output. First, we need to check our assumption of sphericity. All the Mauchly's W's are not statistically significant so we satisfy the assumption of sphericity and do not need to apply any sphericity corrections.

\includegraphics{images/06-factorial-anova/rm-factorial_assumption.png}

Next let's look at the within subjects effects table. Remember, we do not need to worry about the between subjects effects table because we do not have one; it will be used in the mixed factorial design below. Overall, we see a significant main effect of area, a significant main effect of time, and a significant interaction effect of both area and time. Neat!

\includegraphics{images/06-factorial-anova/rm-factorial_results.png}

Next, we can look at post hoc comparisons because the main effects were all statistically significant. For area, we can see that client and action had significantly higher means than product, but there was no difference between client and action. Furthermore, post-intervention performance was significantly higher than pre-intervention.

\includegraphics{images/06-factorial-anova/rm-factorial_tukey.png}

Last, let's look at the interaction to get a sense of what the interaction looks like. It appears that although there are no differences between pre- and post-intervention for product, there are significant differences from pre- to post-intervention for both client and action. To be more specific on where the statistically significant differences are, you can also ask for post hoc tests for the interaction term. This is where including a plot can be very helpful for your audience!

\includegraphics{images/06-factorial-anova/rm-factorial_interaction.png}

Now we have everything we need (in addition to the estimated marginal means) and can write-up our results.

\begin{quote}
We tested a 2 (time: pre- and post-intervention) x 3 (area: product, client, action) repeated measures factorial design to examine how both time and area affected performance. We satisfied the assumption of sphericity for all effects. There was a significant main effect of time (\emph{F} {[}1, 9{]} = 33.85, \emph{p} \textless{} .001, \(\eta^2_G\) = .25) such that performance at post-intervention (\emph{M} = 26.80, \emph{SE} = 1.84) was higher than at pre-intervention (\emph{M} = 19.37, \emph{SE} = 1.84). There was also a significant main effect of area (\emph{F} {[}2, 18{]} = 26.96, \emph{p} \textless{} .001, \(\eta^2_G\) = .36) such that both client (\emph{M} = 25.10, \emph{SE} = 1.95) and action (\emph{M} = 27.65, \emph{SE}~= 19.5) performance was higher than product performance (\emph{M} = 16.50, \emph{SE} = 1.95), but there was no difference between client and action performance. Lastly, there was a significant interaction between time and area such that there were no differences in product performance from pre- to post-intervention but there was for client and action performance (see Figure 1).
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=BQAFjSzoFHU"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\label{fig:unnamed-chunk-2}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{mixed-factorial-anova}{%
\subsection{Mixed Factorial ANOVA}\label{mixed-factorial-anova}}

You can find the dataset here to follow along: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/mixed-factorial.sav}{mixed-factorial.sav Download}

This dataset comes from a larger studying examining the effect of a delayed reward preference of three commodities (food, money, and music) on food cravings (as rated by the Food Craving Questionnaire {[}FCQ{]}) for each participant. Participants were in one of two conditions: the control condition did not do anything and the experimental condition had participants do the tasks while fasting.

Therefore, this study is a 2 (between-subjects: condition {[}control or fasting{]}) x 3 (within-subjects: reward {[}food, money, and music{]}) mixed factorial design.

To perform a mixed factorial ANOVA, we use the same procedures as the repeated measures ANOVA but we also need to add a between-subjects factor.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  To perform a mixed factorial ANOVA in jamovi, go to the Analyses tab, click the ANOVA button, and choose ``Repeated Measures ANOVA''.
\item
  Under ``Repeated Measures Factors'' name your independent variable. In this case you can name it ``Reward''. Rename the three levels of Task: Food, Money, and Music.
\item
  Under ``Repeated Measures Cells'' move the given variable into the correct level. For example, you'll move FQ\_1 to Food, FQ\_2 to Money, and FQ\_3 to Music.
\item
  Under ``Between Subject Factors'' add your between-subjects variable "condition.
\item
  Select Generalised \(\eta^2\) as your measure of effect size.
\item
  In the Assumption Checks drop-down menu, select \texttt{Sphericity\ tests}.
\item
  In the Post Hoc Tests drop-down menu, move your two independent variables over and select \texttt{Tukey}. Remember that we only interpret these if the overall \emph{F} is statistically significant.
\item
  In the Estimated Marginal Means drop-down menu, move Reward, Condition, and both reward and condition into the terms under Marginal Means. Select tables and plots, and select \texttt{Observed\ scores}. Uncheck \texttt{Equal\ cell\ weights}.
\end{enumerate}

Now let's go through the output!

First, as always we check our assumption of sphericity. Mauchly's W is not statistically significant (\emph{p} = .073) so we satisfy the assumption of sphericity. We do not need to apply a sphericity correction.

\includegraphics{images/06-factorial-anova/mixed_assumptions.png}

Next, we interpret out output! This time we interpret both our within subjects effects and between subjects effects tables. In the within subjects effects table, our main effect of reward is statistically significant. In the between subjects effects table, our main effect of condition is statistically significant. However, in the within subjects effects table, there is no statistically significant interaction effect of reward on condition.

\includegraphics{images/06-factorial-anova/mixed_results.png}

To understand where the differences lie between conditions or reward preferences, we look to our post hoc tests. For reward, it looks like there is only a significant difference between food and music (\emph{p} = .009). For condition, it looks like cravings were higher in the fasting group than in the control group. We can look at the estimated marginal means tables to find the actual Means of the conditions and see the plots.

\includegraphics{images/06-factorial-anova/mixed_posthoc.png}

We can look at the interaction plot, but notice that the lines are parallel which is a good indication that there is no significant interaction.

\includegraphics{images/06-factorial-anova/mixed_interaction.png}

Lastly, we can write up the results in APA style!

\begin{quote}
To test how both condition (control or fasting) and reward preference (food, money, and music) affected food cravings, we performed a mixed factorial ANOVA. There was a significant main effect of condition (\emph{F} {[}1, 98{]} = 82.44, \emph{p} \textless{} .001, \(\eta^2_G\) = .43) and a significant main effect of reward (\emph{F} {[}2, 196{]} = 4.45, \emph{p} = .013, \(\eta^2_G\) = .00). However, there was no statistically significant interaction effect of reward on condition (\emph{F} {[}2, 196{]} = .66, \emph{p} = .519, \(\eta^2_G\) = .00).

For condition, participants who fasted (\emph{M} = 3.81, \emph{SE} = .11) reported significantly more food cravings than participants in the control condition (\emph{M} = 2.33, \emph{SE} = .11; \(p_{Tukey}\) \textless{} .001). For reward, the food reward (\emph{M} = 3.14, \emph{SE} = .09) led to significantly higher food cravings than the music reward (\emph{M} = 3.00, \emph{SE} = .09; \(p_{Tukey}\) = .009), but there was no differences between the money reward (\emph{M} = 3.07, \emph{SE} = .09) and both food (\(p_{Tukey}\) = .340) or music (\(p_{Tukey}\) = .258).
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=lbZK\_FoZKW4"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\label{fig:unnamed-chunk-3}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{ancova}{%
\section{ANCOVA}\label{ancova}}

\hypertarget{overview-9}{%
\subsection{Overview}\label{overview-9}}

\textbf{ANCOVA} (\textbf{AN}alysis of \textbf{COVA}riance) examines the difference in means between \underline{three or more} groups, while controlling for or partialling out the effect of one or more continuous confounds or covariates.

\textbf{Some definitions}: A \emph{confounding} variable is a variable that affects or is related to both the independent and dependent variable. A \emph{covariate} variable is a variable that only affects or is only related to the dependent variable.

There are two main reasons for including covariates:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{To reduce within-group error variance}: Remember that to get a larger F-statistic, we need to maximize between-groups variance and minimize within-groups variance. Adding covariates can sometimes minimize within-groups variance if that covariate helps \emph{explain} some of the within-group variance.
\item
  \textbf{Elimination of covariates}: Sometimes there are other variables that also explain our outcome variable. We want to look at the effect of another variable on the outcome while removing or eliminating the other variables (confounds) that also explain our outcome variable.
\end{enumerate}

\hypertarget{assumptions-5}{%
\subsection{Assumptions}\label{assumptions-5}}

In addition to the same assumptions of the one-way ANOVA (see \ref{anova-assumptions}), the ANCOVA has two additional assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Independence of the covariate and treatment effect}: When the covariate and treatment effect are related, then we can have incorrect F-statistic values. However, this is only important in experimental designs. In quasi-experimental designs, this is often violated and you just have to interpret results accordingly.

  \begin{itemize}
  \tightlist
  \item
    If you do have an experimental manipulation with a covariate, you can test this assumption by running a one-way ANOVA but with your experimental manipulation as your IV or group variable and your covariate as your DV. If there is a significant F-ratio, then you have violated this assumption.
  \end{itemize}
\item
  \textbf{Homogeneity of regression slopes}: The relationship between the covariate and the outcomes must be similar across groups.

  \begin{itemize}
  \tightlist
  \item
    To test this assumption, add an interaction term between the covariate and each independent variable in jamovi under the Model drop-down menu. Add the interactions as model terms.
  \end{itemize}
\end{enumerate}

\hypertarget{perform-the-test-8}{%
\subsection{Perform the test}\label{perform-the-test-8}}

Let's run an example with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``ancova''. This data is fictional data from a health psychologist who was interested in the effect of routine cycling (1 = driving, 2 = cycling) and stress (1 = high, 2 = low) on happiness levels, with age as a covariate. Notice how this is a 2x2 independent factorial design with a covariate!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  To perform an ANCOVA in jamovi, select ANCOVA under the ANOVA analysis menu.
\item
  Move your dependent variable \texttt{happiness} to the Dependent Variable box, your independent variables \texttt{stress} and \texttt{commute} to the Fixed Factors box, and your covariate \texttt{age} to the Covariates box.
\item
  Select \(\omega^2\) as your effect size.
\item
  Under Assumption Checks, select all three assumption checks: \texttt{Homogeneity\ test}, \texttt{Normality\ test}, and \texttt{Q-Q\ Plot}.
\item
  Under Post Hoc Tests, move both of your independent variables over, select the \texttt{Tukey} correction and select \texttt{Cohen\textquotesingle{}s\ d} for your effect size.
\item
  Under Estimated Marginal Means, move each of your independent variables over into its own term box. Also include combinations of your independent variables if you have an interaction term in your model. Select both plots and tables, select \texttt{Observed\ scores}, and de-select \texttt{Equal\ cell\ weights}.
\end{enumerate}

First, let's check our assumptions in jamovi. Shapiro-Wilk's test was not statistically significant (\emph{p} = .735) and the Q-Q plot looks good; therefore, we've satisfied the assumption of normality. Levene's test was not statistically significant (\emph{p} = .925); therefore, we've satisfied the assumption of homogeneity of variance.

\includegraphics{images/07-ancova/ancova_assumptions.png}

However, we have two additional assumptions we need to check. Let's check the assumption of independence of the covariate and treatment effect. For that, we need to perform another ANOVA (not an ANCOVA) with our independent variables predicting age. Our results indicate we violate this assumption: both \texttt{stress} and the interaction of \texttt{stress\ *\ commute} are related to age. This suggests age is in fact a \emph{confounding} variable, not a covariate. We should be performing a mediation, but because we want to illustrate the ANCOVA we will continue.

\includegraphics{images/07-ancova/ancova_assumptions2.png}

The second additional assumption is that the relationship between the covariate and the dependent variable is similar for all levels of the independent variable (homogeneity of regression slopes). We can test this by adding an interaction term between the covariate and each independent variable in jamovi under the Model drop-down menu. If the interaction effect is not significant it can be removed. If it is significant then a different and more advanced statistical technique might be appropriate (which is beyond the scope of this class). In our case, the interactions between each IV and our covariate are not statistically significant so we can remove the interaction terms and move on.

\includegraphics{images/07-ancova/ancova_assumptions3.png}

Now it's time to interpret the results! The ANCOVA table shows that both independent variables (\texttt{stress} and \texttt{commute}), the interaction term (\texttt{stress\ *\ commute*}), and the covariate (\texttt{age}) are statistically significant. Therefore, we can look at our post hoc tests to find where the differences are.

\includegraphics{images/07-ancova/ancova_results.png}

Technically, we don't need to look at the post hoc table much in this example. Because there are only two groups, we already know one group will have higher means than the other group if the F-test is significant. In fact, check this out: the square root of our F-statistic is equal to the t-statistic in our post hoc table. Neat!

Post hoc tests show that low stress had higher happiness than high stress, and that cycling had higher happiness than driving. We can also look to the estimated marginal means tables and plots for information for reporting.

\includegraphics{images/07-ancova/ancova_tukey.png}

Last, we can write-up our results! Reporting ANCOVA is very similar to reporting an ANOVA test (in this case an independent factorial ANOVA) except that we also report the effect of the covariate, as well. Here's an example write-up:

\begin{quote}
We conducted a study examining how stress and commute affect happiness levels in a 2 (stress: high or low) x 2 (commute: cycling or driving) independent factorial design. Furthermore, we collected data on age as a covariate of our study. We satisfied all assumptions of the ANCOVA except that age was in fact a confounding variable in that it relates to our independent variable of stress. Despite failing to meet this assumption, we proceeded with the ANCOVA analysis.

There was a significant main effect of stress on happiness such that participants in the low stress condition (\emph{M} = 68.45, \emph{SE} = 2.55) reported significantly greater happiness than participants in the high stress condition (\emph{M} = 39.85, \emph{SE} = 2.55), \emph{F} (1, 15) = 52.61, \emph{p} \textless{} .001, \(\omega^2\) = .39. There was also a significant main effect of commute on happiness such that participants who commuted via cycling (\emph{M} = 64.70, \emph{SE} = 2.29) reported significantly greater happiness than participants who commuted via driving (\emph{M} = 43.60, \emph{SE} = 2.29), \emph{F} (1, 15) = 42.33, \emph{p} \textless{} .001, \(\omega^2\) = .31. There was a significant interaction between stress and commute type such that happiness levels were similar in the low stress condition for both commute types, but happiness was significantly higher for participants who cycled versus those who drove in the high stress condition, \emph{F} (1, 15) = 14.15, \emph{p}~= .002, \(\omega^2\) = .10. Furthermore, age was a significant covariate of our dependent variable, \emph{F} (1, 15) = 6.39, \emph{p} = .023, \(\omega^2\) = .04.
\end{quote}

\hypertarget{video-8}{%
\subsection[ Video]{\texorpdfstring{\protect\includegraphics{images/07-ancova/ancova_interaction.png} Video}{ Video}}\label{video-8}}

Here's a video walking through the ANCOVA test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=OdKyMYoO0VU"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{correlation-and-regression}{%
\chapter{Correlation and regression}\label{correlation-and-regression}}

Correlations are the relationships between two (usually) continuous variables.

Regressions have one or more predictor variables (usually at least one is a continuous variable) and a single continuous dependent variable.

The last chapter will show how all these inferential statistics we've learned are all related.

\hypertarget{correlation}{%
\section{Correlation}\label{correlation}}

\hypertarget{overview-10}{%
\subsection{Overview}\label{overview-10}}

Correlation (\emph{r}) tests the relationship between two variables, which are usually continuous (i.e., ratio or interval) variables. The relationship between those two variables could be \emph{positively related}, \emph{negatively related}, or \emph{not related at all}.

\textbf{Note}: Remember that correlation does not always equal causation!

We will learn about other types of correlations, but mainly we are interested in the Pearson product moment correlation, which is often just called the Pearson correlation or simply correlation. Other correlations are generally referred to by their specific name.

The strength of the correlation is determined by how closely the points in the scatterplot matrix fit on the regression line. Correlations are really \emph{standardized covariances}. \underline{Covariance} is the extent to which the deviation of one variable from its mean matches the deviation of the other variable from its mean. We then standardize the covariance into the correlation which ranges from -1 to +1. Because correlations are standardized, they are considered effect sizes! Commonly, we describe values of .1 as a small effect size, .3 as medium, and .5 as large, but remember that this heuristic is simply a heuristic and it's best to think about size in relation to your field.

\includegraphics{images/08-correlation/correlation-examples.png}

\textbf{Note}: Try your hand at guessing the correlation coefficient! Play at www.guessthecorrelation.com

\textbf{Note}: Another fun website to play around with is the interactive visualization website Interpreting Correlations by Kristoffer Magnusson. You can play around with what data looks like at various correlations. \url{https://rpsychologist.com/correlation/}

\hypertarget{specify-your-hypotheses-6}{%
\subsection{Specify your hypotheses}\label{specify-your-hypotheses-6}}

Let's run an example with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open ``parenthood''. This dataset measures a new mother's\footnote{The dataset built into jamovi says the person's name is Dan, but they now go by Danielle. You can follow her on Twitter at \href{https://twitter.com/djnavarro}{@djnavarro}.} daily grumpiness very precisely, on a scale from 0 (not at all grumpy) to 100 (extremely grumpy). In addition, I am also tracking her sleeping patterns and her son's sleeping patterns across 100 days.

The null hypothesis is there is no correlation whereas the alternative hypothesis is that there is a correlation. In this case, our hypothesis is a two-tailed hypothesis, although we could have an \emph{a priori} hypothesis about the relationship between our variables.

\hypertarget{look-at-the-data-8}{%
\subsection{Look at the data}\label{look-at-the-data-8}}

\hypertarget{data-set-up-8}{%
\subsubsection{Data set-up}\label{data-set-up-8}}

To conduct the correlation we first need to ensure our data is set-up properly in our dataset. This requires having two columns, one for each of our continuous variables. Each row is a unique participant or unit of analysis. Note that jamovi might have incorrectly imported \texttt{dan.grump} as a nominal variable but that is incorrect! This shows the importance of looking at your data and checking your measure types.

\includegraphics[width=5.20833in,height=\textheight]{images/08-correlation/correlation-data.png}

\hypertarget{describe-the-data-6}{%
\subsubsection{Describe the data}\label{describe-the-data-6}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. We can see first that we have 100 cases and no missing data. The means, medians, standard deviations, and variances are then shown, followed by the minimum and maximum values.

We also see skew and kurtosis. Calculating the \emph{z}-score for all the skew and kurtosis (remember: skew or kurtosis divided by its standard error) suggests we do not violate the assumption of normality much except for \texttt{day}. However, notice what the variable \texttt{day} is! It's just the day of the study, from 1-100. If you look at the graph, it has a \emph{uniform distribution} (completely flat and uniform) not a normal distribution (bell curve)!

\includegraphics{images/08-correlation/correlation-descriptives.png}

\hypertarget{check-assumptions-6}{%
\subsection{Check assumptions}\label{check-assumptions-6}}

\hypertarget{assumptions-6}{%
\subsubsection{Assumptions}\label{assumptions-6}}

The Pearson correlation has the three following assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Both variables are \textbf{normally distributed}
\item
  Both variables are measured at the \textbf{interval or ratio} (i.e., continuous) level (however, we will see what we can do if we violate this)
\item
  The relationship between the two variables is \textbf{linear}
\end{enumerate}

We test for normal distribution using the Exploration-Descriptives analysis in jamovi, looking at Shapiro-Wilk's test, the Q-Q plot, a histogram or density plot, and skew and kurtosis z-scores.

The third assumption requires looking at a scatterplot of one variable on the x-axis and the other variable on the y-axis.

\hypertarget{checking-assumptions-6}{%
\subsubsection{Checking assumptions}\label{checking-assumptions-6}}

\hypertarget{testing-normality-3}{%
\paragraph{Testing normality}\label{testing-normality-3}}

By now we've had a lot of practice testing for normality. One of our data points (\texttt{day)} is strange because it's just a linear number 1-100, so we can ignore it. The Q-Q plot for \texttt{dan.sleep} looks a bit iffy, but the density plot, skew, kurtosis, and Shapiro-Wilk's tests look fine. We will say we met the assumption of normality. Below, you can see our density plots in the diagonal of our scatterplot matrix.

\includegraphics{images/08-correlation/correlation-plots.png}

\hypertarget{testing-linearity}{%
\paragraph{Testing linearity}\label{testing-linearity}}

There's nothing we can do here except look out our correlations! Do the underlying data in any of the scatterplots look like there is actually a non-linear (e.g., curvilinear) relationship? If so, you fail to meet this assumption.

The scatterplots above do not suggest a non-linear relationship, so we meet the assumption of linearity.

\hypertarget{perform-the-test-9}{%
\subsection{Perform the test}\label{perform-the-test-9}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  First, you'll need to check your assumption of normality \emph{outside} of the correlations analysis. Go to Explorations and choose Descriptives and check whether you meet the assumption of normality.
\item
  To perform a correlation, go to Regression and select Correlation Matrix.
\item
  Move all four variables into the dialogue box on the right (\texttt{dan.sleep}, \texttt{baby.sleep}, \texttt{day}, and \texttt{dan.grump}).
\item
  Select Pearson under Correlation Coefficients. We'll go over the other two later.
\item
  Under Additional Options, select \texttt{Report\ significance}, \texttt{Flag\ significant\ correlations}, and, if you have missing data, \texttt{N} (we don't have missing data so we can ignore this).
\item
  Under Plot, select \texttt{Correlation\ matrix}. Alternatively, you can ask for \texttt{Densities\ for\ variables} to see the density plots for each variable and \texttt{Statistics} to have the correlation coefficient added to the plot.
\end{enumerate}

When you are done, your setup should look like this:

\includegraphics[width=5.20833in,height=\textheight]{images/08-correlation/correlation-setup.png}

\hypertarget{interpreting-results-2}{%
\subsection{Interpreting results}\label{interpreting-results-2}}

Once we are satisfied we have satisfied the assumptions for the correlation, we can interpret our results.

\includegraphics{images/08-correlation/correlation-matrix.png}

It looks like three of the variables are significantly (\emph{p} \textless{} .05) correlated with each other: \texttt{dan.sleep}, \texttt{baby.sleep}, and \texttt{dan.grump}. \texttt{day} does not seem to be significantly correlated with any of the other three variables.

\hypertarget{write-up-the-results-in-apa-style-8}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-8}}

We can write up our results in APA something like this:

\begin{quote}
Dan's grumpiness (\emph{M} = 63.71, \emph{SD} = 10.05) is negatively correlated with both Dan's quality of sleep (\emph{M} = 6.97, \emph{SD} = 1.02; \emph{r} = -.90, \emph{p} \textless{} .001) and the baby's quality of sleep (\emph{M} = 8.05, \emph{SD} = 2.07; \emph{r} = -.57, \emph{p} \textless{} .001). Furthermore, Dan's and the baby's quality of sleep are positively correlated (\emph{r} = .63, \emph{p} \textless{} .001).
\end{quote}

\hypertarget{visualize-the-results-7}{%
\subsubsection{Visualize the results}\label{visualize-the-results-7}}

The default in the Correlation Matrix is to plot the correlation matrix of all the variables, and optionally show the densities for variables and the statistics. This is fine, but I'm not a huge fan of it. You can see it below:

\includegraphics{images/08-correlation/correlation-plots.png}

Personally, this is why I like the \texttt{scatr} module in jamovi. You can create high-quality scatterplots of the six graphs above and then stitch them together in a nicer version. For example, here's the correlation between the sleep quality of both Dan and the baby with a linear regression line and standard error:

\includegraphics[width=5.20833in,height=\textheight]{images/08-correlation/correlation-plot1.png}

\hypertarget{video-9}{%
\subsection{Video}\label{video-9}}

Here's a video walking through the correlation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=p4LNqatn2sg"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-1}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{in-case-of-violated-assumptions-7}{%
\subsection{In case of violated assumptions}\label{in-case-of-violated-assumptions-7}}

If you violate any of the three assumptions, you can choose to perform Spearman's rank correlation instead of a Pearson correlation. Both Spearman's rho and Kendall's tau are non-parametric statistics based on rank order. To perform Spearman's correlation, change the check mark in jamovi from Pearson to Spearman. You will interpret just the same; however, instead of using the letter \emph{r} you can either use \(r_s\), \(r_{spearman}\), or \(\rho\) (the Greek letter rho).

What about Kendall's tau? It will likely give you the same results as Spearman's rho but it is interpreted slightly differently. We won't use it in this class.

\hypertarget{additional-information-4}{%
\subsection{Additional information}\label{additional-information-4}}

\hypertarget{r-squared}{%
\subsubsection{R-Squared}\label{r-squared}}

The cool thing about the correlation is that we can square \(r\) to get \(r^2\), which is the percentage of variance overlap. It is the percentage of variance in one variable that is shared by the other. You simply square the \(r\) correlation coefficient to find the \(r^2\). For example, our correlation above between Dan's grumpiness and Dan's quality of sleep is \(r\) = -.90; therefore, its \(r^2\) = .81 or 81\%. 81\% of the variance in Dan's grumpiness can be explained by Dan's quality of sleep!

\hypertarget{comparing-strengths-of-correlations}{%
\subsubsection{Comparing strengths of correlations}\label{comparing-strengths-of-correlations}}

\textbf{Note}: For PSYC 290 students, you can read the below information but I will not test you on it.

Sometimes you want to compare two correlations to find out if one correlation is significantly stronger than another. You can use this calculator to calculate the p-value: \href{https://www.psychometrica.de/correlation.html}{Testing the Significance of Correlations}

Note that you use \#1 (Independent Samples) when the correlations come from different samples and \#2 (Dependent Samples) when the correlations come from the same sample. For example, to compare the correlation between English and Reading to the correlation between English and Writing, you would use \#2 (Dependent Samples). But to compare the correlations between English and Reading for men and women, you would use \#1 (Independent Samples).

Let's try them both with our \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Comparison of correlations from independent samples}
\end{enumerate}

We want to test the correlations between English and Reading for men and women. We first need to gather those correlations in jamovi. We can do this through \textbf{filters}.

Let's first find the correlation for men. Go to the Data tab in jamovi, click Filters, and enter in the \(\int_x\) = Gender == 0. Next, go to the Analyses tab in jamovi, click Regression, and choose Correlation Matrix. Move our two variables over (\texttt{English} and \texttt{Reading}) and check the box for \texttt{N}. You should get \emph{r} = .36, \emph{p} \textless{} .001, \emph{n}~= 181.

Now let's find the correlation for women. Go back to the Data tab in jamovi, click Filters, and change the equation to \(\int_x\) = Gender == 1. Your results should automatically update because the filter changed. For women, you should get \emph{r} = .33, \emph{p} \textless{} .001, \emph{n} = 210.

Now we can compare the correlations in \href{https://www.psychometrica.de/correlation.html\#independent}{Testing the Significance of Correlations - Independent Samples}. In Correlation 1, put 181 in the n column and .36 in the r column. In Correlation 2, put 210 in the n column and .33 in the r column. The results are shown below. The z-score is not statistically significant (\emph{p} = .369) so there is no significant difference in correlation strength.

\includegraphics{images/08-correlation/compare-correlations-independent.png}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Comparison of correlations from dependent samples}
\end{enumerate}

Now let's test whether the correlation between English and Reading differs from the correlation between English and Writing.

Notice how we have three tests we are comparing: (1) English, (2) Reading, and (3) Writing. We can't use this test if we are testing the correlation between variables A and B and the correlation between variables C and D. There needs to be overlap.

If you still have your filter on in your dataset from the previous analysis, turn it off. Go to the Data tab, click Filters, and either select the X to delete it or toggle the active button so it's turned off. Return to your Correlation Matrix results and click on it to edit it. Add Writing to the box.

However, we have a problem! The \href{https://www.psychometrica.de/correlation.html\#dependent}{Testing the Significance of Correlations - Dependent Samples} webpage (\#2) wants a single N, but our correlation matrix has different Ns because of missing data. What can we do? We need to chain filters! Go back to your Data tab, click Filters, and add three filters like below (note: this is how you can get \emph{listwise deletion} in jamovi):

\includegraphics{images/08-correlation/correlation-filters.png}

Our correlation matrix should have automatically updated and all the N's equal 370. Great! We now have all the information we need to input into our \href{https://www.psychometrica.de/correlation.html}{Testing the Significance of Correlations} webpage, \#2. For n we input 370. For \(r_{12}\) we enter the correlation between (1) English and (2) Reading. For \(r_{13}\) we enter the correlation between (1) English and (3) Writing. For \(r_{23}\) we enter the correlation between (2) Reading and (3) Writing. Our z-score is not statistically significant (\emph{p} = .213) so there is no significant difference in the correlation between English and Reading (\emph{r} = .32) with the correlation between English and Writing (\emph{r} = .37).

\includegraphics{images/08-correlation/compare-correlations-dependent.png}

\hypertarget{your-turn-8}{%
\subsection{Your turn!}\label{your-turn-8}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

Perform correlations based on the following research questions.

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Are there significant correlations among the four tests (English, reading, math, writing)?}

  \begin{itemize}
  \item
    Do you meet the assumption of normality for all four tests?
  \item
    Do you meet the assumption of linearity for all four tests?
  \item
    Are the four tests significantly correlated among each other?
  \item
    Round your answers to two decimal places:

    \begin{itemize}
    \item
      What is the correlation between reading and math?
    \item
      What is the correlation between writing and reading?
    \item
      What is the correlation between writing and English?
    \end{itemize}
  \end{itemize}
\end{enumerate}

\hypertarget{regression}{%
\section{Regression}\label{regression}}

\hypertarget{overview-11}{%
\subsection{Overview}\label{overview-11}}

Regression can examine multiple predictor variables simultaneously. Whereas the factorial ANOVA can only handle categorical variables (i.e., nominal or ordinal), regression can handle all types of predictor variables including both categorical and continuous.

There are three types of regression in general:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \underline{Linear regression}: this looks at the effect of a single predictor (IV) on a single outcome (DV). This is equivalent to a t-test (dichotomous predictor), one-way ANOVA (ordinal predictor), or correlation (scale predictor).
\item
  \underline{Multiple regression}: this looks at the effect of multiple predictors (IVs) on a single outcome (DV).
\item
  \underline{Hierarchical regression}: this looks at the effect of multiple predictors (IVs) on a single outcome (DV), but there are multiple ``blocks'' or ``steps'' so that you can check the added predictability of new variables.
\end{enumerate}

Note that the linear regression is actually equivalent to a lot of the statistics we've learned. For example, the linear regression will produce the same results as a t-test when we have a dichotomous predictor, a one-way ANOVA when we have an ordinal predictor, and a correlation when we have a continuous predictor. We'll learn more about this at the end of the textbook when we wrap everything up.

\hypertarget{understanding-regression}{%
\subsubsection{Understanding regression}\label{understanding-regression}}

A linear regression model is basically a linear line, which many of us learned as y = mx + b, where y is our predicted outcome score, x is the IV, b is the intercept (the score in y when x = 0), and m is the slope (when you increase x-value by 1 unit, the y-value goes up by m units).

Let's imagine we have a dataset of dragons with a categorical predictor (whether they are spotted or striped) and a continuous predictor (height) and a continuous dependent variable (weight). We want to use this dataset to be able to predict the weight of future dragons. First, let's learn how to interpret the coefficients for our two predictor variables (images from \href{https://github.com/allisonhorst/stats-illustrations\#multiple-linear-regression-dragons-thread}{Allison Horst}).

\begin{figure}

{\centering \includegraphics[width=0.49\linewidth]{images/13-regression/dragon_categorical} \includegraphics[width=0.49\linewidth]{images/13-regression/dragons_continuous} 

}

\caption{Regression lines and residuals}\label{fig:unnamed-chunk-1}
\end{figure}

We determine our line equation from the scatterplot of scores by figuring out the line that fits closest to all data points. The regression line is the line with the \emph{smallest} residuals between the line and data points.

Let's visualize the regression line for how Dan's sleepiness affect Dan's grumpiness. On the left, we see the regression line (in purple) is very close to the data points and the residuals (the grey lines between the purple line and the data points) are smaller. On the right, we see the regression line is far from a lot of the data points and the residuals are larger.

\begin{figure}

{\centering \includegraphics[width=0.49\linewidth]{images/13-regression/good-regression-line} \includegraphics[width=0.49\linewidth]{images/13-regression/bad-regression-line} 

}

\caption{Regression lines and residuals}\label{fig:unnamed-chunk-2}
\end{figure}

Let's go back to our dragon example and input one of our dragons into the model to find out how residuals work. On the left, based on our dataset and the fact that our dragon is striped (spotted = 0) and has a height of 5.1 feet, we would expect our dragon to weigh 3.9 tons. However, when we actually weigh him, he weighs 4.2 tons! Therefore, the residual in this case would be .3 tons.

\begin{figure}

{\centering \includegraphics[width=0.49\linewidth]{images/13-regression/dragon_predict_mlr} \includegraphics[width=0.49\linewidth]{images/13-regression/dragon_residual} 

}

\caption{Regression lines and residuals}\label{fig:unnamed-chunk-3}
\end{figure}

One of our assumption checks is that our residuals are normally distributed, so we would take all our residuals and examine those for normality.

\begin{figure}

{\centering \includegraphics[width=0.49\linewidth]{images/13-regression/dragon_residual_distribution} 

}

\caption{Regression lines and residuals}\label{fig:unnamed-chunk-4}
\end{figure}

There is more math to regression, which is needed to calculate the \emph{F}-test you get for the overall model test and the t-tests you get for your model coefficients, but we won't get into that detail.

\hypertarget{look-at-the-data-9}{%
\subsection{Look at the data}\label{look-at-the-data-9}}

Let's run an example with data from lsj-data. Open data from your Data Library in ``lsj-data''. Select and open \texttt{parenthood}. This dataset includes the sleep quality of both Dan and Dan's baby, Dan's grumpiness, and the day of the data collection from 1-100.

We'll be testing how both Dan's and Dan's baby's quality of sleep affect Dan's grumpiness.

\hypertarget{data-set-up-9}{%
\subsubsection{Data set-up}\label{data-set-up-9}}

Our data set-up for regression depends on the type of regression and type of data, but in general we'll have one column of our continuous DV and one or more columns of our IV(s).

For this chapter, we're going to return to the \texttt{parenthood} dataset from lsj-data. Remember that this dataset includes the sleep quality of both Dan and Dan's baby, Dan's grumpiness, and the day of the data collection from 1-100.

\includegraphics{images/08-correlation/correlation-data.png}

\hypertarget{describe-the-data-7}{%
\subsubsection{Describe the data}\label{describe-the-data-7}}

Once we confirm our data is setup correctly in jamovi, we should look at our data using descriptive statistics and graphs. First, our descriptive statistics are shown below. We can see first that we have 100 cases and no missing data. The means, medians, standard deviations, and variances are then shown, followed by the minimum and maximum values.

We also see skew and kurtosis. Calculating the \emph{z}-score for all the skew and kurtosis (remember: skew or kurtosis divided by its standard error) suggests we do not violate the assumption of normality much except for \texttt{day}. However, notice what the variable \texttt{day} is! It's just the day of the study, from 1-100. If you look at the graph, it has a \emph{uniform distribution} (completely flat and uniform) not a normal distribution (bell curve)!

\includegraphics{images/08-correlation/correlation-descriptives.png}

\hypertarget{check-assumptions-7}{%
\subsection{Check Assumptions}\label{check-assumptions-7}}

\hypertarget{assumptions-7}{%
\subsubsection{Assumptions}\label{assumptions-7}}

The regression has a lot of assumptions.

Some require no testing:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Variable types}: The DV is continuous and the IVs are either continuous, dichotomous, or ordinal.
\item
  \textbf{Independence}: All the outcome variable values are independent (e.g., come from a separate entity).
\end{enumerate}

Other assumptions require testing:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{No outliers}: There shouldn't be any data in the dataset that is an outlier which would strongly influence your results.
\item
  \textbf{Normality of the \emph{residuals}}: Up to this point, we've examined the normality of the outcome variables. With regression, our variables can be non-normal as long as the residuals (i.e., error) are normally distributed.
\item
  \textbf{Linearity}: The relationship between each IV and DV is linear. Sometimes you may expect a curvilinear relationship between an IV and DV, in which case we square or cube the IV and use that variable as our predictor variable in the regression.
\item
  \textbf{Homogeneity of variance (homoscedasticity)}: At each level of the predictor variables, the variance of the residual terms should be constant.
\item
  \textbf{Independent residuals}: For any two observations, the residual terms should be uncorrelated (or independent). Our errors must be normally distributed \emph{and} uncorrelated.
\item
  \textbf{No multicollinearity}: There should be no perfect or near-perfect linear relationship between two or more of the predictors in your regression model. For example, you would not include ``heigh\_cm'' and ``heigh\_in'' in your model because they would be perfectly related to one another. We'll learn how to test for this.
\end{enumerate}

\hypertarget{checking-assumptions-7}{%
\subsubsection{Checking Assumptions}\label{checking-assumptions-7}}

\hypertarget{outliers}{%
\paragraph{Outliers}\label{outliers}}

Under Data Summary, you should have a table with Cook's distance. This is one way we can check for \emph{multivariate outliers}. This examines whether any one \emph{line} of data is an outlier, not just one data \emph{point}. In general, Cook's distances greater than 1 indicate a multivariate outlier. Our Cook's distances are very small, so we do not have a problem with outliers.

\includegraphics{images/13-regression/regression-cooks.png}

If you violate this assumption and have one or more multivariate outliers, then go to the Save tab in your regression setup and select the box for Cook's distance. That will create a new variable in your dataset with the Cook's distance. Create a filter and remove any data that has a Cook's distance greater than 1.

\hypertarget{normality-of-the-residuals}{%
\paragraph{Normality of the residuals}\label{normality-of-the-residuals}}

The regression analysis in jamovi allows us to check multivariate normality with the Shapiro-Wilk's test and the Q-Q plot of our residuals. We've seen this multiple times, so by now it should be well-ingrained that because Shapiro-Wilk's is not statistically significant and our data points fall along the diagonal line that we satisfy the assumption of normally distributed residuals.

Note that in large datasets, your Q-Q plot may look fine but your Shapiro-Wilk's test may be statistically significant. In that case, you can likely assume your data is normally distributed. The Shapiro-Wilk's test tends to say things are not normal with very small deviations from large datasets.

If you violate the assumption of normality, you can try transformating one or more variables. For the purposes of our assignments, if you violate this assumption then just mention that it is violated and that you will proceed anyways.

\includegraphics{images/13-regression/regression-normality.png}

\hypertarget{linearity-homoscedasticity}{%
\paragraph{Linearity \& homoscedasticity}\label{linearity-homoscedasticity}}

To examine linearity and homoscedasticity, two of the assumptions of regression, we examine the Residuals Plots. You will get one plot of the overall model (Fitted) and one for each of your variables (DV and IV(s)). I've displayed the residuals plot for the Fitted values against the residuals below. In these plots, we want our data to look like a random scattering of dots even dispersed around zero on the y-axis.

We will not be learning non-normal or weighted least squares regression in this course, so if you violate one or both of these assumptions then mention which are violated and that you will proceed anyways.

\textbf{Linearity}: If the data points seem to have a curve in the graph, then that suggests you have failed the assumption of linearity. Our data doesn't seem to have any curve to it, so we satisfy the assumption of linearity.

\textbf{Homoscedasticity}: If the graph seems to funnel (e.g., widely dispersed on one end of the x-axis and narrowly dispersed on the other end), then that suggests you fail the assumption of homoscedasticity. Our data doesn't seem to be wider at any point, so we satisfy the assumption of homoscedasticity.

\includegraphics{images/13-regression/regression-residuals.png}

\hypertarget{independence-of-residuals}{%
\paragraph{Independence of residuals}\label{independence-of-residuals}}

The Durbin-Watson test for autocorrelation tests for independence of residuals. We want the Durbin-Watson value to be as close to 2 as possible. Values less than 1 or greater than 3 are problematic and indicate we are violating this assumption. In our case, the DW test statistic is 2.12 and so very close to 2. Furthermore, they provide a p-value and the p-value is greater than .05 so the test statistic is not statistically significant, further supporting that we meet the assumption that our residuals are independent.

If you violate this assumption, it's likely a function of how your data was collected (e.g., a time effect or you have nested data). We won't be covering what to do in these cases, but if you have nested data you may be interested in multilevel or hierarchical modeling (MLM/HLM).

\includegraphics{images/13-regression/regression-durbinwatson.png}

\hypertarget{multicollinearity}{%
\paragraph{Multicollinearity}\label{multicollinearity}}

Multicollinearity is a problem for three reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Untrustworthy \emph{B}s}: As multicollinearity increases, so do the standard errors of the \emph{B} coefficient. We want smaller standard errors, so this is problematic.
\item
  \textbf{Limits the size of R}, and therefore the size of R\textsuperscript{2}, and we want to have the largest R or R\textsuperscript{2} possible, given our data.
\item
  \textbf{Importance of predictors}: When two predictors are highly correlated, it is very hard to determine which variable is more important than the other.
\end{enumerate}

Multicollinearity is simply that multiple variables are correlated. We can first just look for general \emph{collinearity}, or the correlations between all our predictors, using the correlation matrix in jamovi. Any correlations greater than .8 or .9 are problematic. You would either need to drop one variable or combine them into a mean composite variable.

However, to test for \emph{multicollinearity}, we examine the VIF and Tolerance values. VIF is actually a transformation of Tolerance (Tolerance = 1/VIF and VIF = 1/Tolerance). In general, we want values 10 or lower, which corresponds to Tolerance values greater than .2.

In our data, our VIF is 1.65 and Tolerance is .61, so we satisfy the assumption of no multicollinearity.

\includegraphics{images/13-regression/regression-multicollinearity.png}

Now that we met all the assumptions, we can interpret our results!

\hypertarget{perform-the-test-10}{%
\subsection{Perform the test}\label{perform-the-test-10}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  From the `Analyses' toolbar select `Regression' - `Linear regression'. Note that we select this option regardless of whether we are performing a linear regression, multiple regression, or hierarchical regression.
\item
  Move your dependent variable \texttt{dan.grump} into the Dependent Variable box and all your independent variables into either Covariates (if they are continuous variables) or Factors (if they are categorical variables). In this case, all our variables are continuous so move both \texttt{dan.sleep} and \texttt{baby.sleep} to the Covariates box.
\item
  If you are performing a hierarchical regression, you will use the Model Builder drop-down menu. More information on hierarchical regression will be discussed later.
\item
  If you have categorical predictors with more than two levels, you will use the Reference Levels drop-down menu to specify what you want your reference level to be and whether you want the intercept to be the reference level or the grand man. More information on categorical predictors will be discussed later.
\item
  Under Assumption Checks, check \emph{all} the boxes!
\item
  Under Model Fit, select \texttt{R}, \texttt{R-squared}, \texttt{Adjusted\ R-squared}, and \texttt{F\ test}. The other options (AIC, BIC, RMSE) are more useful when we are comparing models and will be discussed later in the Hierarchical regression section.
\item
  Under Model Coefficients, select \texttt{Standardized\ estimate}.
\item
  Optionally, you can ask for plots and tables of the estimated marginal means.
\end{enumerate}

I'm not going to show the set-up figure here because there's just too much to show.

\hypertarget{interpret-results-6}{%
\subsection{Interpret results}\label{interpret-results-6}}

\includegraphics{images/13-regression/regression-results.png}

The first table shows us our overall model results.

\textbf{R, R-squared, and adjusted R-squared}: We get our R and R-squared values (R-squared literally being R squared). Remember back to correlation: R-squared is the \emph{proportion} of variance in the dependent variable that can be accounted for by the predictor(s). In this case, Dan and the baby's sleep quality predict 82\% of the variance in Dan's grumpiness.

However, more commonly we report the adjusted R-squared value, which adjusts the R-squared value based on the number of predictors in the model. Adding more predictors to the model will \emph{always} cause R-squared to increase (or at least not decrease) so it's important that we control for that using an adjustment. It's interpreted basically the same, just adjusted for biased. I encourage you to use the adjusted R-squared, \emph{especially} if you have lots of predictors in your model.

\textbf{Overall Model Test}: We also get an \emph{F}-test for the overall model. If you want, you can get the full ANOVA test by selected ANOVA test under Model Coefficients. This is how we know if the overall model is statistically significant. In our case, our \emph{F}-test is statistically significant so we know that the set of predictors significantly predicts our dependent variable.

\textbf{Model coefficients}: Just like in ANOVA, we first examine if the model is significant (overall model test) and then look at individual factors, in this case being individual variables in our regression model. Each variable--our intercept and both independent variables--have an associated \emph{t}-test. In this case, Dan's sleep significantly predicts Dan's grumpiness, but the baby's sleep does not.

\textbf{Standardized coefficients}: We also asked for standardized estimates, which we get in the last column of our model coefficients table. These are \emph{standardized} so that we can compare them to other variables. They give us an idea of the \emph{strength} of the relationship between that IV on the DV. Larger values = bigger effects. The standardized estimate is called Beta (\(\beta\)) whereas the unstandardized estimate is just called that or B (the letter B, not Beta). We use the standardized estimates to compare the strength of the estimate to other IVs and we use unstandardized estimates to write our linear equations and predict the DV given values of the IV.

\emph{What about the intercept?} You might be wondering what we do with the intercept. Typically, nothing. We only use it to create our equation so that we can predict Dan's grumpiness based on Dan's sleep and the baby's sleep. For example, our equation from our data is such:

\(y = 125.97 - 8.95(dan.sleep) + .01(baby.sleep)\)

If Dan's sleep was 5 and baby's sleep was 8, then we'd expect Dan's grumpiness to be:

\(y = 125.97 - 8.95(5) + .01(8) = 125.97 - 44.75 + .08 = 81.3\)

\hypertarget{write-up-the-results-in-apa-style-9}{%
\subsubsection{Write up the results in APA style}\label{write-up-the-results-in-apa-style-9}}

We can write up our results in APA something like this:

\begin{quote}
Dan collected data on how many hours of sleep Dan and Dan's baby got, as well as Dan's grumpiness, for 100 days. Dan tested how the hours of sleep both Dan and the baby got affected Dan's grumpiness using a multiple regression. The combination of predictors were significantly related to Dan's grumpiness, \emph{F} (2, 97) = 215.24, \emph{p} \textless{} .001, adjusted \(R^2\) = .81. The number of hours of sleep Dan got significantly predicted Dan's grumpiness, \(\beta\) = -.90, \emph{t} (97)= -16.17, \emph{SE} = .55, \emph{p} \textless{} .001. However, the number of hours of sleep the baby got did not significantly relate to Dan's grumpiness, \(\beta\) = 0.00, \emph{t} (97)= .04, \emph{SE} = .27, \emph{p} = .969.
\end{quote}

Note that in many of these write-ups I did not include anything about assumption checking. I normally write up that information as part of my analytic plan in my methods section (e.g., ``I checked for multivariate outliers using Cook's distance.''). Included in this section, I explain what I will do if I do not meet various assumptions. Then, if I don't meet the assumption in the results section I explain that I did not meet the assumption, explain the results if necessary, explain what I did, and then give the results. In this case, we met all the assumptions (that presumably I described in my methods section) and therefore went straight to the results.

\hypertarget{video-10}{%
\subsection{Video}\label{video-10}}

Here's a video walking through the regression.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_url}\NormalTok{(}\StringTok{"https://www.youtube.com/watch?v=SfubvsatkdA"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.
\end{verbatim}

\label{fig:unnamed-chunk-5}\textbf{CAPTION THIS FIGURE!!}

\hypertarget{additional-information-5}{%
\subsection{Additional information}\label{additional-information-5}}

\hypertarget{hierarchical-regression}{%
\subsubsection{Hierarchical regression}\label{hierarchical-regression}}

Hierarchical regression is exactly the same as multiple regression but now we have multiple models or blocks. You can specify hierarchical regression using the Model Builder drop-down menu in jamovi. Let's try an example where we have \texttt{baby.sleep} as Block 1 and \texttt{dan.sleep} as Block 2. In addition, using the Model Fit drop-down menu you should check \texttt{AIC} and \texttt{BIC} in addition to the previously selected options. Your setup should look something like this:

\includegraphics{images/13-regression/hierarchical-setup.png}

Our model results now change. We now have two lines for the Model Fit Measures and a Model Comparisons table. In addition, under Model Specific Results, we have a drop-down menu to specify which model we want to examine.

\includegraphics{images/13-regression/hierarchical-results.png}

Let's interpret. Our first model (with just \texttt{baby.sleep} is significant), \emph{F} (1, 98) = 46.18, \emph{p} \textless{} .001, \emph{adjusted} \(R^2\) = .31. So is our second model (that has both \texttt{baby.sleep} and \texttt{dan.sleep}),~\emph{F} (2, 97) = 215.24, \emph{p} \textless{} .001, \emph{adjusted} \(R^2\) = .81. There was a significant improvement between model 1 and model 2, \(F_{change}\) (1, 97) = 261.52, \emph{p} \textless{} .001, \(\Delta R^2\) = .50. The significant improvement means that the predictors added to model 2 significantly predict our DV \emph{above and beyond} the predictors in model 1.

We might write-up these results as such:

\begin{quote}
Dan collected data on how many hours of sleep Dan and Dan's baby got, as well as Dan's grumpiness, for 100 days. Dan tested how the hours of sleep both Dan and the baby got affected Dan's grumpiness using hierarchical regression to find out how Dan's sleep predicted Dan's grumpiness above and beyond the baby's sleep.

First, the baby's sleep significantly predicted Dan's grumpiness\emph{, F} (1, 98) = 46.18, \emph{p} \textless{} .001, \emph{adjusted} \(R^2\) = .31. As the baby's hours of sleep increased, Dan's grumpiness decreased, \emph{t} (98) = -6.80, \emph{SE} = .40, \emph{p} \textless{} .001, \(\beta\) = -.57.

A second model was tested that added Dan's sleep. This model--comprised of both baby's sleep and Dan's sleep--significantly predicted Dan's grumpiness, \emph{F} (2, 97) = 215.24, \emph{p} \textless{} .001, \emph{adjusted} \(R^2\) = .81. There was a significant improvement between model 1 and model 2, \(F_{change}\) (1, 97) = 261.52, \emph{p} \textless{} .001, \(\Delta R^2\) = .50. In the second model, as Dan's sleep increased, Dan's grumpiness decreased, \emph{t} (97) = -16.17, \emph{SE} = .55, \emph{p} \textless{} .001, \(\beta\) = -.90. However, the baby's sleep did not significantly relate to Dan's grumpiness when controlling for Dan's sleep, \emph{t} (97) = .04, \emph{SE} = .27, \emph{p} = .969, \(\beta\) = .00.
\end{quote}

\hypertarget{categorical-predictors}{%
\subsubsection{Categorical Predictors}\label{categorical-predictors}}

Dummy coded variables (with values 0 or 1) are pretty easy to interpret in regression. If the Beta is positive, then the value of 1 would have a higher mean on the DV than the value of 0. If the Beta is negative, then the value of 0 would have a higher mean on the DV than the value of 1.

However, if we have a nominal variable with more than two categories, then we need to dummy code the data to analyze in a regression. Fortunately, jamovi can do this automatically for us!

The dataset we're using doesn't currently have a categorical variable, so I'm going to manually create one for demonstration purposes. I'm going to transform the \texttt{day} variable, which is the day of the data collection from 1 to 100, into a new variable that indicates whether the day is 1-32, 33-65, or 66-100, which is roughly 3 equal groups. You can see the transformation here:

\includegraphics{images/13-regression/transform.png}

Let's add that to our regression model and just make it a simple multiple regression model. Three independent variables (\texttt{dan.sleep}, \texttt{baby.sleep}, and our new \texttt{day\_3groups} variable) all in one block.

Now we need to go to the Reference Levels drop-down menu. We have two options:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Reference level (dummy coding)}: We can have our intercept be the mean of our reference level group, meaning that if all other variables were set to 0 this is the mean of our dependent variable for that group. For example, if we set day = 1 to be our reference level, then the intercept is the value of Dan's grumpiness when Dan's sleep is 0 and baby's sleep is 0 for the first 32 days. \emph{This is the option I normally choose.}
\item
  \textbf{Grand mean (simple coding)}: Alternatively, we can have our intercept be the grand mean, or the overall mean when all other variables were set to 0 and we ignored day. \emph{I am not sure when I would use this option, to be honest}.
\end{enumerate}

The other option you have is what is considered your reference level. It will default to your first level in your dataset (in this case, day\_3Groups = 1) but you can change to any other level in your variable. I set my reference level to be 1, the default, and I know that because the day variable compares both levels 2 and 3 to 1. Our intercept (126.02) then is the value of grumpiness if Dan and the baby slept 0 hours in the first 32 days of our data collection.

\includegraphics{images/13-regression/regression-categorical.png}

The first line of day - 3\_Groups (2 -- 1) is then the difference in Dan's grumpiness between the second 1/3 of days (days 33-65) and the first 1/3 of days (days 1-32). It is not statistically significant, so there is no difference in Dan's grumpiness between the first and second 1/3 of days. Because the estimate is negative, that indicates that the first 1/3 of days have a higher estimated mean of Dan's grumpiness, but again it's not statistically significant.

The second line of day - 3\_Groups (3 -- 1) is the difference in Dan's grumpiness between the third 1/3 of days (days 66-100) and the first 1/3 of days (days 1-32). It is not statistically significant, so there is no difference in Dan's grumpiness between the first and third 1/3 of days, either.

In this case, the Estimated Marginal Means can be very helpful for us to interpret the model coefficients. We can get the estimated marginal means of each group on the DV at the average levels of the other two variables.

\includegraphics{images/13-regression/regression-categorical-EMM.png}

\hypertarget{your-turn-9}{%
\subsection{Your turn!}\label{your-turn-9}}

Open the \texttt{Sample\_Dataset\_2014.xlsx} file that we will be using for all Your Turn exercises. You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

To get the most out of these exercises, try to first find out the answer on your own and then use the drop-down menus to check your answer.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Perform a multiple regression examining how \texttt{English}}, \textbf{\texttt{Reading} and \texttt{Writing}, as well as \texttt{Gender} relate to the dependent variable \texttt{Math}.}

  \begin{itemize}
  \item
    Do you have any significant outliers?
  \item
    Are your residuals normally distributed?
  \item
    Do you satisfy the assumption of linearity and homoscedasticity of your residuals (just check the Fitted residual plot)?
  \item
    Do you meet the assumption of independent residuals?
  \item
    Do you meet the assumption of no multicollinearity?
  \item
    Can you perform a regression with this data?
  \item
    What is your adjusted R-squared, rounded to two decimal places?
  \item
    Is the overall model statistically significant?
  \item
    Is \texttt{English} statistically significant?
  \item
    Is \texttt{Reading} statistically significant?
  \item
    Is \texttt{Writing} statistically significant?
  \item
    Is \texttt{Gender} statistically significant?
  \item
    For \texttt{Gender}, do male (Gender = 0) or female (Gender = 1) students have higher math scores?
  \end{itemize}
\end{enumerate}

\hypertarget{general-linear-model}{%
\section{General Linear Model}\label{general-linear-model}}

\hypertarget{overview-12}{%
\subsection{Overview}\label{overview-12}}

The regression is a General Linear Model (GLM). Everything we've learned up to this point is also a general linear model. Pretty much everything we've learned in this class \emph{could} be performed as simple a regression. You may wonder why we have not just taught regression and none of the others. There are some who are indeed proponents of that! However, I believe teaching ``simpler'' statistics like the t-test and correlation first is easiest to understand. Most of the statistics you will perform from here on out---including in your careers---will be what we have already learned (i.e., t-test, ANOVA, chi-square, correlation). However, I present this information so you may begin to see how all of this is related.

If you'd like to learn more about this, there's a fantastic online book on the subject called \href{https://lindeloev.github.io/tests-as-linear/}{Common statistical tests are linear models (or: how to teach stats)}

Note that for all these examples I am using the Sample\_Dataset\_2014.sav dataset and I am only presenting the relevant output. I am also only going to cover the correlation, t-tests, and one-way ANOVA because they are the simplest to compare. You can run these yourself! You can find the dataset here: \href{https://github.com/danawanzer/stats-with-jamovi/blob/master/data/Sample_Dataset_2014.xlsx}{Sample\_Dataset\_2014.xlsx Download}

\hypertarget{correlation-as-a-regression}{%
\subsection{Correlation as a regression}\label{correlation-as-a-regression}}

Imagine we want to see how English and Reading are related. We would do a Pearson correlation, as seen on the top. However, we could also run a simple regression with English predicting Reading or vice versa, as seen on the bottom.

Notice how the Beta coefficient in the regression output is the \emph{standardized coefficient} and that the correlation is the \emph{standardized covariance}. Therefore, their values (and p-values) match identically!

\includegraphics{images/14-regression-wrap-up/correlation.png}

\hypertarget{independent-t-test-as-a-regression}{%
\subsection{Independent t-test as a regression}\label{independent-t-test-as-a-regression}}

Next let's look at how gender is related to reading scores. First, our t-statistic and p-value match directly from the independent t-test to the linear regression coefficient. Second, our unstandardized estimate in the regression \emph{is exactly the mean difference between the two genders}!

\includegraphics{images/14-regression-wrap-up/t-test.png}

\hypertarget{dependent-t-test-as-a-regression}{%
\subsection{Dependent t-test as a regression}\label{dependent-t-test-as-a-regression}}

The dependent t-test can't be performed as a regression in the base jamovi, but it can if we run it in the Rj editor using the stats package. The regression formula for a dependent t-test is \(y_1 -y_0 = 1\) and jamovi doesn't like it if there are not IVs, just an intercept. However, the stats package doesn't mind! Notice that our t-statistic, df, and p-value are exactly the same, and that the intercept estimate and SE match the mean difference in the paired samples t-test.

\includegraphics{images/14-regression-wrap-up/dependent_t-test.png}

\hypertarget{one-way-anova-as-a-regression}{%
\subsection{One-way ANOVA as a regression}\label{one-way-anova-as-a-regression}}

The one-way ANOVA is the same as regression, too. Let's examine how rank (an ordinal variable from 1-4) relates to English scores. In the linear regression, we asked for the ANOVA test under Model Coefficients; notice how it directly matches the ANOVA table.

Although I did not directly ask for them, the estimated marginal means for the linear regression match that of the one-way ANOVA. However, I want to call attention to how the coefficients directly match. The intercept is the average English score when Rank = 1 (freshman). However, the estimate for 2 -- 1 is .68, but 81.93 + .68 = 82.61; it's not exact due to rounding errors, but it matches the mean for group 2 because in the linear equation if you set that value to 1 you are saying the other values are 0 so the group membership is Rank = 2 (sophomore). You can do this for all the groups and see how they match.

\begin{figure}

{\centering \includegraphics[width=0.49\linewidth]{images/14-regression-wrap-up/anova1} \includegraphics[width=0.49\linewidth]{images/14-regression-wrap-up/anova2} 

}

\caption{One-way ANOVA as a regression}\label{fig:unnamed-chunk-1}
\end{figure}

\hypertarget{writing-up-results}{%
\chapter{Writing up results}\label{writing-up-results}}

This chapter goes over how to write up statistical results. Refer back to this chapter often!

\hypertarget{the-4-components-of-writing-statistical-results}{%
\section{The 4 components of writing statistical results}\label{the-4-components-of-writing-statistical-results}}

When writing up the results of a statistical test, we should always include the following information:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Description of your research question and/or hypotheses.
\item
  Description of your data. If you fail to meet assumptions, you should specify that and describe what test you chose to perform as a result.
\item
  The results of the inferential test, including what test was performed, the test value and degrees of freedom, p-value, and effect size.
\item
  Interpretation of the results or whether the hypothesis was supported or not, including any other information as needed.
\end{enumerate}

\hypertarget{an-example-1}{%
\section{An example}\label{an-example-1}}

Let's go through an example. This data comes from the independent t-test chapter. Given the results of the t-test, we can write up our results in APA something like this:

\begin{quote}
The research question was whether there was a difference in student grades between Anastasia's and Bernadette's classes. Anastasia's students (\emph{M} = 74.53, \emph{SD} = 9.00, \emph{n} = 15) had significantly higher grades than Bernadette's students (\emph{M} = 69.06, \emph{SD} = 5.77, \emph{n}~= 18), \emph{t} (31) = 2.12, \emph{p} = .043, \emph{d} = .74.
\end{quote}

Let's analyze that against the 4 things we need to report:

\begin{quote}
\textbf{\#1:} The research question was whether there was a difference in student grades between Anastasia's and Bernadette's classes. \textbf{\#4} Anastasia's students \textbf{\#2} (\emph{M} = 74.53, \emph{SD} = 9.00, \emph{n} = 15) \textbf{\#4 cont.} had significantly higher grades than Bernadette's students \textbf{\#2} (\emph{M} = 69.06, \emph{SD} = 5.77, \emph{n}~= 18), \textbf{\#3} \emph{t} (31) = 2.12, \emph{p} = .043, \emph{d} = .74.
\end{quote}

To ease the interpretation, let's write it out like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Research question or hypothesis}: Is there a difference in student grades between Anastasia's and Bernadette's classes?
\item
  \textbf{Descriptive statistics}: Anastasia's students (\emph{M} = 74.53, \emph{SD} = 9.00, \emph{n} = 15); Bernadette's students (\emph{M} = 69.06, \emph{SD} = 5.77, \emph{n}~= 18)
\item
  \textbf{Inferential statistics}: \emph{t} (31) = 2.12, \emph{p} = .043, \emph{d} = .74
\item
  \textbf{Interpretation of results that answer's the research question or demonstrates whether the hypothesis was rejected or not}: Anastasia's students had significantly higher grades than Bernadette's students.
\end{enumerate}

Sometimes, people like to put the statistics inside a parentheses. In that case, you need to change the parentheses around the degrees of freedom as brackets. Here's another example write-up of the results in APA style:

\begin{quote}
\textbf{\#1} I tested the difference in grades between Anastasia's students \textbf{\#2} (\emph{M} = 74.53, \emph{SD} = 9.00, \emph{n} = 15) and Bernadette's students (\emph{M} = 69.06, \emph{SD} = 5.77, \emph{n}~= 18). \textbf{\#3} An independent samples t-test showed that the 5.48 mean difference between the tutor's student was statistically significant (\emph{t} {[}31{]} = 2.12, \emph{p} = .043, \emph{d} = .74). \textbf{\#4} Therefore, we reject the null hypothesis that there is no difference in grades between the two classes.
\end{quote}

Note that these are not the only way we can write up the results in APA format. The key is that we include all four pieces of information as specified above.

\hypertarget{appendix-appendices}{%
\appendix}


\hypertarget{answers}{%
\chapter{Answers}\label{answers}}

\hypertarget{answers-to-5.3-power}{%
\section{Answers to 5.3 Power}\label{answers-to-5.3-power}}

In the following table, determine where each of the pieces should go. Note that we have six things to populate but only four cells: each cell must contain at least one of the six things. Think critically here before testing your answers!

\begin{longtable}[]{@{}lcc@{}}
\toprule
& H\textsubscript{0} is true & H\textsubscript{1} is true \\
\midrule
\endhead
\textbf{\emph{p}} \textbf{\textless{} .05} (statistically significant) & A & B \\
\textbf{\emph{p}} \textbf{\textgreater{} .05} (statistically non-significant) & C & D \\
\bottomrule
\end{longtable}

Which cell should each of the following items go?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  alpha (answer = A)
\item
  power (answer = B)
\item
  type I error (answer = A)
\item
  Type II error (answer = D)
\item
  Correct inference (answer = B \& C)
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Let's see what happens when we both increase power AND decrease alpha. Fill out the table on your own. When we assume the null and alternative hypotheses are 50\% likely each, and we set our alpha to 1\% and our power to 95\%, how much more likely is it that the alternative hypothesis is true than the null hypothesis is true? (answer = 95 times more likely!)

\hypertarget{answers-to-7.1-one-sample-t-test}{%
\section{Answers to 7.1 one-sample t-test}\label{answers-to-7.1-one-sample-t-test}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Do the students in our dataset have a higher Writing score than than the passing score? (\emph{M} = 70)?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis? (answer = one-tailed)
  \item
    Which statistic should you use based on your assumptions? (answer = Wilcoxon rank one sample t-test)
  \item
    Do the students in our dataset have a higher Writing score than than the passing score? (answer = yes)
  \end{itemize}
\item
  \textbf{Do the students in our dataset have the same national average height of college students (\emph{M} = 68 inches)?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis? (answer = two-tailed)
  \item
    Which statistic should you use based on your assumptions? (answer = student one sample t-test)
  \item
    Do the students in our dataset have the same national average height of college students)? (answer = no)
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-7.2-independent-samples-t-test}{%
\section{Answers to 7.2 independent samples t-test}\label{answers-to-7.2-independent-samples-t-test}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Does height differ by gender (Gender: male = 0, female = 1)?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis? (answer = two-tailed)
  \item
    Which statistic should you use based on your assumptions? (answer = Mann Whitney U)
  \item
    Does height differ by gender? (answer = yes)
  \end{itemize}
\item
  \textbf{Do athletes (Athlete: athletes = 1, non-athlete = 0) have faster sprint times than non-athletes?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis? (answer = one-tailed)
  \item
    Which statistic should you use based on your assumptions? (answer = Mann Whitney U)
  \item
    Do athletes have faster sprint times than non-athletes? (answer = yes)
  \end{itemize}
\item
  \textbf{Do students who live on campus (LiveOnCampus: on campus = 1, off campus = 0) have higher English scores than students who live off campus?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis? (answer = one-tailed)
  \item
    Which statistic should you use based on your assumptions? (answer = Welch t-test)
  \item
    Does students who live on campus have higher English scores? (answer = no)
  \end{itemize}
\item
  \textbf{Does athletic status relate to math scores?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis? (answer = two-tailed)
  \item
    Which statistic should you use based on your assumptions? (answer = independent t-test)
  \item
    Does athletic status relate to math scores? (answer = yes)
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-7.3-dependent-t-test}{%
\section{Answers to 7.3 dependent t-test}\label{answers-to-7.3-dependent-t-test}}

\textbf{Note}: Technically, none of our data is suitable for a dependent t-test in this dataset. We will pretend that the four test score variables (\texttt{English}, \texttt{Reading}, \texttt{Math}, and \texttt{Writing}) are really four measurements of the same underlying test. In reality, we would analyze this data using correlation.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Do students perform better on the English test than they do the Writing test?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis? (answer = one-tailed)
  \item
    Which statistic should you use based on your assumptions? (answer = dependent t-test)
  \item
    Do students perform better on the English test than they do the Writing test? (answer = yes)
  \end{itemize}
\item
  \textbf{Does students' English scores relate to their Reading scores?}

  \begin{itemize}
  \item
    Should you use a one-tailed or two-tailed hypothesis? (answer = two-tailed)
  \item
    Which statistic should you use based on your assumptions? (answer = dependent t-test)
  \item
    Does students' English scores relate to their Reading scores? (answer = no)
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-8.1-goodness-of-fit-test}{%
\section{Answers to 8.1 goodness of fit test}\label{answers-to-8.1-goodness-of-fit-test}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Are there equal numbers of athletes and non-athletes?} (\texttt{Athlete} variable)

  \begin{itemize}
  \item
    Do you meet the assumptions? (answer = yes)
  \item
    Are the observed frequencies similar to the expected frequencies? (answer = no)
  \item
    What is your chi-square value, rounded to two decimal places? (answer = 10.32)
  \end{itemize}
\item
  \textbf{I happen to know the school this data comes from has 40\% athletes and 60\% non-athletes. Does our data match the school population?}

  \begin{itemize}
  \item
    Change your Expected Proportions ratio to .6 for non-athletes and .4 for athletes.
  \item
    Are the observed frequencies similar to the expected frequencies? (answer = yes)
  \item
    What is your chi-square value, rounded to two decimal places? (answer = .96)
  \end{itemize}
\item
  \textbf{Are there equal numbers of freshmen, sophomores, juniors, and seniors?} (\texttt{Rank} variable)

  \begin{itemize}
  \item
    Do you meet the assumptions? (answer = yes)
  \item
    Are the observed frequencies similar to the expected frequencies? (answer = no)
  \item
    What is your chi-square value, rounded to two decimal places? (answer = 33.94)
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-8.2-chi-square-test-of-independence}{%
\section{Answers to 8.2 chi-square test of independence}\label{answers-to-8.2-chi-square-test-of-independence}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Is Athlete related to Gender?}

  \begin{itemize}
  \item
    Do you meet the assumptions? (answer = yes)
  \item
    Which test should you perform? (answer = chi-square)
  \item
    Are the observed frequencies similar to the expected frequencies? (answer = no)
  \item
    What is your chi-square value, rounded to two decimal places? (answer = 8.45)
  \end{itemize}
\item
  \textbf{Is Gender related to Rank?}

  \begin{itemize}
  \item
    Do you meet the assumptions? (answer = yes)
  \item
    Which test should you perform? (answer = chi-square)
  \item
    Are the observed frequencies similar to the expected frequencies? (answer = yes)
  \item
    What is your chi-square value, rounded to two decimal places? (answer = .61)
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-9.1-one-way-anova}{%
\section{Answers to 9.1 one-way ANOVA}\label{answers-to-9.1-one-way-anova}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Does students differ on English scores by rank (i.e., freshmen, sophomore, junior, senior)?}

  \begin{itemize}
  \item
    Do you satisfy the assumption of normality? (answer = yes)
  \item
    Do you satisfy the assumption of homogeneity of variance? (answer = yes)
  \item
    Which statistic should you use? (answer = one-way ANOVA)
  \item
    Do students differ on English scores by rank? (answer = no)
  \end{itemize}
\item
  \textbf{Does smoking status (Smoking: Nonsmoker = 0, Past smoker = 1, Current smoker = 2) relate to sprint time?}

  \begin{itemize}
  \item
    Do you satisfy the assumption of normality? (answer = no)
  \item
    Do you satisfy the assumption of homogeneity of variance? (answer = yes)
  \item
    Which statistic should you use? (answer = Kruskal-Wallis test)
  \item
    Does smoking status relate to sprint time? (answer = yes)
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-9.2-finding-group-differences}{%
\section{Answers to 9.2 finding group differences}\label{answers-to-9.2-finding-group-differences}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Does students differ on English scores by rank (i.e., freshmen, sophomore, junior, senior)?}

  \begin{itemize}
  \tightlist
  \item
    Perform Tukey's post hoc tests. What are the results of the post hoc comparison? (answer = trick question! you wouldn't perform them because the F-test is not significant)
  \end{itemize}
\item
  \textbf{Does smoking status (Smoking: Nonsmoker = 0, Past smoker = 1, Current smoker = 2) relate to sprint time?}

  \begin{itemize}
  \tightlist
  \item
    Perform Tukey's post hoc tests. What are the results of the post hoc comparison? (answer = Nonsmokers had significantly faster sprint times than current smokers)
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-9.3-repeated-measures-anova}{%
\section{Answers to 9.3 repeated measures ANOVA}\label{answers-to-9.3-repeated-measures-anova}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Does students differ on their test scores (English, Reading, Math, Writing)?}

  \begin{itemize}
  \item
    Based on your understanding of the nature of the test scores, which statistic should you use? (answer = repeated measures ANOVA)
  \item
    Should you apply a sphericity correction? If so, which one? (answer = yes, Huynh-Feldt)
  \item
    Do students differ on their test scores? (answer = yes)
  \item
    Should you perform a planned contrast or post hoc comparison? (answer = yes)
  \item
    What are the results of the post hoc comparison?
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-10.1-correlation}{%
\section{Answers to 10.1 correlation}\label{answers-to-10.1-correlation}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Are there significant correlations among the four tests (English, reading, math, writing)?}

  \begin{itemize}
  \item
    Do you meet the assumption of normality for all four tests? (answer = yes for all but maybe not writing)
  \item
    Do you meet the assumption of linearity for all four tests? (answer = yes)
  \item
    Are the four tests significantly correlated among each other? (answer = yes)
  \item
    Round your answers to two decimal places:

    \begin{itemize}
    \item
      What is the correlation between reading and math? (answer = .52)
    \item
      What is the correlation between writing and reading? (answer = .11)
    \item
      What is the correlation between writing and English? (answer = .37)
    \end{itemize}
  \end{itemize}
\end{enumerate}

\hypertarget{answers-to-10.2-regression}{%
\section{Answers to 10.2 regression}\label{answers-to-10.2-regression}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Perform a multiple regression examining how \texttt{English}}, \textbf{\texttt{Reading} and \texttt{Writing}, as well as \texttt{Gender} relate to the dependent variable \texttt{Math}.}

  \begin{itemize}
  \item
    Do you have any significant outliers? (answer = no)
  \item
    Are your residuals normally distributed? (answer = yes)
  \item
    Do you satisfy the assumption of linearity and homoscedasticity of your residuals (just check the Fitted residual plot)? (answer = yes)
  \item
    Do you meet the assumption of independent residuals? (answer = yes)
  \item
    Do you meet the assumption of no multicollinearity? (answer = yes)
  \item
    Can you perform a regression with this data? (answer = yes)
  \item
    What is your adjusted R-squared, rounded to two decimal places? (answer = .31)
  \item
    Is the overall model statistically significant? (answer = yes)
  \item
    Is \texttt{English} statistically significant? (answer = no)
  \item
    Is \texttt{Reading} statistically significant? (answer = yes)
  \item
    Is \texttt{Writing} statistically significant? (answer = yes)
  \item
    Is \texttt{Gender} statistically significant? (answer = yes)
  \item
    For \texttt{Gender}, do male (Gender = 0) or female (Gender = 1) students have higher math scores? (answer = male)
  \end{itemize}
\end{enumerate}

  \bibliography{book.bib,packages.bib}

\end{document}
