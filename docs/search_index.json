[["index.html", "Statistics with jamovi Welcome", " Statistics with jamovi Dana Wanzer Last Update: 2020-10-24 Welcome This is the website for PSYC 290 and PSYC 790 at the University of Wisconsin-Stout, taught by Dana Wanzer. These resources are aimed at teaching you how to use jamovi and null hypothesis significance testing (NHST) to answer research questions. This website is free to use and is licensed under a Creative Commons BY-SA (CC BY-SA) license version 4.0. This means you are free to share (i.e., copy and redistribute the material in any medium or format) and adapt (i.e., remix, transform, and build upon the material for any purpose, even commercially), provided that you attribute these resources by citing me, indicating if changes were made and you share alike (i.e., if you adapt, you must distribute your contributes under the same license as the original). Portions of this book may have been adapted from Learning statistics with jamovi: A tutorial for psychology students and other beginners by Danielle J. Navarro and David R. Foxcroft, version 0.70. Furthermore, the template and style of this book is from PsyTeachR. "],["introduction.html", "Chapter 1 Introduction 1.1 Quiz Questions", " Chapter 1 Introduction This chapter will walk you through how this website/book works. 1.1 Quiz Questions Throughout this website, there will be questions to help you test your knowledge. When you type in or select the correct answer, the dashed box will change color and become solid. For example: What is 2+2? We attend the University of Wisconsin- Stout Madison Green Bay True or false: Statistics is awesome. TRUE FALSE "],["independent-t-test.html", "Chapter 2 Independent t-test 2.1 What is the independent t-test? 2.2 Data set-up 2.3 The math behind the independent t-test 2.4 Assumptions 2.5 In jamovi 2.6 Additional information about the independent t-test", " Chapter 2 Independent t-test 2.1 What is the independent t-test? The independent t-test is used to test the difference in our dependent variable between two different groups of observations. Our grouping variable is our independent variable. In other words, we use the independent t-test when we have a research question with a continuous dependent variable and a categorical independent variable with two categories in which different participants are in each category. The independent t-test is also the independent samples t-test and the Students t-test. I will use these terms interchangeably. 2.2 Data set-up To conduct the independent t-test, we first need to ensure our data is set-up properly in our dataset. This requires having two columns: one with our continuous dependent variable and one indicating which group the participant is in. Each row is a unique participant or unit of analysis. Heres what example data may look like if we were testing for differences in a test score by students in my fall or spring semesters of this course: Example data for the independent t-test ID Semester TestScore 1 Fall 86 2 Fall 80 3 Fall 75 4 Fall 79 5 Fall 82 6 Spring 84 7 Spring 90 8 Spring 72 9 Spring 75 10 Spring 81 In the example data above, what is your independent variable? ID Semester TestScore In the example data above, what is your dependent variable? ID Semester TestScore 2.3 The math behind the independent t-test The basic math of the independent t-test the mean difference divided by the pooled standard error. \\(t = \\frac{\\bar{X}_1 - \\bar{X}_2}{SE({\\bar{X}_1 - \\bar{X}_2})}\\) The denominator of the equation is more difficult to calculate and depends on whether the sample size between groups is equal. 2.4 Assumptions As a parametric test, the independent t-test has the same assumptions as other parametric tests: The dependent variable is normally distributed Variances in the two groups are roughly equal (i.e., homogeneity of variances) The dependent variable is interval or ratio (i.e., continuous) Scores are independent between groups We cannot test the third and fourth assumptions; rather, those are based on knowing your data. However, we can and should test for the first two assumptions. Fortunately, the independent samples t-test in jamovi has two check boxes under Assumption Checks that lets us test for both assumptions. 2.5 In jamovi Lets run an example with data from lsj-data. Open data from your Data Library in lsj-data. Select and open Harpo. This dataset is hypothetical data of 33 students taking Dr. Harpos statistics lectures. We have two tutors for the class, Anastasia (n = 15) and Bernadette (n = 18). Our research question is Which tutor results in better student grades? We dont have a hypothesis that one does better than the other. To perform an independent t-test in jamovi, go to the Analyses tab, click the T-Tests button, and choose Independent Samples T-Test. Move your dependent variable grade to the Dependent Variables box and your independent variable tutor to the Grouping Variable box. Under Tests, select Student's Under Hypothesis, because we have a two-sided hypothesis select a two-sided hypothesis (Group 1 does not equal Group 2). Under Additional Statistics, select Mean difference, Effect size, and Descriptives. Under Assumption Checks, select all three options: Homogeneity test, Normality test, and Q-Q plot. When you are done, your setup should look like this Figure 2.1: Independent t-test setup in jamovi 2.5.1 Checking assumptions in jamovi 2.5.1.1 Testing normality We test for normality using the Shapiro-Wilk test and the Q-Q plot. The Shapiro-Wilk test was not statistically significant (W = .98, p = .827); therefore, this indicates the data is normally distributed. Furthermore, the lines are fairly close to the diagonal line in the Q-Q plot. We can conclude that we satisfy the assumption of normality. Figure 2.2: Testing normality in jamovi 2.5.1.2 Testing homogeneity of variance We test for homogeneity of variance using the Levenes test. The Levenes test was not statistically significant (F [1, 31] = 2.49, p = .125); therefore, this indicates our data satisfies the assumption of homogeneity of variance. However, I would add a caveat that we have a small sample of data (n = 15 for Anastasia and n = 18 for Bernadette) and the standard deviations are quite different from one another (SD = 9.00 vs 5.77, respectively). We should have tried to collect more data. Figure 2.3: Testing homogeneity of variance in jamovi 2.5.2 Interpreting results Once we are satisfied we have satisfied the assumptions for the independent t-test, we can interpret our results. Figure 2.4: Independent t-test results in jamovi Our p-value is less than .05, so our results are statistically significant. We can write up our results in APA something like this: Anastasias students (M = 74.53, SD = 9.00, n = 15) had significantly higher grades than Bernadettes students (M = 69.06, SD = 5.77, n = 18), t (31) = 2.12, p = .043, d = .74. Sometimes, people like to put the statistics inside a parentheses. In that case, you need to change the parentheses around the degrees of freedom as brackets. Heres another example write-up of the results in APA style: I tested the difference in grades between Anastasias students (M = 74.53, SD = 9.00, n = 15) and Bernadettes students (M = 69.06, SD = 5.77, n = 18). An independent samples t-test showed that the 5.48 mean difference between the tutors student was statistically significant (t [31] = 2.12, p = .043, d = .74). 2.6 Additional information about the independent t-test 2.6.1 Positive and negative t values Students often worry about positive or negative t-statistic values and are unsure how to interpret it. Positive or negative t-statistic values simply occur based on which group is listed first. Our t-statistic above is positive because we tested the difference between Anastasia and Bernadette: (Anastasia - Bernadette) = (74.53 - 69.06) = (5.48). However, if we flipped it and tested the difference between Bernadette and Anastasia, our mean difference would be -5.48 and our t-statistic would be -2.12. All that is to say, your positive or negative t-statistic is arbitrary. So do not fret! However, it is important the sign of your t-statistic matches what you report. For example, notice the difference: Anastasias students had higher grades than Bernadettes, t (31) = 2.12, p = .043, d = .74. Bernadettes students had lower grades than Anastasias, t (31) = -2.12, p = .043, d = .74. One last note: this positive or negative t-statistic is only relevant for the independent and dependent t-test. You will not get negative values for the F-statistic or chi-square tests! 2.6.2 What if I violated assumptions? The great news is that jamovi includes the Welchs t-statistic and the non-parametric version of the independent t-test (Mann-Whitney U)! The Welchs t-test has three main differences from the independent samples t-test: (a) the standard error (SE) is not a pooled estimate, (b) the degrees of freedom are calculated very different (not N - 2), and (c) it does not have an assumption of homogeneity of variance. The Mann-Whitney U is not calculated based on the mean but rather the median and compares ranks of values across the two groups: it has no assumptions about the distribution of data or homogeneity of variances. Heres what statistic you should choose based on satisfying assumptions: Normality: satisfied Normality: not satisfied Homogeneity of Variance: satisfied independent samples t-test Mann-Whitney U Homogeneity of Variance: not satisfied Welchs t-test Mann-Whitney U Here is what the output for all three tests look like: Figure 2.5: All independent t-test results in jamovi 2.6.2.1 Welchs t-test in jamovi To conduct this in jamovi, under Tests select Welch's. You will interpret the results similarly to the independent t-test: Using a Welchs t-test, there was not a statistically significant difference in grades between Anastasias students (M = 74.53, SD = 9.00, n = 15) and Bernadettes students (M = 69.06, SD = 5.77, n = 18), t (23.02) = 2.03, p = .054, d = .72. Why is it no longer statistically significant? Which result should you trust? In reality, the difference in p-values is likely due to chance. However, the independent t-test and Welchs test have different strengths and weaknesses. If the two populations really do have equal variances, then the independent t-test is slightly more powerful (lower Type II error rate) than the Welchs test. However, if they dont have the same variances, then the assumptions of the independent t-test are violated and you may not be able to trust the results; you may end up with a higher Type I error rate. So its a trade-off. Which should you use? I tend to prefer always using Welchs t-test because if the variances are equal, then there will be practically no difference between the independent and Welchs t-test. But if the variances are not equal, then Welchs t-test will outperform the independent t-test. For that reason, defaulting to the Welchs t-test makes most sense to me. 2.6.2.2 Mann-Whitney U test If you do not satisfy the assumption of normality (regardless of whether you satisfy the assumption of homogeneity of variance), you should either try to transform your data to be normally distributed or you will need to use a non-parametric test. In this case, if you originally wanted to perform an independent t-test, the non-parametric equivalent test is the Mann-Whitney U test. I will not go into specifics, but the idea behind the Mann-Whitney U test is that you take all the values (regardless of group) and rank them. You then sum the ranks across groups and calculate your U statistic and p-value. You interpret the p-value like you normally would, but there are differences in how we report the results because this statistic is based on the median not the mean. Using the Mann-Whitney U test, there was a statistically significant difference in grades between Anastasias students (Mdn = 76, n = 15) and Bernadettes students (Mdn = 69, n = 18), t (23.02) = 2.03, p = .054, d = .72. "],["references.html", "A References", " A References "]]
