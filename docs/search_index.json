[["cleaning-data.html", "3.3 Cleaning data", " 3.3 Cleaning data There are four basic types of cleaning we will be learning about: checking your data is setup correctly, computing new variables, transforming variables, and using filters. 3.3.1 Data setup As previously mentioned, its really important to check that the data types and measurement types of your variables are correct. You should open the Setup () option under the Data tab to check. When youre in Setup, heres the things you should be doing for all variables: Make sure the variable name is meaningful to you. You may also want to change it to something that will appear nicely in your data visualizations or tables (e.g., dont write Q35 but rather BDI Score). Add a description to your variable so you have more context. Maybe you write Average score of all BDI items for the description of your BDI Score variable. Check your measure and data types are correct. Specify if there is a code for missing values. Make sure the code does not match the code you use for actual variables! For example, if I have a variable that ranges from 0-10, then I wouldnt use 9 as a code for missing values; instead, I might use 99 or -9. Add labels to levels. For example, the variable Athlete is 0 for non-athlete and 1 for athlete. Rather than keeping just the 0 and 1, you can specify under Levels that 0 is non-athlete. 3.3.2 Compute Sometimes you need to create new variables from your raw (meaning uncleaned) data. Perhaps you collected data on a scale that has five items. Normally, we create an average score of all the five items and that new computed average score is what we use in our analyses. Lets open the Big 5 dataset built into jamovi. You can open this dataset by clicking the three horizontal lines on the top left of jamovi (the menu), choose Open, then select Data Library. In the main Data Library folder is a dataset called Big 5. This dataset has the scores on all five subscales of the Big Five personality test. Lets imagine we want the average score of the entire Big Five test. We would click on the Data tab and choose Compute. We would rename the computed variable (e.g., Big5_Avg), add in a description, and then create the formula. In this case, we need to select the function MEAN. Below the function, it provides a template of what the formula should look like. We need to specify the function MEAN(), add all the variables we want to calculate in the mean (i.e., the five subscales of the Big 5), and there are two alternative options: ignore_missing is defaulted to 0 (meaning DONT ignore missing, or rather include missing) and min_valid is defaulted to 0 (meaning its ignoring this; perhaps you only want to include people that have at least three valid cases). The basic formula, then is to do MEAN(var1, var2,  varn). You can see what we need to do with this dataset below. Theres actually no missing data, so the two additional arguments arent necessary for us to worry about. If youd like to learn more about computed variables in jamovi, check out this jamovi blog post on the topic. 3.3.3 Transform Sometimes we want to take an existing variable and transform it in some way or we want to do a computation across multiple variables (e.g., reverse-score multiple items in a dataset). If you want to learn more about transforming variables, the jamovi blog has a great blog post on the topic. 3.3.3.1 Recoding Maybe we want to recode variables. Perhaps we want to recode the Neuroticism scale into low, moderate, and high extraversion. The scale ranges from 1-5, so Im going to say that scores between 1-2.333 are low, 2.334 to 3.666 is moderate, and 3.667 to 5 is high. First, I create a new Transform variable: Then I need to specify the transformation. Click Edit to do so (or, when creating a new transformation, click the transformation and select Create New Transform). We need to specify the recode conditions. Click Add recode condition twice. For the first formula, we want to specify that if the $source (meaning the score for the variable were using for the transformation, in this case Neuroticism) is less than or equal to 2.333, then it will be recoded as low. Notice the use of apostrophes around the text! We do the same for moderate. Then we can end with an else statement: all other values (else) are recoded as high. We can either let it auto determine the measure type, but I like to be in control of my data and therefore specify it is an ordinal variable. 3.3.3.2 Multiple transformations Maybe we instead want to do a computation across multiple variables. Perhaps we have multiple items that need to be reverse-scored, or in our case we want to use our previous Low_mod_high transformation to perform on all the subscales of the Big 5. We can click a new variable (e.g., Openness), select Transform, rename the variable, and select the Low_mod_high transformation we already used. Voila! The work we did previously can easily be used again in this analysis. 3.3.4 Filters Sometimes we only want to analyze certain pieces of our data. We can filter by rows and by columns. Check out this blog post by jamovi on more details of filters. 3.3.4.1 Row filters Maybe we only want to analyze data from people who are low in neuroticism. We would create the following filter: Youll notice in the dataset it will add a new column named Filter 1 (the name of the filter) and there will either be an X or a green check mark indicating whether its removed (X) or kept (check) in the analyses. If you want to take off the filter, but keep it available, click on the filter column and toggle the green button on the top right from active to inactive. It will then grey out the column. A couple things to note: Notice that to say it equals to low you have to use a double equal sign: == Another common thing you may want to specify is that the variable is not equal to something. You would use the following: != Otherwise you should be familiar with the other operations: &lt;, &gt;, &lt;=, &gt;= 3.3.4.2 Column filters Column filters are useful when you want to use a filter for some but not all of your analyses. Rather than creating a filter, we need to compute a new variable using the FILTER() function. For example, we can compute a new variable that is FILTER(Neutoricism_cat, Neuroticism_cat == 'low' . Then we could use that new variable in an analysis (in this case its not very useful because there is no variability in this variable, but there are useful times for using column filters for analyses). "]]
